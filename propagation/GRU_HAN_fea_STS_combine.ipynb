{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgupxXAn-5HF",
        "outputId": "6141f5c2-2d6b-4baa-9ce3-c979e30f5121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import sys\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from keras import Sequential, regularizers \n",
        "\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras import losses\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten, InputLayer\n",
        "\n",
        "import time\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import torch\n",
        "from sklearn.metrics import precision_score, \\\n",
        "    recall_score, confusion_matrix, classification_report, \\\n",
        "    accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn import metrics\n",
        "import plotly.express as px\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer,  text_to_word_sequence\n",
        "# from keras.engine.topology import Layer\n",
        "from keras import initializers as initializers, regularizers, constraints\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Embedding, Input, Dense, LSTM, GRU, Bidirectional, TimeDistributed, Dropout\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.models import Model\n",
        "from nltk import tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_df = \"/content/drive/MyDrive/fake_bert/politifact_global_feature.pkl\""
      ],
      "metadata": {
        "id": "BxH344MZ_D_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pickle.load(open(path_df, \"rb\"))"
      ],
      "metadata": {
        "id": "AOIr3tZp_J-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "b5z39z9wJkPK",
        "outputId": "29b5f021-31e8-4f21-9a02-d69c5bb39a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                              text  \\\n",
              "id                                                                   \n",
              "politifact720    Organizing for ’18\\n\\nThrough Election Day\\n\\n...   \n",
              "politifact10731  COLUMBUS, Ohio — America's role as a world lea...   \n",
              "politifact11115  In the course of the email review, State Depar...   \n",
              "politifact14148  We all get lazy from time to time and just wan...   \n",
              "politifact6932   Mitt Romney came to coal country on Aug. 14, s...   \n",
              "\n",
              "                                                             title  \\\n",
              "id                                                                   \n",
              "politifact720                                Organizing for Action   \n",
              "politifact10731  Call 'Islamic terrorism' what it is: a threat ...   \n",
              "politifact11115   Inquiry Sought in Hillary Clinton’s Use of Email   \n",
              "politifact14148  NASA Will Pay You 18000 USD To Stay In Bed And...   \n",
              "politifact6932   Barack Obama says Mitt Romney condemned coal-f...   \n",
              "\n",
              "                                                           top_img  \\\n",
              "id                                                                   \n",
              "politifact720    https://secure.assets.bostatic.com/apps/quincy...   \n",
              "politifact10731  http://triblive.com/csp/mediapool/sites/dt.com...   \n",
              "politifact11115  https://static01.nyt.com/images/2015/07/24/us/...   \n",
              "politifact14148  http://reflectionofmind.org/wp-content/uploads...   \n",
              "politifact6932   http://static.politifact.com.s3.amazonaws.com/...   \n",
              "\n",
              "                 publish_date  \\\n",
              "id                              \n",
              "politifact720            None   \n",
              "politifact10731  1429079762.0   \n",
              "politifact11115  1437721200.0   \n",
              "politifact14148  1482942009.0   \n",
              "politifact6932   1345705200.0   \n",
              "\n",
              "                                                            images  \\\n",
              "id                                                                   \n",
              "politifact720    [https://secure.assets.bostatic.com/apps/quinc...   \n",
              "politifact10731  [http://triblive.com/csp/mediapool/sites/TribL...   \n",
              "politifact11115  [https://static01.nyt.com/images/2015/07/24/us...   \n",
              "politifact14148  [http://reflectionofmind.org/wp-content/upload...   \n",
              "politifact6932   [http://metric.politifact.com/b/ss/spttbglobal...   \n",
              "\n",
              "                     source  target  \\\n",
              "id                                    \n",
              "politifact720    politifact       1   \n",
              "politifact10731  politifact       1   \n",
              "politifact11115  politifact       1   \n",
              "politifact14148  politifact       0   \n",
              "politifact6932   politifact       1   \n",
              "\n",
              "                                                         tweet_mod  \\\n",
              "id                                                                   \n",
              "politifact720    [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "politifact10731  [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "politifact11115  [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "politifact14148  [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "politifact6932   [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "\n",
              "                                                         comp_text  \\\n",
              "id                                                                   \n",
              "politifact720    Organizing for 18 Through Election Day Sometim...   \n",
              "politifact10731  COLUMBUS Ohio America's role as a world leader...   \n",
              "politifact11115  In the course of the email review State Depart...   \n",
              "politifact14148  We all get lazy from time to time and just wan...   \n",
              "politifact6932   Mitt Romney came to coal country on Aug. 14 st...   \n",
              "\n",
              "                                                          lem_text  ...  \\\n",
              "id                                                                  ...   \n",
              "politifact720    organize for 18 through election day sometimes...  ...   \n",
              "politifact10731  columbus ohio americas role a a world leader a...  ...   \n",
              "politifact11115  in the course of the email review state depart...  ...   \n",
              "politifact14148  we all get lazy from time to time and just wan...  ...   \n",
              "politifact6932   mitt romney come to coal country on aug 14 sta...  ...   \n",
              "\n",
              "                    Sen15     Sen16     Sen17     Sen18     Sen19        G1  \\\n",
              "id                                                                            \n",
              "politifact720    0.949437  0.034845  0.071476  1.681818  0.011628  0.012289   \n",
              "politifact10731  0.694333  0.000000 -0.738400  1.250000  0.041667  0.046498   \n",
              "politifact11115  0.778346  0.012754 -0.472698  1.156863  0.000543  0.000609   \n",
              "politifact14148  0.829039  0.098993  0.134468  1.240000  0.000836  0.000885   \n",
              "politifact6932   0.642184  0.016658 -0.765808  1.000000  0.025000  0.025214   \n",
              "\n",
              "                     G2      G3            G4      G5  \n",
              "id                                                     \n",
              "politifact720      79.0    86.0  1.866903e-04    85.0  \n",
              "politifact10731    20.0    24.0  3.071834e-03    23.0  \n",
              "politifact11115  1673.0  1842.0  5.721557e-07  1841.0  \n",
              "politifact14148  1089.0  1196.0  1.024639e-06  1195.0  \n",
              "politifact6932     38.0    40.0  6.738988e-04    39.0  \n",
              "\n",
              "[5 rows x 67 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-613158cc-000d-4d76-a468-9f6fea4dbb8b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>top_img</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>images</th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>tweet_mod</th>\n",
              "      <th>comp_text</th>\n",
              "      <th>lem_text</th>\n",
              "      <th>...</th>\n",
              "      <th>Sen15</th>\n",
              "      <th>Sen16</th>\n",
              "      <th>Sen17</th>\n",
              "      <th>Sen18</th>\n",
              "      <th>Sen19</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "      <th>G4</th>\n",
              "      <th>G5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>politifact720</th>\n",
              "      <td>Organizing for ’18\\n\\nThrough Election Day\\n\\n...</td>\n",
              "      <td>Organizing for Action</td>\n",
              "      <td>https://secure.assets.bostatic.com/apps/quincy...</td>\n",
              "      <td>None</td>\n",
              "      <td>[https://secure.assets.bostatic.com/apps/quinc...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>Organizing for 18 Through Election Day Sometim...</td>\n",
              "      <td>organize for 18 through election day sometimes...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.949437</td>\n",
              "      <td>0.034845</td>\n",
              "      <td>0.071476</td>\n",
              "      <td>1.681818</td>\n",
              "      <td>0.011628</td>\n",
              "      <td>0.012289</td>\n",
              "      <td>79.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>1.866903e-04</td>\n",
              "      <td>85.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10731</th>\n",
              "      <td>COLUMBUS, Ohio — America's role as a world lea...</td>\n",
              "      <td>Call 'Islamic terrorism' what it is: a threat ...</td>\n",
              "      <td>http://triblive.com/csp/mediapool/sites/dt.com...</td>\n",
              "      <td>1429079762.0</td>\n",
              "      <td>[http://triblive.com/csp/mediapool/sites/TribL...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>COLUMBUS Ohio America's role as a world leader...</td>\n",
              "      <td>columbus ohio americas role a a world leader a...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.694333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.738400</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.046498</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3.071834e-03</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact11115</th>\n",
              "      <td>In the course of the email review, State Depar...</td>\n",
              "      <td>Inquiry Sought in Hillary Clinton’s Use of Email</td>\n",
              "      <td>https://static01.nyt.com/images/2015/07/24/us/...</td>\n",
              "      <td>1437721200.0</td>\n",
              "      <td>[https://static01.nyt.com/images/2015/07/24/us...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>In the course of the email review State Depart...</td>\n",
              "      <td>in the course of the email review state depart...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.778346</td>\n",
              "      <td>0.012754</td>\n",
              "      <td>-0.472698</td>\n",
              "      <td>1.156863</td>\n",
              "      <td>0.000543</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>1673.0</td>\n",
              "      <td>1842.0</td>\n",
              "      <td>5.721557e-07</td>\n",
              "      <td>1841.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14148</th>\n",
              "      <td>We all get lazy from time to time and just wan...</td>\n",
              "      <td>NASA Will Pay You 18000 USD To Stay In Bed And...</td>\n",
              "      <td>http://reflectionofmind.org/wp-content/uploads...</td>\n",
              "      <td>1482942009.0</td>\n",
              "      <td>[http://reflectionofmind.org/wp-content/upload...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>We all get lazy from time to time and just wan...</td>\n",
              "      <td>we all get lazy from time to time and just wan...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.829039</td>\n",
              "      <td>0.098993</td>\n",
              "      <td>0.134468</td>\n",
              "      <td>1.240000</td>\n",
              "      <td>0.000836</td>\n",
              "      <td>0.000885</td>\n",
              "      <td>1089.0</td>\n",
              "      <td>1196.0</td>\n",
              "      <td>1.024639e-06</td>\n",
              "      <td>1195.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact6932</th>\n",
              "      <td>Mitt Romney came to coal country on Aug. 14, s...</td>\n",
              "      <td>Barack Obama says Mitt Romney condemned coal-f...</td>\n",
              "      <td>http://static.politifact.com.s3.amazonaws.com/...</td>\n",
              "      <td>1345705200.0</td>\n",
              "      <td>[http://metric.politifact.com/b/ss/spttbglobal...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>Mitt Romney came to coal country on Aug. 14 st...</td>\n",
              "      <td>mitt romney come to coal country on aug 14 sta...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.642184</td>\n",
              "      <td>0.016658</td>\n",
              "      <td>-0.765808</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.025214</td>\n",
              "      <td>38.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>6.738988e-04</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 67 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-613158cc-000d-4d76-a468-9f6fea4dbb8b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-613158cc-000d-4d76-a468-9f6fea4dbb8b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-613158cc-000d-4d76-a468-9f6fea4dbb8b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_lens = []\n",
        "sent_nums = []\n",
        "texts = []\n",
        "paras = []\n",
        "\n",
        "for idx in range(df[\"comp_text\"].shape[0]):\n",
        "    text = df[\"comp_text\"][idx]\n",
        "    texts.append(text)\n",
        "    sentences = tokenize.sent_tokenize(text)\n",
        "    sent_nums.append(len(sentences))\n",
        "    for sent in sentences:\n",
        "        sent_lens.append(len(text_to_word_sequence(sent)))\n",
        "    # print(len(sentences))\n",
        "    paras.append(sentences)"
      ],
      "metadata": {
        "id": "zW6KwrZlETFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentences[0]\n",
        "# print(\"---\")\n",
        "paras[0]\n",
        "# len(paras[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bax7g5rVJ_Gq",
        "outputId": "04804794-0adb-41d1-a39b-f3a8282091d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Organizing for 18 Through Election Day Sometimes fighting for progress on the issues means fighting to win on election day.',\n",
              " \"This year many of the issues we've fought for for years are on the ballot so we're Organizing for 18.\",\n",
              " 'Host or find an event near you this election season.',\n",
              " 'Find an event']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features=10000\n",
        "max_senten_len=40\n",
        "max_senten_num=6\n",
        "embed_size=100\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "metadata": {
        "id": "Stonxlk1BXVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_features, oov_token=True)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "data = np.zeros((len(texts), max_senten_num, max_senten_len), dtype='int32')\n",
        "for i, sentences in enumerate(paras):\n",
        "    for j, sent in enumerate(sentences):\n",
        "        if j< max_senten_num:\n",
        "            wordTokens = text_to_word_sequence(sent)\n",
        "            k=0\n",
        "            for _, word in enumerate(wordTokens):\n",
        "                try:\n",
        "                    if k<max_senten_len and tokenizer.word_index[word]<max_features:\n",
        "                        data[i,j,k] = tokenizer.word_index[word]\n",
        "                        k=k+1\n",
        "                except:\n",
        "                    print(word)\n",
        "                    pass"
      ],
      "metadata": {
        "id": "0QqUbo-D_Mk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(sent_lens, bins=200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wdsGl92SKcrx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "fe4f63f2-2671-4248-9254-319c178f5232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_lens"
      ],
      "metadata": {
        "id": "X49qAppeJSaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd1b4fc-1353-42a5-81a8-8bd02ca54c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20,\n",
              " 20,\n",
              " 10,\n",
              " 3,\n",
              " 26,\n",
              " 4,\n",
              " 34,\n",
              " 28,\n",
              " 5,\n",
              " 38,\n",
              " 30,\n",
              " 27,\n",
              " 30,\n",
              " 27,\n",
              " 21,\n",
              " 25,\n",
              " 23,\n",
              " 15,\n",
              " 51,\n",
              " 22,\n",
              " 37,\n",
              " 32,\n",
              " 10,\n",
              " 5,\n",
              " 15,\n",
              " 18,\n",
              " 26,\n",
              " 34,\n",
              " 12,\n",
              " 16,\n",
              " 23,\n",
              " 17,\n",
              " 32,\n",
              " 20,\n",
              " 22,\n",
              " 26,\n",
              " 5,\n",
              " 31,\n",
              " 2,\n",
              " 8,\n",
              " 23,\n",
              " 10,\n",
              " 15,\n",
              " 27,\n",
              " 14,\n",
              " 6,\n",
              " 9,\n",
              " 5,\n",
              " 21,\n",
              " 24,\n",
              " 15,\n",
              " 29,\n",
              " 12,\n",
              " 14,\n",
              " 41,\n",
              " 18,\n",
              " 14,\n",
              " 5,\n",
              " 16,\n",
              " 6,\n",
              " 31,\n",
              " 12,\n",
              " 34,\n",
              " 30,\n",
              " 14,\n",
              " 20,\n",
              " 33,\n",
              " 13,\n",
              " 50,\n",
              " 16,\n",
              " 24,\n",
              " 9,\n",
              " 23,\n",
              " 26,\n",
              " 15,\n",
              " 18,\n",
              " 24,\n",
              " 15,\n",
              " 12,\n",
              " 13,\n",
              " 35,\n",
              " 22,\n",
              " 31,\n",
              " 18,\n",
              " 17,\n",
              " 14,\n",
              " 5,\n",
              " 32,\n",
              " 5,\n",
              " 18,\n",
              " 32,\n",
              " 37,\n",
              " 1,\n",
              " 25,\n",
              " 32,\n",
              " 37,\n",
              " 13,\n",
              " 34,\n",
              " 26,\n",
              " 19,\n",
              " 37,\n",
              " 6,\n",
              " 14,\n",
              " 8,\n",
              " 11,\n",
              " 18,\n",
              " 36,\n",
              " 11,\n",
              " 24,\n",
              " 27,\n",
              " 9,\n",
              " 9,\n",
              " 15,\n",
              " 46,\n",
              " 36,\n",
              " 51,\n",
              " 17,\n",
              " 22,\n",
              " 7,\n",
              " 44,\n",
              " 26,\n",
              " 17,\n",
              " 10,\n",
              " 9,\n",
              " 22,\n",
              " 47,\n",
              " 9,\n",
              " 12,\n",
              " 21,\n",
              " 39,\n",
              " 11,\n",
              " 11,\n",
              " 25,\n",
              " 16,\n",
              " 12,\n",
              " 35,\n",
              " 18,\n",
              " 18,\n",
              " 9,\n",
              " 13,\n",
              " 40,\n",
              " 57,\n",
              " 23,\n",
              " 15,\n",
              " 58,\n",
              " 14,\n",
              " 10,\n",
              " 28,\n",
              " 38,\n",
              " 15,\n",
              " 27,\n",
              " 3,\n",
              " 14,\n",
              " 8,\n",
              " 26,\n",
              " 25,\n",
              " 20,\n",
              " 16,\n",
              " 9,\n",
              " 10,\n",
              " 13,\n",
              " 18,\n",
              " 21,\n",
              " 24,\n",
              " 24,\n",
              " 19,\n",
              " 10,\n",
              " 20,\n",
              " 18,\n",
              " 38,\n",
              " 57,\n",
              " 13,\n",
              " 28,\n",
              " 21,\n",
              " 24,\n",
              " 15,\n",
              " 37,\n",
              " 9,\n",
              " 2,\n",
              " 27,\n",
              " 31,\n",
              " 18,\n",
              " 21,\n",
              " 18,\n",
              " 21,\n",
              " 16,\n",
              " 26,\n",
              " 33,\n",
              " 21,\n",
              " 36,\n",
              " 17,\n",
              " 19,\n",
              " 41,\n",
              " 26,\n",
              " 34,\n",
              " 23,\n",
              " 19,\n",
              " 32,\n",
              " 20,\n",
              " 24,\n",
              " 28,\n",
              " 28,\n",
              " 15,\n",
              " 12,\n",
              " 27,\n",
              " 13,\n",
              " 17,\n",
              " 18,\n",
              " 11,\n",
              " 8,\n",
              " 4,\n",
              " 28,\n",
              " 13,\n",
              " 12,\n",
              " 7,\n",
              " 27,\n",
              " 20,\n",
              " 23,\n",
              " 20,\n",
              " 28,\n",
              " 22,\n",
              " 53,\n",
              " 12,\n",
              " 31,\n",
              " 19,\n",
              " 44,\n",
              " 4,\n",
              " 20,\n",
              " 40,\n",
              " 26,\n",
              " 2,\n",
              " 42,\n",
              " 22,\n",
              " 21,\n",
              " 30,\n",
              " 43,\n",
              " 30,\n",
              " 17,\n",
              " 25,\n",
              " 33,\n",
              " 1,\n",
              " 41,\n",
              " 16,\n",
              " 29,\n",
              " 17,\n",
              " 8,\n",
              " 18,\n",
              " 16,\n",
              " 31,\n",
              " 34,\n",
              " 28,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 21,\n",
              " 24,\n",
              " 10,\n",
              " 18,\n",
              " 23,\n",
              " 27,\n",
              " 4,\n",
              " 7,\n",
              " 70,\n",
              " 13,\n",
              " 10,\n",
              " 13,\n",
              " 21,\n",
              " 16,\n",
              " 28,\n",
              " 18,\n",
              " 9,\n",
              " 14,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 8,\n",
              " 6,\n",
              " 6,\n",
              " 1,\n",
              " 14,\n",
              " 1,\n",
              " 8,\n",
              " 32,\n",
              " 5,\n",
              " 7,\n",
              " 1,\n",
              " 11,\n",
              " 1,\n",
              " 8,\n",
              " 1,\n",
              " 4,\n",
              " 17,\n",
              " 1,\n",
              " 10,\n",
              " 1,\n",
              " 6,\n",
              " 1,\n",
              " 5,\n",
              " 1,\n",
              " 12,\n",
              " 1,\n",
              " 15,\n",
              " 1,\n",
              " 14,\n",
              " 1,\n",
              " 13,\n",
              " 16,\n",
              " 1,\n",
              " 9,\n",
              " 1,\n",
              " 6,\n",
              " 7,\n",
              " 14,\n",
              " 6,\n",
              " 2,\n",
              " 1,\n",
              " 7,\n",
              " 1,\n",
              " 4,\n",
              " 13,\n",
              " 1,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 16,\n",
              " 1,\n",
              " 52,\n",
              " 40,\n",
              " 14,\n",
              " 20,\n",
              " 4,\n",
              " 8,\n",
              " 11,\n",
              " 12,\n",
              " 26,\n",
              " 1,\n",
              " 5,\n",
              " 40,\n",
              " 1,\n",
              " 14,\n",
              " 17,\n",
              " 5,\n",
              " 14,\n",
              " 13,\n",
              " 13,\n",
              " 5,\n",
              " 1,\n",
              " 22,\n",
              " 14,\n",
              " 18,\n",
              " 35,\n",
              " 12,\n",
              " 5,\n",
              " 1,\n",
              " 33,\n",
              " 7,\n",
              " 1,\n",
              " 52,\n",
              " 14,\n",
              " 87,\n",
              " 26,\n",
              " 34,\n",
              " 42,\n",
              " 1,\n",
              " 7,\n",
              " 41,\n",
              " 25,\n",
              " 6,\n",
              " 31,\n",
              " 19,\n",
              " 18,\n",
              " 11,\n",
              " 32,\n",
              " 10,\n",
              " 9,\n",
              " 34,\n",
              " 27,\n",
              " 11,\n",
              " 15,\n",
              " 22,\n",
              " 7,\n",
              " 18,\n",
              " 17,\n",
              " 3,\n",
              " 17,\n",
              " 11,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 11,\n",
              " 33,\n",
              " 10,\n",
              " 22,\n",
              " 9,\n",
              " 22,\n",
              " 28,\n",
              " 36,\n",
              " 23,\n",
              " 1,\n",
              " 26,\n",
              " 1,\n",
              " 24,\n",
              " 16,\n",
              " 17,\n",
              " 12,\n",
              " 1,\n",
              " 16,\n",
              " 11,\n",
              " 6,\n",
              " 6,\n",
              " 8,\n",
              " 19,\n",
              " 1,\n",
              " 28,\n",
              " 1,\n",
              " 10,\n",
              " 14,\n",
              " 10,\n",
              " 12,\n",
              " 6,\n",
              " 18,\n",
              " 20,\n",
              " 8,\n",
              " 22,\n",
              " 18,\n",
              " 19,\n",
              " 15,\n",
              " 12,\n",
              " 8,\n",
              " 8,\n",
              " 14,\n",
              " 1,\n",
              " 41,\n",
              " 26,\n",
              " 1,\n",
              " 19,\n",
              " 7,\n",
              " 1,\n",
              " 15,\n",
              " 31,\n",
              " 1,\n",
              " 39,\n",
              " 16,\n",
              " 22,\n",
              " 34,\n",
              " 22,\n",
              " 9,\n",
              " 30,\n",
              " 1,\n",
              " 6,\n",
              " 16,\n",
              " 8,\n",
              " 1,\n",
              " 40,\n",
              " 1,\n",
              " 39,\n",
              " 30,\n",
              " 27,\n",
              " 7,\n",
              " 1,\n",
              " 20,\n",
              " 26,\n",
              " 25,\n",
              " 12,\n",
              " 1,\n",
              " 5,\n",
              " 17,\n",
              " 8,\n",
              " 26,\n",
              " 30,\n",
              " 17,\n",
              " 1,\n",
              " 23,\n",
              " 30,\n",
              " 1,\n",
              " 21,\n",
              " 18,\n",
              " 33,\n",
              " 8,\n",
              " 8,\n",
              " 18,\n",
              " 1,\n",
              " 70,\n",
              " 9,\n",
              " 13,\n",
              " 14,\n",
              " 25,\n",
              " 13,\n",
              " 19,\n",
              " 3,\n",
              " 11,\n",
              " 24,\n",
              " 9,\n",
              " 1,\n",
              " 37,\n",
              " 27,\n",
              " 8,\n",
              " 4,\n",
              " 22,\n",
              " 24,\n",
              " 8,\n",
              " 15,\n",
              " 12,\n",
              " 23,\n",
              " 1,\n",
              " 8,\n",
              " 62,\n",
              " 1,\n",
              " 60,\n",
              " 21,\n",
              " 4,\n",
              " 27,\n",
              " 1,\n",
              " 35,\n",
              " 5,\n",
              " 7,\n",
              " 1,\n",
              " 21,\n",
              " 20,\n",
              " 1,\n",
              " 17,\n",
              " 14,\n",
              " 23,\n",
              " 38,\n",
              " 11,\n",
              " 14,\n",
              " 1,\n",
              " 16,\n",
              " 7,\n",
              " 1,\n",
              " 15,\n",
              " 1,\n",
              " 6,\n",
              " 34,\n",
              " 1,\n",
              " 22,\n",
              " 1,\n",
              " 37,\n",
              " 14,\n",
              " 12,\n",
              " 11,\n",
              " 1,\n",
              " 21,\n",
              " 32,\n",
              " 5,\n",
              " 9,\n",
              " 1,\n",
              " 8,\n",
              " 7,\n",
              " 3,\n",
              " 17,\n",
              " 1,\n",
              " 9,\n",
              " 26,\n",
              " 17,\n",
              " 7,\n",
              " 25,\n",
              " 8,\n",
              " 19,\n",
              " 9,\n",
              " 1,\n",
              " 8,\n",
              " 18,\n",
              " 32,\n",
              " 27,\n",
              " 27,\n",
              " 23,\n",
              " 1,\n",
              " 80,\n",
              " 16,\n",
              " 23,\n",
              " 1,\n",
              " 9,\n",
              " 6,\n",
              " 52,\n",
              " 1,\n",
              " 21,\n",
              " 5,\n",
              " 3,\n",
              " 1,\n",
              " 6,\n",
              " 31,\n",
              " 15,\n",
              " 39,\n",
              " 37,\n",
              " 9,\n",
              " 20,\n",
              " 23,\n",
              " 31,\n",
              " 18,\n",
              " 34,\n",
              " 6,\n",
              " 12,\n",
              " 8,\n",
              " 32,\n",
              " 22,\n",
              " 27,\n",
              " 11,\n",
              " 4,\n",
              " 18,\n",
              " 32,\n",
              " 27,\n",
              " 48,\n",
              " 34,\n",
              " 27,\n",
              " 15,\n",
              " 29,\n",
              " 7,\n",
              " 17,\n",
              " 14,\n",
              " 35,\n",
              " 31,\n",
              " 20,\n",
              " 22,\n",
              " 37,\n",
              " 6,\n",
              " 9,\n",
              " 27,\n",
              " 14,\n",
              " 27,\n",
              " 24,\n",
              " 39,\n",
              " 56,\n",
              " 4,\n",
              " 18,\n",
              " 2,\n",
              " 25,\n",
              " 54,\n",
              " 32,\n",
              " 23,\n",
              " 19,\n",
              " 10,\n",
              " 11,\n",
              " 7,\n",
              " 20,\n",
              " 42,\n",
              " 22,\n",
              " 24,\n",
              " 59,\n",
              " 31,\n",
              " 30,\n",
              " 38,\n",
              " 25,\n",
              " 29,\n",
              " 13,\n",
              " 8,\n",
              " 26,\n",
              " 35,\n",
              " 60,\n",
              " 17,\n",
              " 23,\n",
              " 40,\n",
              " 20,\n",
              " 23,\n",
              " 45,\n",
              " 2,\n",
              " 20,\n",
              " 9,\n",
              " 19,\n",
              " 7,\n",
              " 20,\n",
              " 18,\n",
              " 5,\n",
              " 5,\n",
              " 36,\n",
              " 13,\n",
              " 11,\n",
              " 23,\n",
              " 21,\n",
              " 26,\n",
              " 22,\n",
              " 30,\n",
              " 10,\n",
              " 25,\n",
              " 36,\n",
              " 6,\n",
              " 17,\n",
              " 13,\n",
              " 4,\n",
              " 32,\n",
              " 16,\n",
              " 8,\n",
              " 18,\n",
              " 14,\n",
              " 16,\n",
              " 13,\n",
              " 8,\n",
              " 18,\n",
              " 5,\n",
              " 8,\n",
              " 11,\n",
              " 5,\n",
              " 29,\n",
              " 20,\n",
              " 11,\n",
              " 23,\n",
              " 4,\n",
              " 13,\n",
              " 11,\n",
              " 3,\n",
              " 29,\n",
              " 35,\n",
              " 34,\n",
              " 25,\n",
              " 17,\n",
              " 46,\n",
              " 20,\n",
              " 26,\n",
              " 6,\n",
              " 8,\n",
              " 25,\n",
              " 11,\n",
              " 22,\n",
              " 27,\n",
              " 24,\n",
              " 23,\n",
              " 24,\n",
              " 15,\n",
              " 42,\n",
              " 11,\n",
              " 17,\n",
              " 37,\n",
              " 31,\n",
              " 29,\n",
              " 37,\n",
              " 26,\n",
              " 26,\n",
              " 31,\n",
              " 28,\n",
              " 46,\n",
              " 23,\n",
              " 23,\n",
              " 10,\n",
              " 10,\n",
              " 22,\n",
              " 15,\n",
              " 24,\n",
              " 43,\n",
              " 6,\n",
              " 32,\n",
              " 40,\n",
              " 15,\n",
              " 17,\n",
              " 33,\n",
              " 6,\n",
              " 19,\n",
              " 23,\n",
              " 22,\n",
              " 8,\n",
              " 7,\n",
              " 24,\n",
              " 14,\n",
              " 19,\n",
              " 17,\n",
              " 1,\n",
              " 177,\n",
              " 42,\n",
              " 20,\n",
              " 32,\n",
              " 18,\n",
              " 5,\n",
              " 26,\n",
              " 17,\n",
              " 34,\n",
              " 34,\n",
              " 28,\n",
              " 9,\n",
              " 27,\n",
              " 29,\n",
              " 30,\n",
              " 18,\n",
              " 12,\n",
              " 13,\n",
              " 33,\n",
              " 49,\n",
              " 22,\n",
              " 48,\n",
              " 12,\n",
              " 5,\n",
              " 29,\n",
              " 23,\n",
              " 13,\n",
              " 47,\n",
              " 17,\n",
              " 14,\n",
              " 33,\n",
              " 23,\n",
              " 43,\n",
              " 30,\n",
              " 16,\n",
              " 17,\n",
              " 40,\n",
              " 9,\n",
              " 6,\n",
              " 9,\n",
              " 9,\n",
              " 3,\n",
              " 8,\n",
              " 21,\n",
              " 16,\n",
              " 8,\n",
              " 22,\n",
              " 9,\n",
              " 37,\n",
              " 11,\n",
              " 37,\n",
              " 15,\n",
              " 31,\n",
              " 66,\n",
              " 51,\n",
              " 28,\n",
              " 31,\n",
              " 21,\n",
              " 15,\n",
              " 4,\n",
              " 28,\n",
              " 33,\n",
              " 20,\n",
              " 17,\n",
              " 5,\n",
              " 8,\n",
              " 11,\n",
              " 17,\n",
              " 7,\n",
              " 6,\n",
              " 6,\n",
              " 19,\n",
              " 10,\n",
              " 7,\n",
              " 5,\n",
              " 12,\n",
              " 26,\n",
              " 12,\n",
              " 24,\n",
              " 4,\n",
              " 23,\n",
              " 7,\n",
              " 9,\n",
              " 7,\n",
              " 4,\n",
              " 47,\n",
              " 19,\n",
              " 14,\n",
              " 19,\n",
              " 15,\n",
              " 26,\n",
              " 18,\n",
              " 16,\n",
              " 28,\n",
              " 18,\n",
              " 15,\n",
              " 11,\n",
              " 26,\n",
              " 12,\n",
              " 42,\n",
              " 45,\n",
              " 17,\n",
              " 29,\n",
              " 19,\n",
              " 27,\n",
              " 30,\n",
              " 40,\n",
              " 24,\n",
              " 16,\n",
              " 46,\n",
              " 4,\n",
              " 32,\n",
              " 37,\n",
              " 47,\n",
              " 50,\n",
              " 26,\n",
              " 21,\n",
              " 16,\n",
              " 19,\n",
              " 11,\n",
              " 68,\n",
              " 46,\n",
              " 18,\n",
              " 7,\n",
              " 2,\n",
              " 25,\n",
              " 14,\n",
              " 30,\n",
              " 31,\n",
              " 49,\n",
              " 22,\n",
              " 34,\n",
              " 21,\n",
              " 6,\n",
              " 18,\n",
              " 29,\n",
              " 28,\n",
              " 6,\n",
              " 12,\n",
              " 25,\n",
              " 13,\n",
              " 14,\n",
              " 25,\n",
              " 35,\n",
              " 12,\n",
              " 16,\n",
              " 24,\n",
              " 5,\n",
              " 9,\n",
              " 5,\n",
              " 8,\n",
              " 7,\n",
              " 8,\n",
              " 3,\n",
              " 5,\n",
              " 6,\n",
              " 25,\n",
              " 23,\n",
              " 10,\n",
              " 7,\n",
              " 6,\n",
              " 13,\n",
              " 4,\n",
              " 6,\n",
              " 22,\n",
              " 7,\n",
              " 60,\n",
              " 13,\n",
              " 14,\n",
              " 11,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 10,\n",
              " 34,\n",
              " 5,\n",
              " 21,\n",
              " 49,\n",
              " 2,\n",
              " 5,\n",
              " 6,\n",
              " 2,\n",
              " 42,\n",
              " 11,\n",
              " 4,\n",
              " 8,\n",
              " 10,\n",
              " 13,\n",
              " 33,\n",
              " 6,\n",
              " 17,\n",
              " 16,\n",
              " 24,\n",
              " 14,\n",
              " 28,\n",
              " 7,\n",
              " 8,\n",
              " 4,\n",
              " 5,\n",
              " 12,\n",
              " 14,\n",
              " 6,\n",
              " 5,\n",
              " 38,\n",
              " 10,\n",
              " 15,\n",
              " 52,\n",
              " 15,\n",
              " 23,\n",
              " 18,\n",
              " 31,\n",
              " 26,\n",
              " 13,\n",
              " 18,\n",
              " 10,\n",
              " 54,\n",
              " 32,\n",
              " 50,\n",
              " 30,\n",
              " 60,\n",
              " 26,\n",
              " 9,\n",
              " 32,\n",
              " 17,\n",
              " 6,\n",
              " 5,\n",
              " 11,\n",
              " 13,\n",
              " 14,\n",
              " 9,\n",
              " 60,\n",
              " 19,\n",
              " 16,\n",
              " 11,\n",
              " 23,\n",
              " 30,\n",
              " 6,\n",
              " 7,\n",
              " 16,\n",
              " 16,\n",
              " 14,\n",
              " 38,\n",
              " 22,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDILNjmxK6ZQ",
        "outputId": "20eb1997-efaa-4f3c-fe4f-2494a87b20d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 6, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Total %s unique tokens.' % len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMsaPY3vK-fe",
        "outputId": "f4d3d2e8-ca48-4f20-a514-387122f9e7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 17560 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.get_dummies(df[\"target\"])\n",
        "# labels = df[\"target\"]"
      ],
      "metadata": {
        "id": "qcsD-akXLBU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fea_st_col = df.iloc[:, 10:10 + 14 + 13].columns\n",
        "fea_sen_col = df.iloc[:, 10 + 14 + 13 + 6:10 + 14 + 13 + 6 + 19].columns\n",
        "union_cols = fea_st_col.union(fea_sen_col)"
      ],
      "metadata": {
        "id": "KYZmASmucTrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_feature_array = df[union_cols]"
      ],
      "metadata": {
        "id": "nFJpXzmENN9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of labels tensor:', labels.shape)\n",
        "print('Shape of sample_feature_array tensor:', sample_feature_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfPelUK8LNfI",
        "outputId": "83bc6fd1-98c0-47b7-bc59-03e88d8e38ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (312, 6, 40)\n",
            "Shape of labels tensor: (312, 2)\n",
            "Shape of sample_feature_array tensor: (312, 46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(data.shape[0])"
      ],
      "metadata": {
        "id": "PoHLCeqOPGQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[indices]"
      ],
      "metadata": {
        "id": "2RwrMU1dVMxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEwADdziVSUF",
        "outputId": "424313de-dffe-426e-9c3a-44baf99863a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 6, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test, f_train, f_test = train_test_split(data, df['target'], sample_feature_array, test_size= .15, random_state= 111, stratify= df['target'] )\n",
        "x_train, x_val, y_train, y_val, f_train, f_val= train_test_split(x_train, y_train,f_train, test_size= .10, random_state= 111, stratify= None )"
      ],
      "metadata": {
        "id": "D_IRCpwDXS1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "xWSKwOCPUd7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0417aa5-2e9f-489f-88bd-db397b5c11c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 459,  113, 1237, ...,    0,    0,    0],\n",
              "        [  41,   74,   51, ...,    0,    0,    0],\n",
              "        [  17,  838,  113, ...,    0,    0,    0],\n",
              "        [   2, 2521,   22, ...,    0,    0,    0],\n",
              "        [2327,   41,   10, ...,    0,    0,    0],\n",
              "        [   2,  113, 1237, ...,    0,    0,    0]],\n",
              "\n",
              "       [[  30,    2,  459, ...,    0,    0,    0],\n",
              "        [ 108,   18,    2, ...,    0,    0,    0],\n",
              "        [1979, 7061,    2, ...,    0,    0,    0],\n",
              "        [ 334, 1219, 6066, ...,    0,    0,    0],\n",
              "        [   2, 1955, 1276, ...,    0,    0,    0],\n",
              "        [ 225,  354, 1715, ...,    0,    0,    0]],\n",
              "\n",
              "       [[ 313,  280, 6323, ...,    7,    2, 5269],\n",
              "        [ 745,   28,    2, ...,    0,    0,    0],\n",
              "        [   2, 4093, 3703, ...,    0,    0,    0],\n",
              "        [  57,  538,   30, ...,    0,    0,    0],\n",
              "        [ 258,    6,  313, ...,    0,    0,    0],\n",
              "        [  57, 1497, 3762, ...,    7, 3703,   32]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[  37,  326, 3922, ...,    0,    0,    0],\n",
              "        [7612, 7613,    0, ...,    0,    0,    0],\n",
              "        [  58,    5,    2, ...,    0,    0,    0],\n",
              "        [  26,   20,  152, ...,    0,    0,    0],\n",
              "        [  11,  327,   24, ...,    0,    0,    0],\n",
              "        [  41,  197,  914, ...,    0,    0,    0]],\n",
              "\n",
              "       [[1354,    3, 6277, ...,    0,    0,    0],\n",
              "        [4152,  127, 2295, ...,    0,    0,    0],\n",
              "        [  17, 2634,  180, ...,    0,    0,    0],\n",
              "        [ 632, 2443, 1100, ...,    0,    0,    0],\n",
              "        [ 189,   41,  747, ...,    0,    0,    0],\n",
              "        [ 340,   84,  105, ...,    0,    0,    0]],\n",
              "\n",
              "       [[ 268, 1536,  143, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0]]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFICaSJVXXrM",
        "outputId": "fc016998-57b4-4011-d987-20f61ae58f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(238, 6, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train, x_test, y_train, y_test = train_test_split(data, df['target'], test_size= .15, random_state= 111, stratify= None )\n",
        "# x_train, x_val, y_train, y_val= train_test_split(x_train, y_train, test_size= .10, random_state= 111, stratify= None )\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "# np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels.iloc[indices]\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_val = data[-nb_validation_samples:]\n",
        "y_val = labels[-nb_validation_samples:]\n",
        "print('Number of positive and negative reviews in traing and validation set')\n",
        "f_train = sample_feature_array[:-nb_validation_samples]\n",
        "f_val = sample_feature_array[-nb_validation_samples:]\n",
        "# print(y_train.columns.tolist())\n",
        "# print(y_train.sum(axis=0).tolist())\n",
        "# print(y_val.sum(axis=0).tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YgxADbELQ9C",
        "outputId": "d969666b-662b-4b28-dd63-4f0cf9d665bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive and negative reviews in traing and validation set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "id": "SoGZdSmTUYHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02399915-85d7-4169-a187-6561ad739bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4658,   14,  300,  241,  263,  209, 1286,  766,   14, 1049,   16,\n",
              "           2,  416,  428,  766,    3,  554,   16,  263,  209,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [  17,  147,  146,    5,    2,  416,  173, 1256,   14,   14,  107,\n",
              "          18,   16,    2, 2324,   34,  100, 4658,   14,  300,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [1497,   46,  475,   45, 1066, 1629,   12,   17,  263, 1433,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [ 475,   45, 1066,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_train = sample_feature_array[:-nb_validation_samples]\n",
        "f_val = sample_feature_array[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "uTVmqysyNi0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHgrkpQQNx-m",
        "outputId": "92a236e0-5e65-430d-e4c1-33e74d86faf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62, 46)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val"
      ],
      "metadata": {
        "id": "yXDfTj0Bc3pr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "ae95d5e0-d277-4048-ea09-b96552751754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0  1\n",
              "id                   \n",
              "politifact15371  1  0\n",
              "politifact13132  0  1\n",
              "politifact15187  1  0\n",
              "politifact14289  1  0\n",
              "politifact8152   0  1\n",
              "...             .. ..\n",
              "politifact7511   0  1\n",
              "politifact160    0  1\n",
              "politifact13443  0  1\n",
              "politifact14003  1  0\n",
              "politifact10903  0  1\n",
              "\n",
              "[62 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-674b400b-f09c-4502-95fe-f0903ca38a63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>politifact15371</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact13132</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact15187</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14289</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact8152</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact7511</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact160</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact13443</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14003</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10903</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-674b400b-f09c-4502-95fe-f0903ca38a63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-674b400b-f09c-4502-95fe-f0903ca38a63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-674b400b-f09c-4502-95fe-f0903ca38a63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHrHxoEJBppV",
        "outputId": "cd0883a8-8859-4da1-a2fc-3f5bd6f92335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250, 6, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWXGDpyDKVta",
        "outputId": "7b9f74a0-a94f-497a-c6a1-fd01c3f019e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Uj3qHChMcPYs",
        "outputId": "55cd185f-1e7c-48fa-be4f-539690c71f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0  1\n",
              "id                   \n",
              "politifact720    0  1\n",
              "politifact10731  0  1\n",
              "politifact11115  0  1\n",
              "politifact14148  1  0\n",
              "politifact6932   0  1\n",
              "...             .. ..\n",
              "politifact7511   0  1\n",
              "politifact160    0  1\n",
              "politifact13443  0  1\n",
              "politifact14003  1  0\n",
              "politifact10903  0  1\n",
              "\n",
              "[312 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-018ff41d-512c-45ef-8f6f-cee9f34b9df1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>politifact720</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10731</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact11115</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14148</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact6932</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact7511</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact160</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact13443</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14003</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10903</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>312 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-018ff41d-512c-45ef-8f6f-cee9f34b9df1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-018ff41d-512c-45ef-8f6f-cee9f34b9df1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-018ff41d-512c-45ef-8f6f-cee9f34b9df1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REG_PARAM = 1e-13\n",
        "l2_reg = regularizers.l2(REG_PARAM)"
      ],
      "metadata": {
        "id": "A3A4j8FaLcHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n"
      ],
      "metadata": {
        "id": "VASyRsA6pJ3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip glove*.zip\n"
      ],
      "metadata": {
        "id": "LPe1rsbzp0VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GLOVE_DIR = \"/content/drive/MyDrive/glove.6B.100d.txt\"\n",
        "embeddings_index = {}\n",
        "f = open(GLOVE_DIR)\n",
        "for line in f:\n",
        "    try:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = values[1:]\n",
        "        # coefs = np.asarray(y, dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    except:\n",
        "        print(\"except\")\n",
        "        print(word)\n",
        "        pass\n",
        "f.close()\n",
        "print('Total %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTYXTLsvLhhY",
        "outputId": "83f93311-f66f-4a5f-efa4-f3a34e3b56aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KF6l9fw4Apm",
        "outputId": "5faeb86b-1106-482c-d61a-b783532c5c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
        "absent_words = 0\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        absent_words += 1\n",
        "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7ZTdhVvq9OX",
        "outputId": "441d8e04-5db9-425b-9bdc-b2cd7330a571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total absent words are 978 which is 5.57 % of total words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1,embed_size,weights=[embedding_matrix], input_length=max_senten_len, trainable=False)"
      ],
      "metadata": {
        "id": "bFMWX8BO4xbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.engine.topology import Layer\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "\n",
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "class AttentionWithContext(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, context_vector_length = 1000, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.context_vector_length = context_vector_length\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "        print('{}_W'.format(self.name))\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'context_vector_length': self.context_vector_length\n",
        "        }\n",
        "        base_config = super(AttentionWithContext, self).get_config()\n",
        "        return {**base_config, **config}\n"
      ],
      "metadata": {
        "id": "OCFoIfaU5FPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_input = Input(shape=(max_senten_len,), dtype='float32')\n",
        "word_sequences = embedding_layer(word_input)\n",
        "embeding_dim = 256\n",
        "word_lstm = Bidirectional(GRU(embeding_dim, return_sequences=True, kernel_regularizer=l2_reg))(word_sequences)\n",
        "word_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(word_lstm)\n",
        "word_att = AttentionWithContext()(word_dense)\n",
        "wordEncoder = Model(word_input, word_att)\n",
        "\n",
        "sent_input = Input(shape=(max_senten_num, max_senten_len), dtype='float32')\n",
        "sent_encoder = TimeDistributed(wordEncoder)(sent_input)\n",
        "sent_lstm = Bidirectional(GRU(embeding_dim, return_sequences=True, kernel_regularizer=l2_reg))(sent_encoder)\n",
        "sent_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(sent_lstm)\n",
        "sent_att = Dropout(0.2)(AttentionWithContext()(sent_dense))\n",
        "# sentEncoder = Model(sent_input, sent_att)\n",
        "# preds = Dense(2, activation='sigmoid')(sent_att)\n",
        "dense_cat = Dense(128, activation='relu')(sent_att)\n",
        "# dense_cat shape == feature.shape 1 dim will be diff and rest same. \n",
        "feature_input = Input(shape=f_train.shape[1], dtype='float64', name='text')\n",
        "# fea_encoder = TimeDistributed(sent_encoder)(text_input)\n",
        "\n",
        "# embedded_text = tf.keras.layers.Embedding(64, len(f_train))(text_input)\n",
        "# encoded_feature = tf.keras.layers.LSTM(64)(feature_input)\n",
        "#shape of feature vector\n",
        "# feature_input = Input(shape=(sample_feature_array.shape), dtype='float64')\n",
        "# feature_encoder = tf.keras.layers.TimeDistributed(sample_feature_array)(feature_input)\n",
        "\n",
        "# feature_encoder = TimeDistributed(sample_feature_array)(feature_input)\n",
        "# feature_lstm = Bidirectional(LSTM(embeding_dim, return_sequences=True, kernel_regularizer=l2_reg))(feature_encoder)\n",
        "# feature_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(feature_lstm)\n",
        "# feature_att = Dropout(0.5)(AttentionWithContext()(feature_dense))\n",
        "# merged = tf.keras.layers.concatenate([encoded_feature, dense_cat],axis=-1)\n",
        "merged = tf.keras.layers.Concatenate(axis=1)([feature_input, dense_cat])\n",
        "\n",
        "preds = tf.keras.layers.Dense(2, activation='softmax')(merged)\n",
        "# merged = tf.keras.layers.concatenate([dense_cat, feature_input])\n",
        "\n",
        "# preds = Dense(2, activation='sigmoid')(concatenated)\n",
        "\n",
        "model = Model([sent_input, feature_input], preds)\n",
        "# model = Model(preds, sent_input, text_input)\n",
        "# model.add(GlobalAveragePooling2D())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTdtECWZ41N_",
        "outputId": "e5af5b93-5e98-4160-ee9b-cfc09bcf4766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_with_context_4_W\n",
            "attention_with_context_5_W\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(1e-3),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "d3dluKpHAeq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKTPlbry_t6u",
        "outputId": "e4887d6b-7e33-4858-98b6-c7eba93b5dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 6, 40)]      0           []                               \n",
            "                                                                                                  \n",
            " time_distributed_7 (TimeDistri  (None, 6, 200)      2448988     ['input_6[0][0]']                \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " bidirectional_5 (Bidirectional  (None, 6, 512)      703488      ['time_distributed_7[0][0]']     \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " time_distributed_8 (TimeDistri  (None, 6, 200)      102600      ['bidirectional_5[0][0]']        \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " attention_with_context_5 (Atte  (None, 200)         40400       ['time_distributed_8[0][0]']     \n",
            " ntionWithContext)                                                                                \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 200)          0           ['attention_with_context_5[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " text (InputLayer)              [(None, 46)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 128)          25728       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 174)          0           ['text[0][0]',                   \n",
            "                                                                  'dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 2)            350         ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,321,554\n",
            "Trainable params: 1,565,454\n",
            "Non-trainable params: 1,756,100\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "metadata": {
        "id": "0Brmua8v9SSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.MinMaxScaler()\n",
        "f_train_transform = scaler.fit_transform(f_train)\n",
        "f_val_transform = scaler.fit_transform(f_val)\n",
        "f_test_transform = scaler.fit_transform(f_test)"
      ],
      "metadata": {
        "id": "6u6c8oDC3VCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_train_arr = [x_train, f_train_transform]\n",
        "merged_val_arr = [x_val, f_val_transform]\n",
        "# merged_test_arr = [x_test, f_test_transform]"
      ],
      "metadata": {
        "id": "bKSJz_AKYMfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_val_arr"
      ],
      "metadata": {
        "id": "epoBuEEoX9My",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef36cb9-d771-4016-9368-57a13eaac467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[  61,   41,    4, ...,    5,  210,  101],\n",
              "         [   6,  478,  101, ...,    0,    0,    0],\n",
              "         [   2, 2071, 1636, ...,   21,    8,  214],\n",
              "         [ 255,   84,   18, ...,   14,  710, 2657],\n",
              "         [   3,   15,    6, ...,    0,    0,    0],\n",
              "         [  20,  785,    2, ...,    0,    0,    0]],\n",
              " \n",
              "        [[ 267,  569,   10, ...,    0,    0,    0],\n",
              "         [   8,    6,  708, ...,    0,    0,    0],\n",
              "         [ 267,  569,   83, ...,    0,    0,    0],\n",
              "         [  11, 4530,  222, ...,    0,    0,    0],\n",
              "         [  11,  559,    2, ...,    0,    0,    0],\n",
              "         [ 637,   17, 3437, ...,    0,    0,    0]],\n",
              " \n",
              "        [[ 384, 5295,  264, ...,    0,    0,    0],\n",
              "         [1164,  287, 5661, ...,    0,    0,    0],\n",
              "         [ 758,  234,   23, ...,    0,    0,    0],\n",
              "         [ 104,    2, 2656, ...,    8,  225,  129],\n",
              "         [ 267,  376, 3415, ...,    0,    0,    0],\n",
              "         [ 153,   55,   10, ...,    0,    0,    0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 268, 1536,  143, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0]],\n",
              " \n",
              "        [[6330,    4,   40, ...,    0,    0,    0],\n",
              "         [ 980, 1790, 2466, ...,  330, 5890, 3105],\n",
              "         [   2,  488, 1404, ...,    0,    0,    0],\n",
              "         [ 367,    3, 1846, ...,    0,    0,    0],\n",
              "         [ 255, 2928,    3, ...,    0,    0,    0],\n",
              "         [1781,    5,   52, ...,    0,    0,    0]],\n",
              " \n",
              "        [[  71,  479,    0, ...,    0,    0,    0],\n",
              "         [  13, 2219,   62, ...,    0,    0,    0],\n",
              "         [1791,    8, 2104, ...,    0,    0,    0],\n",
              "         [ 637,    6, 1796, ...,    0,    0,    0],\n",
              "         [   2,  488, 1172, ...,    0,    0,    0],\n",
              "         [   2,  242,   10, ...,    0,    0,    0]]], dtype=int32),\n",
              " array([[1.00000000e+00, 5.71428571e-01, 3.74462527e-02, ...,\n",
              "         6.27576689e-04, 1.44302679e-04, 1.37205194e-03],\n",
              "        [6.25000000e-01, 0.00000000e+00, 1.57840309e-03, ...,\n",
              "         6.15974338e-03, 1.01495855e-04, 0.00000000e+00],\n",
              "        [5.00000000e-01, 5.71428571e-01, 7.31508191e-02, ...,\n",
              "         2.15213399e-05, 1.14072932e-04, 3.02124371e-03],\n",
              "        ...,\n",
              "        [2.50000000e-01, 1.42857143e-01, 1.90496925e-03, ...,\n",
              "         1.05929461e-02, 9.28509627e-04, 0.00000000e+00],\n",
              "        [3.75000000e-01, 2.85714286e-01, 4.68078158e-03, ...,\n",
              "         3.74990619e-04, 5.66563962e-04, 2.51554476e-03],\n",
              "        [3.75000000e-01, 0.00000000e+00, 4.02764927e-03, ...,\n",
              "         3.85428318e-04, 1.01723657e-04, 0.00000000e+00]])]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "berthist = model.fit(merged_train_arr, y_train, validation_data= (merged_val_arr, y_val), epochs=100, batch_size=64, verbose=1, callbacks=[earlyStopping, mcp_save])\n",
        "print(time.time()-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJQ4mHZY9Wlt",
        "outputId": "2328eae0-6f25-4745-fa6f-9a4eff214e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 17s 2s/step - loss: 0.7559 - accuracy: 0.4480 - val_loss: 0.7466 - val_accuracy: 0.4355\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.7243 - accuracy: 0.4320 - val_loss: 0.7267 - val_accuracy: 0.4355\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.7007 - accuracy: 0.5000 - val_loss: 0.7001 - val_accuracy: 0.4839\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.6867 - accuracy: 0.5840 - val_loss: 0.6624 - val_accuracy: 0.5484\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.6917 - accuracy: 0.5640 - val_loss: 0.5905 - val_accuracy: 0.6452\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.6413 - accuracy: 0.6240 - val_loss: 0.5667 - val_accuracy: 0.6774\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.5708 - accuracy: 0.6960 - val_loss: 0.5760 - val_accuracy: 0.6774\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.5049 - accuracy: 0.7680 - val_loss: 0.4986 - val_accuracy: 0.8387\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.4542 - accuracy: 0.7960 - val_loss: 0.5016 - val_accuracy: 0.7419\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.4152 - accuracy: 0.8120 - val_loss: 0.5966 - val_accuracy: 0.7903\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.4025 - accuracy: 0.8240 - val_loss: 0.4622 - val_accuracy: 0.8226\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.3451 - accuracy: 0.8480 - val_loss: 0.5226 - val_accuracy: 0.8065\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.3150 - accuracy: 0.8600 - val_loss: 0.4556 - val_accuracy: 0.8548\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.2735 - accuracy: 0.8760 - val_loss: 0.4833 - val_accuracy: 0.8871\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.2309 - accuracy: 0.8920 - val_loss: 0.5433 - val_accuracy: 0.8871\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.1925 - accuracy: 0.9160 - val_loss: 0.6038 - val_accuracy: 0.8548\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.1542 - accuracy: 0.9200 - val_loss: 0.8798 - val_accuracy: 0.7258\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.1821 - accuracy: 0.9040 - val_loss: 0.7587 - val_accuracy: 0.8548\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.1890 - accuracy: 0.9080 - val_loss: 1.1494 - val_accuracy: 0.7581\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.1121 - accuracy: 0.9560 - val_loss: 0.9013 - val_accuracy: 0.8710\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.1304 - accuracy: 0.9520 - val_loss: 1.0647 - val_accuracy: 0.8710\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0899 - accuracy: 0.9600 - val_loss: 1.1388 - val_accuracy: 0.8065\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0941 - accuracy: 0.9560 - val_loss: 1.2597 - val_accuracy: 0.8548\n",
            "113.72260594367981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"/content/drive/MyDrive/fake_bert/HAN_model_finetune\""
      ],
      "metadata": {
        "id": "FNpV1wmG9zlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, file_name)"
      ],
      "metadata": {
        "id": "OvIGjJmi91u_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8d863a-86db-48d3-838d-f82aac200c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_16_layer_call_fn, gru_cell_16_layer_call_and_return_conditional_losses, gru_cell_17_layer_call_fn, gru_cell_17_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hanModel_pred = model.predict([x_val, f_val])\n",
        "# hanLayerModel_y = np.argmax(hanModel_pred, axis = 1)\n",
        "# hanLayerModel_y\n",
        "\n",
        "hanModel_pred = model.predict(merged_val_arr)\n",
        "hanLayerModel_y = np.argmax(hanModel_pred, axis = 1)\n",
        "hanLayerModel_y"
      ],
      "metadata": {
        "id": "ieyew1Lx95CW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35fa447-5b37-4342-fe23-b726a9d37fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 212ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(hanLayerModel_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC537jmrbkxN",
        "outputId": "a248ba2e-ea31-4430-8c22-b8a482b7774e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_val[1].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUiTQoWzOy4i",
        "outputId": "d199b12c-54ab-40e6-ab46-2b84b877d403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy:', accuracy_score(hanLayerModel_y, y_val[1].values))\n",
        "print('F1 score:', f1_score(y_val[1].values, hanLayerModel_y))\n",
        "print('Recall:', recall_score(np.array(y_val[1]), hanLayerModel_y))\n",
        "print('Precision:', precision_score(np.array(y_val[1]), hanLayerModel_y))\n",
        "print('ROC_AUC Score:', roc_auc_score(np.array(y_val[1]), hanLayerModel_y))\n",
        "\n",
        "print(classification_report(np.array(y_val[1]), hanLayerModel_y))"
      ],
      "metadata": {
        "id": "OkY6U1nP99ZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b32fbd8-26df-42d1-acde-6d13ba95a8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8548387096774194\n",
            "F1 score: 0.8615384615384615\n",
            "Recall: 0.875\n",
            "Precision: 0.8484848484848485\n",
            "ROC_AUC Score: 0.8541666666666666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.83      0.85        30\n",
            "           1       0.85      0.88      0.86        32\n",
            "\n",
            "    accuracy                           0.85        62\n",
            "   macro avg       0.86      0.85      0.85        62\n",
            "weighted avg       0.86      0.85      0.85        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hanLayerModel_y"
      ],
      "metadata": {
        "id": "elvBAVSnOr7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28881d5-db15-4bbf-a00c-17b1521ee5c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    }
  ]
}
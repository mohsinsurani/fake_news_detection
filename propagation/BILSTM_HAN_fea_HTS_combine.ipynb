{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgupxXAn-5HF",
        "outputId": "b4a88cc0-b141-4893-b1ab-48b2916410ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import sys\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from keras import Sequential, regularizers \n",
        "\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras import losses\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten, InputLayer\n",
        "\n",
        "import time\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import torch\n",
        "from sklearn.metrics import precision_score, \\\n",
        "    recall_score, confusion_matrix, classification_report, \\\n",
        "    accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn import metrics\n",
        "import plotly.express as px\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer,  text_to_word_sequence\n",
        "# from keras.engine.topology import Layer\n",
        "from keras import initializers as initializers, regularizers, constraints\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Embedding, Input, Dense, LSTM, GRU, Bidirectional, TimeDistributed, Dropout\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.models import Model\n",
        "from nltk import tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_df = \"/content/drive/MyDrive/fake_bert/politifact_global_feature.pkl\""
      ],
      "metadata": {
        "id": "BxH344MZ_D_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pickle.load(open(path_df, \"rb\"))"
      ],
      "metadata": {
        "id": "AOIr3tZp_J-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "b5z39z9wJkPK",
        "outputId": "f992414c-dc2f-44f7-da63-72be32e966cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                              text  \\\n",
              "id                                                                   \n",
              "politifact720    Organizing for ’18\\n\\nThrough Election Day\\n\\n...   \n",
              "politifact10731  COLUMBUS, Ohio — America's role as a world lea...   \n",
              "politifact11115  In the course of the email review, State Depar...   \n",
              "politifact14148  We all get lazy from time to time and just wan...   \n",
              "politifact6932   Mitt Romney came to coal country on Aug. 14, s...   \n",
              "\n",
              "                                                             title  \\\n",
              "id                                                                   \n",
              "politifact720                                Organizing for Action   \n",
              "politifact10731  Call 'Islamic terrorism' what it is: a threat ...   \n",
              "politifact11115   Inquiry Sought in Hillary Clinton’s Use of Email   \n",
              "politifact14148  NASA Will Pay You 18000 USD To Stay In Bed And...   \n",
              "politifact6932   Barack Obama says Mitt Romney condemned coal-f...   \n",
              "\n",
              "                                                           top_img  \\\n",
              "id                                                                   \n",
              "politifact720    https://secure.assets.bostatic.com/apps/quincy...   \n",
              "politifact10731  http://triblive.com/csp/mediapool/sites/dt.com...   \n",
              "politifact11115  https://static01.nyt.com/images/2015/07/24/us/...   \n",
              "politifact14148  http://reflectionofmind.org/wp-content/uploads...   \n",
              "politifact6932   http://static.politifact.com.s3.amazonaws.com/...   \n",
              "\n",
              "                 publish_date  \\\n",
              "id                              \n",
              "politifact720            None   \n",
              "politifact10731  1429079762.0   \n",
              "politifact11115  1437721200.0   \n",
              "politifact14148  1482942009.0   \n",
              "politifact6932   1345705200.0   \n",
              "\n",
              "                                                            images  \\\n",
              "id                                                                   \n",
              "politifact720    [https://secure.assets.bostatic.com/apps/quinc...   \n",
              "politifact10731  [http://triblive.com/csp/mediapool/sites/TribL...   \n",
              "politifact11115  [https://static01.nyt.com/images/2015/07/24/us...   \n",
              "politifact14148  [http://reflectionofmind.org/wp-content/upload...   \n",
              "politifact6932   [http://metric.politifact.com/b/ss/spttbglobal...   \n",
              "\n",
              "                     source  target  \\\n",
              "id                                    \n",
              "politifact720    politifact       1   \n",
              "politifact10731  politifact       1   \n",
              "politifact11115  politifact       1   \n",
              "politifact14148  politifact       0   \n",
              "politifact6932   politifact       1   \n",
              "\n",
              "                                                         tweet_mod  \\\n",
              "id                                                                   \n",
              "politifact720    [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "politifact10731  [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "politifact11115  [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "politifact14148  [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "politifact6932   [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "\n",
              "                                                         comp_text  \\\n",
              "id                                                                   \n",
              "politifact720    Organizing for 18 Through Election Day Sometim...   \n",
              "politifact10731  COLUMBUS Ohio America's role as a world leader...   \n",
              "politifact11115  In the course of the email review State Depart...   \n",
              "politifact14148  We all get lazy from time to time and just wan...   \n",
              "politifact6932   Mitt Romney came to coal country on Aug. 14 st...   \n",
              "\n",
              "                                                          lem_text  ...  \\\n",
              "id                                                                  ...   \n",
              "politifact720    organize for 18 through election day sometimes...  ...   \n",
              "politifact10731  columbus ohio americas role a a world leader a...  ...   \n",
              "politifact11115  in the course of the email review state depart...  ...   \n",
              "politifact14148  we all get lazy from time to time and just wan...  ...   \n",
              "politifact6932   mitt romney come to coal country on aug 14 sta...  ...   \n",
              "\n",
              "                    Sen15     Sen16     Sen17     Sen18     Sen19        G1  \\\n",
              "id                                                                            \n",
              "politifact720    0.949437  0.034845  0.071476  1.681818  0.011628  0.012289   \n",
              "politifact10731  0.694333  0.000000 -0.738400  1.250000  0.041667  0.046498   \n",
              "politifact11115  0.778346  0.012754 -0.472698  1.156863  0.000543  0.000609   \n",
              "politifact14148  0.829039  0.098993  0.134468  1.240000  0.000836  0.000885   \n",
              "politifact6932   0.642184  0.016658 -0.765808  1.000000  0.025000  0.025214   \n",
              "\n",
              "                     G2      G3            G4      G5  \n",
              "id                                                     \n",
              "politifact720      79.0    86.0  1.866903e-04    85.0  \n",
              "politifact10731    20.0    24.0  3.071834e-03    23.0  \n",
              "politifact11115  1673.0  1842.0  5.721557e-07  1841.0  \n",
              "politifact14148  1089.0  1196.0  1.024639e-06  1195.0  \n",
              "politifact6932     38.0    40.0  6.738988e-04    39.0  \n",
              "\n",
              "[5 rows x 67 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f7e0b4c-c0d9-4dc0-9c61-97367404e4d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>top_img</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>images</th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>tweet_mod</th>\n",
              "      <th>comp_text</th>\n",
              "      <th>lem_text</th>\n",
              "      <th>...</th>\n",
              "      <th>Sen15</th>\n",
              "      <th>Sen16</th>\n",
              "      <th>Sen17</th>\n",
              "      <th>Sen18</th>\n",
              "      <th>Sen19</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "      <th>G4</th>\n",
              "      <th>G5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>politifact720</th>\n",
              "      <td>Organizing for ’18\\n\\nThrough Election Day\\n\\n...</td>\n",
              "      <td>Organizing for Action</td>\n",
              "      <td>https://secure.assets.bostatic.com/apps/quincy...</td>\n",
              "      <td>None</td>\n",
              "      <td>[https://secure.assets.bostatic.com/apps/quinc...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>Organizing for 18 Through Election Day Sometim...</td>\n",
              "      <td>organize for 18 through election day sometimes...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.949437</td>\n",
              "      <td>0.034845</td>\n",
              "      <td>0.071476</td>\n",
              "      <td>1.681818</td>\n",
              "      <td>0.011628</td>\n",
              "      <td>0.012289</td>\n",
              "      <td>79.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>1.866903e-04</td>\n",
              "      <td>85.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10731</th>\n",
              "      <td>COLUMBUS, Ohio — America's role as a world lea...</td>\n",
              "      <td>Call 'Islamic terrorism' what it is: a threat ...</td>\n",
              "      <td>http://triblive.com/csp/mediapool/sites/dt.com...</td>\n",
              "      <td>1429079762.0</td>\n",
              "      <td>[http://triblive.com/csp/mediapool/sites/TribL...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>COLUMBUS Ohio America's role as a world leader...</td>\n",
              "      <td>columbus ohio americas role a a world leader a...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.694333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.738400</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.046498</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3.071834e-03</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact11115</th>\n",
              "      <td>In the course of the email review, State Depar...</td>\n",
              "      <td>Inquiry Sought in Hillary Clinton’s Use of Email</td>\n",
              "      <td>https://static01.nyt.com/images/2015/07/24/us/...</td>\n",
              "      <td>1437721200.0</td>\n",
              "      <td>[https://static01.nyt.com/images/2015/07/24/us...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>In the course of the email review State Depart...</td>\n",
              "      <td>in the course of the email review state depart...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.778346</td>\n",
              "      <td>0.012754</td>\n",
              "      <td>-0.472698</td>\n",
              "      <td>1.156863</td>\n",
              "      <td>0.000543</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>1673.0</td>\n",
              "      <td>1842.0</td>\n",
              "      <td>5.721557e-07</td>\n",
              "      <td>1841.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14148</th>\n",
              "      <td>We all get lazy from time to time and just wan...</td>\n",
              "      <td>NASA Will Pay You 18000 USD To Stay In Bed And...</td>\n",
              "      <td>http://reflectionofmind.org/wp-content/uploads...</td>\n",
              "      <td>1482942009.0</td>\n",
              "      <td>[http://reflectionofmind.org/wp-content/upload...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>We all get lazy from time to time and just wan...</td>\n",
              "      <td>we all get lazy from time to time and just wan...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.829039</td>\n",
              "      <td>0.098993</td>\n",
              "      <td>0.134468</td>\n",
              "      <td>1.240000</td>\n",
              "      <td>0.000836</td>\n",
              "      <td>0.000885</td>\n",
              "      <td>1089.0</td>\n",
              "      <td>1196.0</td>\n",
              "      <td>1.024639e-06</td>\n",
              "      <td>1195.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact6932</th>\n",
              "      <td>Mitt Romney came to coal country on Aug. 14, s...</td>\n",
              "      <td>Barack Obama says Mitt Romney condemned coal-f...</td>\n",
              "      <td>http://static.politifact.com.s3.amazonaws.com/...</td>\n",
              "      <td>1345705200.0</td>\n",
              "      <td>[http://metric.politifact.com/b/ss/spttbglobal...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>Mitt Romney came to coal country on Aug. 14 st...</td>\n",
              "      <td>mitt romney come to coal country on aug 14 sta...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.642184</td>\n",
              "      <td>0.016658</td>\n",
              "      <td>-0.765808</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.025214</td>\n",
              "      <td>38.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>6.738988e-04</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 67 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f7e0b4c-c0d9-4dc0-9c61-97367404e4d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f7e0b4c-c0d9-4dc0-9c61-97367404e4d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f7e0b4c-c0d9-4dc0-9c61-97367404e4d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_lens = []\n",
        "sent_nums = []\n",
        "texts = []\n",
        "paras = []\n",
        "\n",
        "for idx in range(df[\"comp_text\"].shape[0]):\n",
        "    text = df[\"comp_text\"][idx]\n",
        "    texts.append(text)\n",
        "    sentences = tokenize.sent_tokenize(text)\n",
        "    sent_nums.append(len(sentences))\n",
        "    for sent in sentences:\n",
        "        sent_lens.append(len(text_to_word_sequence(sent)))\n",
        "    # print(len(sentences))\n",
        "    paras.append(sentences)"
      ],
      "metadata": {
        "id": "zW6KwrZlETFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentences[0]\n",
        "# print(\"---\")\n",
        "paras[0]\n",
        "# len(paras[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bax7g5rVJ_Gq",
        "outputId": "f1526634-11b2-4155-bc14-80042d817c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Organizing for 18 Through Election Day Sometimes fighting for progress on the issues means fighting to win on election day.',\n",
              " \"This year many of the issues we've fought for for years are on the ballot so we're Organizing for 18.\",\n",
              " 'Host or find an event near you this election season.',\n",
              " 'Find an event']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features=10000\n",
        "max_senten_len=40\n",
        "max_senten_num=6\n",
        "embed_size=100\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "metadata": {
        "id": "Stonxlk1BXVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_features, oov_token=True)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "data = np.zeros((len(texts), max_senten_num, max_senten_len), dtype='int32')\n",
        "for i, sentences in enumerate(paras):\n",
        "    for j, sent in enumerate(sentences):\n",
        "        if j< max_senten_num:\n",
        "            wordTokens = text_to_word_sequence(sent)\n",
        "            k=0\n",
        "            for _, word in enumerate(wordTokens):\n",
        "                try:\n",
        "                    if k<max_senten_len and tokenizer.word_index[word]<max_features:\n",
        "                        data[i,j,k] = tokenizer.word_index[word]\n",
        "                        k=k+1\n",
        "                except:\n",
        "                    print(word)\n",
        "                    pass"
      ],
      "metadata": {
        "id": "0QqUbo-D_Mk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(sent_lens, bins=200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wdsGl92SKcrx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "d45ea855-d992-40fd-8f30-a635ae32d528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAa1UlEQVR4nO3dfZBd9X3f8ffn3rsPegT0gE0FWAJUE9kZx4yC7TrptCHGkMRROoEGEtc0paUPZpo6dVuRtgQz/qNkWog7pilqoaW0CcT4ISohYQJ43ElDZETBBoEVFsSDZDtaCSH0uNp777d/nHNXR4ezu3dXe3R37/m8ZnZ07znn3v0dHUYffr/v7/yOIgIzM7O8Wq8bYGZm85MDwszMCjkgzMyskAPCzMwKOSDMzKxQo9cNmCurVq2KtWvX9roZZmYLyjPPPLMvIlYX7eubgFi7di3bt2/vdTPMzBYUSa9Pts9DTGZmVsgBYWZmhRwQZmZWyAFhZmaFHBBmZlbIAWFmZoUcEGZmVsgBYWZmhRwQZmZWyAFR4He3vcHvbnuj180wM+spB4SZmRVyQJiZWSEHhJmZFXJAmJlZob5Z7nsuRQTR60aYmfWYexAFHn9pL1v+z6u9boaZWU85IAq8ffQEo4fGet0MM7OeckAUaEUw1mwR4YEmM6suB0SBdiQ/Y812r5tiZtYzDogC7XbSczh0vNnjlpiZ9Y4DokA7HVo6POaAMLPqKjUgJF0laaekEUmbC/YPSXoo3b9N0trc/gslHZb0+TLbmTcREO5BmFmFlRYQkurA3cDVwAbgekkbcofdCByIiEuAu4A7cvvvBP6orDZOpp2WHtyDMLMqK7MHcTkwEhGvRsQJ4EFgU+6YTcD96euHgSskCUDSLwC7gB0ltrFQy0NMZmalBsQa4M3M+93ptsJjIqIJHARWSloK/CvgCyW2b1InaxDjvfj1ZmbzwnwtUt8G3BURh6c6SNJNkrZL2j46Ojpnv7wzi8k1CDOrsjLXYtoDXJB5f366reiY3ZIawFnAfuAjwDWSfgs4G2hLOh4RX85+OCK2AFsANm7cOGd3taX5wCEPMZlZhZUZEE8D6yWtIwmC64Bfzh2zFbgBeAq4BngyktuXf7JzgKTbgMP5cCiTZzGZmZUYEBHRlHQz8BhQB+6LiB2Sbge2R8RW4F7gAUkjwFskIdJzrbaL1GZmpS73HRGPAo/mtt2aeX0cuHaa77itlMZNoTPE5B6EmVXZfC1S91RniMk1CDOrMgdEAdcgzMwcEIXarkGYmTkginRqEEccEGZWYQ6IAq5BmJk5IAq1fCe1mZkDokinB3FsvEWz5afKmVk1OSAKtAMG6gLgyFirx60xM+sNB0SBdjtYNFAH4JBXdDWzinJA5LTbQQCLBpOA8FRXM6sqB0RO52FBiwaSVUhcqDazqnJA5HRmMC0e7AwxOSDMrJocEDnNNCAmhpjcgzCzinJA5HSmtXaK1K5BmFlVOSByOj2I4TQgjp3wNFczqyYHRE6nBjHUSP5qjjcdEGZWTQ6InE4PYrATEOO+k9rMqskBkdNqJQFRr4nBRo0x9yDMrKIcEDnNdtJjqEkMN2qMuQdhZhXlgMjp1CBqgqGBOsfH3YMws2pyQOQ0JwJCDA/UGGu6B2Fm1eSAyGlmahDDDfcgzKy6HBA5J2sQcPREywFhZpXlgMiZqEHURKMmT3M1s8pyQORkaxADdU9zNbPqckDktDIB0ai7B2Fm1eWAyOn0IOqCgXrNS22YWWU5IHJanSJ1WoPwjXJmVlUOiJzONFfXIMys6hwQOacWqV2DMLPqckDkNDNLbTTqNd8HYWaV5YDI6dQg6rVkFlOzHRNPmTMzqxIHRM4pNYha8tfj9ZjMrIocEDnZO6kH6gLwMJOZVZIDIidfgwA47h6EmVWQAyKnlZvFBDDmHoSZVZADIic7zbVR83Opzay6HBA5nRlLtVqy1Abg5TbMrJIcEDnN3GJ94CK1mVVTqQEh6SpJOyWNSNpcsH9I0kPp/m2S1qbbL5f0XPrzHUl/q8x2ZnVqEPWaJnoQnuZqZlVUWkBIqgN3A1cDG4DrJW3IHXYjcCAiLgHuAu5It78AbIyIHwOuAu6R1CirrVmdHoTARWozq7QyexCXAyMR8WpEnAAeBDbljtkE3J++fhi4QpIi4mhENNPtw0CU2M5TtNptagK5SG1mFVdmQKwB3sy8351uKzwmDYSDwEoASR+RtAN4HvhHmcCYIOkmSdslbR8dHZ2TRjfbQU1Jz2GiB+EitZlV0LwtUkfEtoj4APDjwC2ShguO2RIRGyNi4+rVq+fk97ZaQa2WBMPEjXLuQZhZBZUZEHuACzLvz0+3FR6T1hjOAvZnD4iIl4DDwAdLa2lG0oNIXnupDTOrsjID4mlgvaR1kgaB64CtuWO2Ajekr68BnoyISD/TAJD0PuBS4LUS2zqh2W5PDDG5BmFmVVbazKCIaEq6GXgMqAP3RcQOSbcD2yNiK3Av8ICkEeAtkhAB+Algs6RxoA38k4jYV1Zbs1rtoJ4GRL3z2FHXIMysgkqdOhoRjwKP5rbdmnl9HLi24HMPAA+U2bbJNDM1CIDhgbp7EGZWSfO2SN0rrUwNAmB4oOalNsyskhwQOdlprgBDjbqL1GZWSQ6InFb71CGmoYGal9ows0pyQOQ02+2JIjXAcKPupTbMrJIcEDn5GsTQQM1FajOrJAdEznh+FlOj7mmuZlZJDoicVq5IPewehJlVlAMiZ8/bx3IB4VlMZlZNDoicdgS1zN/KUMP3QZhZNTkgctqZpTYg6UGMeYjJzCrIAZHTDjzEZGaGA+Jd2nHqNNfFg3WOnmgRccYeamdmNi84IHKSGsTJhFgy1KDZDt9NbWaV01VASPqapJ+V1PeB0mqfOsS0dChZ8PbI2LueeGpm1te6/Qf/PwG/DLws6d9Jen+Jbeqp/BDT87sPAnBkzHUIM6uWrgIiIh6PiF8BLiN5stvjkv5M0q9KGiizgWdaO4J6JiEGG8lf0aGx8V41ycysJ7oeMpK0Evi7wN8HngW+RBIYf1JKy3qknV/ueyD5K3IPwsyqpqsnykn6OvB+kqe8fSoifpDuekjS9rIa1wv5aa5DjTrgGoSZVU+3jxz9L+njQydIGoqIsYjYWEK7eqboTmqAww4IM6uYboeYvliw7am5bMh8kRSpsz2IzhCTA8LMqmXKHoSk9wJrgEWSPgx0/uVcDiwuuW090W4XDzG5B2FmVTPdENMnSQrT5wN3ZrYfAn6jpDb1VCvXgxhsuEhtZtU0ZUBExP3A/ZJ+MSK+eoba1FPt9qk1iHpNNGriyAn3IMysWqYbYvp0RPxPYK2kX8/vj4g7Cz62YLXbQcApq7lCUofwEJOZVc10Q0xL0j+Xlt2Q+aCVLsiXXYsJYGig7iK1mVXOdENM96R/fuHMNKe3Wu00IAp6EA4IM6uabhfr+y1JyyUNSHpC0qikT5fduDOtOREQp24f9BCTmVVQt/dBXBkR7wA/R7IW0yXAvyirUb3Sak3eg3jzrWO9aJKZWc90GxCdoaifBb4SEQdLak9PNdvJMx/eVYNo1Bnzc6nNrGK6XWrjEUnfA44B/1jSauB4ec3qjcmGmIYaNT8wyMwqp9vlvjcDfw3YGBHjwBFgU5kN64VOQBRNc3VAmFnVdNuDALiU5H6I7Gf+xxy3p6cmq0EMNuqcaLbTm+hU9FEzs77T7XLfDwAXA88BncH4oM8CYvIaRNLROjremngEqZlZv+v2X7uNwIaI9E6yPtWarAYxcHJFVweEmVVFt7OYXgDeW2ZD5oPmFDfKgVd0NbNq6fZ/h1cBL0r6NjDW2RgRP19Kq3qk04OoF0xzBT8TwsyqpduAuK3MRswXU91JDe5BmFm1dBUQEfEtSe8D1kfE45IWA/Vym3bmNVtpkXqSISY/E8LMqqTbtZj+AfAwcE+6aQ3wjbIa1SsTPQgPMZmZdV2k/izwceAdgIh4GTh3ug9JukrSTkkjkjYX7B+S9FC6f5ukten2T0h6RtLz6Z8/1e0JnY6pVnMFDzGZWbV0GxBjEXGi8ya9WW7KKa+S6sDdwNXABuB6SRtyh90IHIiIS4C7gDvS7fuAT0XEjwI3AA902c7TcvJO6lO3Z6e5mplVRbcB8S1JvwEskvQJ4CvA/57mM5cDIxHxahouD/Lu5Tk2Afenrx8GrpCkiHg2Ir6fbt+R/t6hLts6a61JbpQbrNcQ7kGYWbV0GxCbgVHgeeAfAo8C/2aaz6wB3sy8351uKzwmIprAQWBl7phfBP5fRIzltiPpJknbJW0fHR3t8lQm15xkqQ1JfiaEmVVOt7OY2pK+AXwjIk7/X+IuSfoAybDTlZO0awuwBWDjxo2nfZf3ZDUI8FPlzKx6puxBKHGbpH3ATmBn+jS5W7v47j3ABZn356fbCo9J6xpnAfvT9+cDXwc+ExGvdHMyp2uy+yAgWbDP01zNrEqmG2L6HMnspR+PiBURsQL4CPBxSZ+b5rNPA+slrZM0CFwHbM0ds5WkCA1wDfBkRISks4E/BDZHxP+dwfmclskW64OkB+EhJjOrkukC4u8A10fErs6GiHgV+DTwmak+mNYUbgYeA14Cfj8idki6XVJniY57gZWSRoBfJ6l1kH7uEuBWSc+lP9NOqz1dk9UgwENMZlY909UgBiJiX35jRIxKGpjuyyPiUZKCdnbbrZnXx4FrCz73ReCL033/XJtsNVdwD8LMqme6HsSJWe5bkJqTLNYHMDRQ58gJB4SZVcd0PYgPSXqnYLuA4RLa01NTzWIabNRcpDazSpkyICKi7xbkm8pkz4MADzGZWfV0e6NcJZy8k/rd+4YaNU4024ynK76amfU7B0TG1D0Ir+hqZtXigMiYbporeD0mM6sOB0TG1HdS+6FBZlYtDoiMVrtNTcnifHmdISb3IMysKhwQGc12FA4vQfaxow4IM6sGB0RGqxWF6zCBHxpkZtXjgMhIehDF+zzEZGZV44DIaE0xxDToISYzqxgHREazHdSnq0Gc8CwmM6sGB0RGs9WetAbRqIlGTR5iMrPKcEBktKaoQUhiyVDDQ0xmVhkOiIypprkCLB1quAdhZpXhgMhotSef5gqwZKjuHoSZVYYDIqPZbk9apAbSISYXqc2sGhwQGVPVIMBDTGZWLQ6IjOZ0Q0yDDggzqw4HRMZUN8oBnsVkZpXigMgYb7WnGWKquwdhZpXhgMiYrgexdDjpQUTEGWyVmVlvOCAypqtBLBseoB1ebsPMqsEBkdGaYi0mgLMWDQBw8Nj4mWqSmVnPOCAymq2pp7lOBMRRB4SZ9T8HRMZ0d1K7B2FmVeKAyGi221MWqf/slf2AA8LMqsEBkTHdndSLBpKnyr3jgDCzCnBAZIy3pp7m2gkI9yDMrAocEBnT1SCGBmoIB4SZVYMDImO650HUJIYH6g4IM6sEB0RGq92mPs3fyKJBB4SZVYMDImO6HgQkdQgHhJlVgQMiY7q1mMABYWbV4YDI6KYHMTxY9zRXM6sEB0RGMotp6mPcgzCzqnBApCJiRkNMXvLbzPqdAyLVbCf/4E8XEIsH6zTbwVEv+W1mfa7UgJB0laSdkkYkbS7YPyTpoXT/Nklr0+0rJX1T0mFJXy6zjR2tNCDqU+eD76Y2s8ooLSAk1YG7gauBDcD1kjbkDrsROBARlwB3AXek248D/xb4fFnty5voQUy1GBNJkRocEGbW/8rsQVwOjETEqxFxAngQ2JQ7ZhNwf/r6YeAKSYqIIxHxpyRBcUa0Wt0NMbkHYWZVUWZArAHezLzfnW4rPCYimsBBYGW3v0DSTZK2S9o+Ojp6Wo1tttvA9D2IRe5BmFlFLOgidURsiYiNEbFx9erVp/VdrYki9dTHuQdhZlVRZkDsAS7IvD8/3VZ4jKQGcBawv8Q2Tao5UaTubojJN8uZWb8rMyCeBtZLWidpELgO2Jo7ZitwQ/r6GuDJ6NENBs0uaxBDAzVqcg/CzPpfo6wvjoimpJuBx4A6cF9E7JB0O7A9IrYC9wIPSBoB3iIJEQAkvQYsBwYl/QJwZUS8WFZ7T9Ygpj6uJrFiySD7Dp8oqylmZvNCaQEBEBGPAo/mtt2aeX0cuHaSz64ts215rS5vlANo1GqMHjpjE6zMzHpiQRep51K3d1IDLBtusPfQWNlNMjPrKQdEauJO6ummMQHLhgcYdUCYWZ9zQKSaXU5zhaQHMXpojHbbC/aZWf9yQKRanSJ1l0NMzXZw4KgL1WbWvxwQqYlprl0OMQGMHvYwk5n1LwdEaiZF6qVDyeSvve84IMysfzkgUjOpQSwfTgPChWoz62MOiNRMahBL04DwTCYz62cOiNRMahBDjTpLBuvs9c1yZtbHHBCpVpeL9XWcu3zYQ0xm1tccEKmZ1CAAVi8d8hCTmfU1B0Sq1eUjRztWL3dAmFl/c0CkZjLNFeDcZUPsfcc1CDPrXw6IVLPVmcXU3fHnLhvmyIkWh8eaJbbKzKx3HBCp5gyHmF7bfwSA3QeOltYmM7NeckCkZvI8CICVSwYBeH2/A8LM+pMDItXtM6k7VqQB8YYDwsz6lAMi1erykaMdiwcbDA/UeP2tIyW2ysysdxwQqZnOYgJYuWTIQ0xm1rccEKlWa+YBsWLJIG+85YAws/7kgEjN9E5qSAJiz4FjE1Nkzcz6iQMi1Wy3qdeEZjTENEizHfzgoG+YM7P+44BINdtBfSbdB07OZHIdwsz6kQMi1WoFjdkGhGcymVkfckCkZtODWL5ogMF6zT0IM+tLDohUqx0M1Gf211GTWL1siO+8+XZJrTIz6x0HRGo2PQiAdauW8OybbzPWbJXQKjOz3nFApFrt9oxrEABrVy7hRLPNd3cfLKFVZma944BIzbYHsXblYgC+veutuW6SmVlPOSBSzVnMYgJYPNTg3GVD/MFze0polZlZ7zggUq1Z9iAA1q5awuv7j/qOajPrKw6I1PHxFoON+qw+e/HqpYw122zzMJOZ9REHROr1t45y4YpFs/rspe9dxvBAja8+s3uOW2Vm1jsOCJLhpdf3H2HdqqWz+vxAvcaPrjmbP3rhh35GtZn1DQcEsOfAMcZbwUWrlsz6Oy678GyOjbf44xd+OIctMzPrHQcE8Mq+wwBctHr2AXHhisVctHoJ93zrFcZdrDazPuCAAHaNJovtrTuNHoQkPn7xKl7ee5j7/nTXXDXNzKxnHBDArn1HWD7cmFiddbZ+5Lzl/PSPvIfffvxldnzfd1ab2cLmgABe3XeYdauXzuhhQZO57MKzGWzUuH7Ln/P0a572amYLV6kBIekqSTsljUjaXLB/SNJD6f5tktZm9t2Sbt8p6ZNltnPX6BEuPo3hpayzFw9y01+/iEa9xrX/+Sk+/5Xv8Bd/eWhOvtvM7ExqlPXFkurA3cAngN3A05K2RsSLmcNuBA5ExCWSrgPuAH5J0gbgOuADwF8BHpf0VyNizpdMPXaixfcPHj+t+kPeOYsHuflvXsI3d+7l68/u4eFndnPx6iVcet5yLn3PMi5cuZhlww1abRhq1Fi3agmLB+sTjzyt10RdQuKU13PRwzEz61ZpAQFcDoxExKsAkh4ENgHZgNgE3Ja+fhj4spJ/BTcBD0bEGLBL0kj6fU/NdSNf258WqE9jBlOR4YE6V3/wPH5y/Wqee+MAu/Yf5alX9vOH3/3BrL+zpuQZFJ2wECSvSbfNXfPNbAG56oPn8R/+9ofm/HvLDIg1wJuZ97uBj0x2TEQ0JR0EVqbb/zz32TX5XyDpJuCm9O1hSTtn29hP3THxchWwb7bfs0BU4RzB59lPqnCOMMvzfBG485dm/TvfN9mOMgOidBGxBdgyl98paXtEbJzL75xvqnCO4PPsJ1U4R5h/51lmkXoPcEHm/fnptsJjJDWAs4D9XX7WzMxKVGZAPA2sl7RO0iBJ0Xlr7pitwA3p62uAJyMi0u3XpbOc1gHrgW+X2FYzM8spbYgprSncDDwG1IH7ImKHpNuB7RGxFbgXeCAtQr9FEiKkx/0+ydBaE/hsGTOYJjGnQ1bzVBXOEXye/aQK5wjz7DyV/A+7mZnZqXwntZmZFXJAmJlZIQdEarplQRYSSRdI+qakFyXtkPRr6fYVkv5E0svpn+ek2yXpP6bn/l1Jl/X2DLonqS7pWUmPpO/Xpcu2jKTLuAym2ydd1mW+k3S2pIclfU/SS5I+1m/XUtLn0v9WX5D0e5KG++FaSrpP0l5JL2S2zfjaSbohPf5lSTcU/a4yOCA4ZVmQq4ENwPXpch8LVRP45xGxAfgo8Nn0fDYDT0TEeuCJ9D0k570+/bkJ+J0z3+RZ+zXgpcz7O4C7IuIS4ADJci6QWdYFuCs9bqH4EvDHEXEp8CGS8+2baylpDfBPgY0R8UGSSS2dpXcW+rX878BVuW0zunaSVgC/SXKj8eXAb3ZCpXQRUfkf4GPAY5n3twC39Lpdc3h+f0CyJtZO4Lx023nAzvT1PcD1meMnjpvPPyT3xzwB/BTwCMlqI/uARv66ksym+1j6upEep16fQxfneBawK9/WfrqWnFxRYUV6bR4BPtkv1xJYC7ww22sHXA/ck9l+ynFl/rgHkShaFuRdS3ssRGn3+8PANuA9EdFZDOqHwHvS1wv1/H8b+JdA5xF+K4G3I6LzYPDseZyyrAvQWdZlvlsHjAL/LR1K+6+SltBH1zIi9gD/HngD+AHJtXmG/ruWHTO9dj27pg6IPiZpKfBV4J9FxDvZfZH8r8iCneMs6eeAvRHxTK/bUrIGcBnwOxHxYeAIJ4ckgL64lueQLNC5jmT15iW8e1imL833a+eASPTd0h6SBkjC4X9FxNfSzX8p6bx0/3nA3nT7Qjz/jwM/L+k14EGSYaYvAWeny7bAqecx2bIu891uYHdEbEvfP0wSGP10LX8a2BURoxExDnyN5Pr227XsmOm169k1dUAkulkWZMGQJJK71F+KiDszu7JLm9xAUpvobP9MOovio8DBTBd4XoqIWyLi/IhYS3K9noyIXwG+SbJsC7z7HIuWdZnXIuKHwJuS3p9uuoJkhYG+uZYkQ0sflbQ4/W+3c459dS0zZnrtHgOulHRO2tu6Mt1Wvl4XcObLD/AzwF8ArwD/utftOc1z+QmSbut3gefSn58hGad9AngZeBxYkR4vkllcrwDPk8wm6fl5zOB8/wbwSPr6IpJ1u0aArwBD6fbh9P1Iuv+iXrd7Buf3Y8D29Hp+Azin364l8AXge8ALwAPAUD9cS+D3SOoq4yS9wRtnc+2Av5ee7wjwq2eq/V5qw8zMCnmIyczMCjkgzMyskAPCzMwKOSDMzKyQA8LMzAo5IMzMrJADwszMCv1/NzdTxmASgc0AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_lens"
      ],
      "metadata": {
        "id": "X49qAppeJSaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d86eb293-ce2d-4e71-8269-7a29732f3f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20,\n",
              " 20,\n",
              " 10,\n",
              " 3,\n",
              " 26,\n",
              " 4,\n",
              " 34,\n",
              " 28,\n",
              " 5,\n",
              " 38,\n",
              " 30,\n",
              " 27,\n",
              " 30,\n",
              " 27,\n",
              " 21,\n",
              " 25,\n",
              " 23,\n",
              " 15,\n",
              " 51,\n",
              " 22,\n",
              " 37,\n",
              " 32,\n",
              " 10,\n",
              " 5,\n",
              " 15,\n",
              " 18,\n",
              " 26,\n",
              " 34,\n",
              " 12,\n",
              " 16,\n",
              " 23,\n",
              " 17,\n",
              " 32,\n",
              " 20,\n",
              " 22,\n",
              " 26,\n",
              " 5,\n",
              " 31,\n",
              " 2,\n",
              " 8,\n",
              " 23,\n",
              " 10,\n",
              " 15,\n",
              " 27,\n",
              " 14,\n",
              " 6,\n",
              " 9,\n",
              " 5,\n",
              " 21,\n",
              " 24,\n",
              " 15,\n",
              " 29,\n",
              " 12,\n",
              " 14,\n",
              " 41,\n",
              " 18,\n",
              " 14,\n",
              " 5,\n",
              " 16,\n",
              " 6,\n",
              " 31,\n",
              " 12,\n",
              " 34,\n",
              " 30,\n",
              " 14,\n",
              " 20,\n",
              " 33,\n",
              " 13,\n",
              " 50,\n",
              " 16,\n",
              " 24,\n",
              " 9,\n",
              " 23,\n",
              " 26,\n",
              " 15,\n",
              " 18,\n",
              " 24,\n",
              " 15,\n",
              " 12,\n",
              " 13,\n",
              " 35,\n",
              " 22,\n",
              " 31,\n",
              " 18,\n",
              " 17,\n",
              " 14,\n",
              " 5,\n",
              " 32,\n",
              " 5,\n",
              " 18,\n",
              " 32,\n",
              " 37,\n",
              " 1,\n",
              " 25,\n",
              " 32,\n",
              " 37,\n",
              " 13,\n",
              " 34,\n",
              " 26,\n",
              " 19,\n",
              " 37,\n",
              " 6,\n",
              " 14,\n",
              " 8,\n",
              " 11,\n",
              " 18,\n",
              " 36,\n",
              " 11,\n",
              " 24,\n",
              " 27,\n",
              " 9,\n",
              " 9,\n",
              " 15,\n",
              " 46,\n",
              " 36,\n",
              " 51,\n",
              " 17,\n",
              " 22,\n",
              " 7,\n",
              " 44,\n",
              " 26,\n",
              " 17,\n",
              " 10,\n",
              " 9,\n",
              " 22,\n",
              " 47,\n",
              " 9,\n",
              " 12,\n",
              " 21,\n",
              " 39,\n",
              " 11,\n",
              " 11,\n",
              " 25,\n",
              " 16,\n",
              " 12,\n",
              " 35,\n",
              " 18,\n",
              " 18,\n",
              " 9,\n",
              " 13,\n",
              " 40,\n",
              " 57,\n",
              " 23,\n",
              " 15,\n",
              " 58,\n",
              " 14,\n",
              " 10,\n",
              " 28,\n",
              " 38,\n",
              " 15,\n",
              " 27,\n",
              " 3,\n",
              " 14,\n",
              " 8,\n",
              " 26,\n",
              " 25,\n",
              " 20,\n",
              " 16,\n",
              " 9,\n",
              " 10,\n",
              " 13,\n",
              " 18,\n",
              " 21,\n",
              " 24,\n",
              " 24,\n",
              " 19,\n",
              " 10,\n",
              " 20,\n",
              " 18,\n",
              " 38,\n",
              " 57,\n",
              " 13,\n",
              " 28,\n",
              " 21,\n",
              " 24,\n",
              " 15,\n",
              " 37,\n",
              " 9,\n",
              " 2,\n",
              " 27,\n",
              " 31,\n",
              " 18,\n",
              " 21,\n",
              " 18,\n",
              " 21,\n",
              " 16,\n",
              " 26,\n",
              " 33,\n",
              " 21,\n",
              " 36,\n",
              " 17,\n",
              " 19,\n",
              " 41,\n",
              " 26,\n",
              " 34,\n",
              " 23,\n",
              " 19,\n",
              " 32,\n",
              " 20,\n",
              " 24,\n",
              " 28,\n",
              " 28,\n",
              " 15,\n",
              " 12,\n",
              " 27,\n",
              " 13,\n",
              " 17,\n",
              " 18,\n",
              " 11,\n",
              " 8,\n",
              " 4,\n",
              " 28,\n",
              " 13,\n",
              " 12,\n",
              " 7,\n",
              " 27,\n",
              " 20,\n",
              " 23,\n",
              " 20,\n",
              " 28,\n",
              " 22,\n",
              " 53,\n",
              " 12,\n",
              " 31,\n",
              " 19,\n",
              " 44,\n",
              " 4,\n",
              " 20,\n",
              " 40,\n",
              " 26,\n",
              " 2,\n",
              " 42,\n",
              " 22,\n",
              " 21,\n",
              " 30,\n",
              " 43,\n",
              " 30,\n",
              " 17,\n",
              " 25,\n",
              " 33,\n",
              " 1,\n",
              " 41,\n",
              " 16,\n",
              " 29,\n",
              " 17,\n",
              " 8,\n",
              " 18,\n",
              " 16,\n",
              " 31,\n",
              " 34,\n",
              " 28,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 21,\n",
              " 24,\n",
              " 10,\n",
              " 18,\n",
              " 23,\n",
              " 27,\n",
              " 4,\n",
              " 7,\n",
              " 70,\n",
              " 13,\n",
              " 10,\n",
              " 13,\n",
              " 21,\n",
              " 16,\n",
              " 28,\n",
              " 18,\n",
              " 9,\n",
              " 14,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 8,\n",
              " 6,\n",
              " 6,\n",
              " 1,\n",
              " 14,\n",
              " 1,\n",
              " 8,\n",
              " 32,\n",
              " 5,\n",
              " 7,\n",
              " 1,\n",
              " 11,\n",
              " 1,\n",
              " 8,\n",
              " 1,\n",
              " 4,\n",
              " 17,\n",
              " 1,\n",
              " 10,\n",
              " 1,\n",
              " 6,\n",
              " 1,\n",
              " 5,\n",
              " 1,\n",
              " 12,\n",
              " 1,\n",
              " 15,\n",
              " 1,\n",
              " 14,\n",
              " 1,\n",
              " 13,\n",
              " 16,\n",
              " 1,\n",
              " 9,\n",
              " 1,\n",
              " 6,\n",
              " 7,\n",
              " 14,\n",
              " 6,\n",
              " 2,\n",
              " 1,\n",
              " 7,\n",
              " 1,\n",
              " 4,\n",
              " 13,\n",
              " 1,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 16,\n",
              " 1,\n",
              " 52,\n",
              " 40,\n",
              " 14,\n",
              " 20,\n",
              " 4,\n",
              " 8,\n",
              " 11,\n",
              " 12,\n",
              " 26,\n",
              " 1,\n",
              " 5,\n",
              " 40,\n",
              " 1,\n",
              " 14,\n",
              " 17,\n",
              " 5,\n",
              " 14,\n",
              " 13,\n",
              " 13,\n",
              " 5,\n",
              " 1,\n",
              " 22,\n",
              " 14,\n",
              " 18,\n",
              " 35,\n",
              " 12,\n",
              " 5,\n",
              " 1,\n",
              " 33,\n",
              " 7,\n",
              " 1,\n",
              " 52,\n",
              " 14,\n",
              " 87,\n",
              " 26,\n",
              " 34,\n",
              " 42,\n",
              " 1,\n",
              " 7,\n",
              " 41,\n",
              " 25,\n",
              " 6,\n",
              " 31,\n",
              " 19,\n",
              " 18,\n",
              " 11,\n",
              " 32,\n",
              " 10,\n",
              " 9,\n",
              " 34,\n",
              " 27,\n",
              " 11,\n",
              " 15,\n",
              " 22,\n",
              " 7,\n",
              " 18,\n",
              " 17,\n",
              " 3,\n",
              " 17,\n",
              " 11,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 11,\n",
              " 33,\n",
              " 10,\n",
              " 22,\n",
              " 9,\n",
              " 22,\n",
              " 28,\n",
              " 36,\n",
              " 23,\n",
              " 1,\n",
              " 26,\n",
              " 1,\n",
              " 24,\n",
              " 16,\n",
              " 17,\n",
              " 12,\n",
              " 1,\n",
              " 16,\n",
              " 11,\n",
              " 6,\n",
              " 6,\n",
              " 8,\n",
              " 19,\n",
              " 1,\n",
              " 28,\n",
              " 1,\n",
              " 10,\n",
              " 14,\n",
              " 10,\n",
              " 12,\n",
              " 6,\n",
              " 18,\n",
              " 20,\n",
              " 8,\n",
              " 22,\n",
              " 18,\n",
              " 19,\n",
              " 15,\n",
              " 12,\n",
              " 8,\n",
              " 8,\n",
              " 14,\n",
              " 1,\n",
              " 41,\n",
              " 26,\n",
              " 1,\n",
              " 19,\n",
              " 7,\n",
              " 1,\n",
              " 15,\n",
              " 31,\n",
              " 1,\n",
              " 39,\n",
              " 16,\n",
              " 22,\n",
              " 34,\n",
              " 22,\n",
              " 9,\n",
              " 30,\n",
              " 1,\n",
              " 6,\n",
              " 16,\n",
              " 8,\n",
              " 1,\n",
              " 40,\n",
              " 1,\n",
              " 39,\n",
              " 30,\n",
              " 27,\n",
              " 7,\n",
              " 1,\n",
              " 20,\n",
              " 26,\n",
              " 25,\n",
              " 12,\n",
              " 1,\n",
              " 5,\n",
              " 17,\n",
              " 8,\n",
              " 26,\n",
              " 30,\n",
              " 17,\n",
              " 1,\n",
              " 23,\n",
              " 30,\n",
              " 1,\n",
              " 21,\n",
              " 18,\n",
              " 33,\n",
              " 8,\n",
              " 8,\n",
              " 18,\n",
              " 1,\n",
              " 70,\n",
              " 9,\n",
              " 13,\n",
              " 14,\n",
              " 25,\n",
              " 13,\n",
              " 19,\n",
              " 3,\n",
              " 11,\n",
              " 24,\n",
              " 9,\n",
              " 1,\n",
              " 37,\n",
              " 27,\n",
              " 8,\n",
              " 4,\n",
              " 22,\n",
              " 24,\n",
              " 8,\n",
              " 15,\n",
              " 12,\n",
              " 23,\n",
              " 1,\n",
              " 8,\n",
              " 62,\n",
              " 1,\n",
              " 60,\n",
              " 21,\n",
              " 4,\n",
              " 27,\n",
              " 1,\n",
              " 35,\n",
              " 5,\n",
              " 7,\n",
              " 1,\n",
              " 21,\n",
              " 20,\n",
              " 1,\n",
              " 17,\n",
              " 14,\n",
              " 23,\n",
              " 38,\n",
              " 11,\n",
              " 14,\n",
              " 1,\n",
              " 16,\n",
              " 7,\n",
              " 1,\n",
              " 15,\n",
              " 1,\n",
              " 6,\n",
              " 34,\n",
              " 1,\n",
              " 22,\n",
              " 1,\n",
              " 37,\n",
              " 14,\n",
              " 12,\n",
              " 11,\n",
              " 1,\n",
              " 21,\n",
              " 32,\n",
              " 5,\n",
              " 9,\n",
              " 1,\n",
              " 8,\n",
              " 7,\n",
              " 3,\n",
              " 17,\n",
              " 1,\n",
              " 9,\n",
              " 26,\n",
              " 17,\n",
              " 7,\n",
              " 25,\n",
              " 8,\n",
              " 19,\n",
              " 9,\n",
              " 1,\n",
              " 8,\n",
              " 18,\n",
              " 32,\n",
              " 27,\n",
              " 27,\n",
              " 23,\n",
              " 1,\n",
              " 80,\n",
              " 16,\n",
              " 23,\n",
              " 1,\n",
              " 9,\n",
              " 6,\n",
              " 52,\n",
              " 1,\n",
              " 21,\n",
              " 5,\n",
              " 3,\n",
              " 1,\n",
              " 6,\n",
              " 31,\n",
              " 15,\n",
              " 39,\n",
              " 37,\n",
              " 9,\n",
              " 20,\n",
              " 23,\n",
              " 31,\n",
              " 18,\n",
              " 34,\n",
              " 6,\n",
              " 12,\n",
              " 8,\n",
              " 32,\n",
              " 22,\n",
              " 27,\n",
              " 11,\n",
              " 4,\n",
              " 18,\n",
              " 32,\n",
              " 27,\n",
              " 48,\n",
              " 34,\n",
              " 27,\n",
              " 15,\n",
              " 29,\n",
              " 7,\n",
              " 17,\n",
              " 14,\n",
              " 35,\n",
              " 31,\n",
              " 20,\n",
              " 22,\n",
              " 37,\n",
              " 6,\n",
              " 9,\n",
              " 27,\n",
              " 14,\n",
              " 27,\n",
              " 24,\n",
              " 39,\n",
              " 56,\n",
              " 4,\n",
              " 18,\n",
              " 2,\n",
              " 25,\n",
              " 54,\n",
              " 32,\n",
              " 23,\n",
              " 19,\n",
              " 10,\n",
              " 11,\n",
              " 7,\n",
              " 20,\n",
              " 42,\n",
              " 22,\n",
              " 24,\n",
              " 59,\n",
              " 31,\n",
              " 30,\n",
              " 38,\n",
              " 25,\n",
              " 29,\n",
              " 13,\n",
              " 8,\n",
              " 26,\n",
              " 35,\n",
              " 60,\n",
              " 17,\n",
              " 23,\n",
              " 40,\n",
              " 20,\n",
              " 23,\n",
              " 45,\n",
              " 2,\n",
              " 20,\n",
              " 9,\n",
              " 19,\n",
              " 7,\n",
              " 20,\n",
              " 18,\n",
              " 5,\n",
              " 5,\n",
              " 36,\n",
              " 13,\n",
              " 11,\n",
              " 23,\n",
              " 21,\n",
              " 26,\n",
              " 22,\n",
              " 30,\n",
              " 10,\n",
              " 25,\n",
              " 36,\n",
              " 6,\n",
              " 17,\n",
              " 13,\n",
              " 4,\n",
              " 32,\n",
              " 16,\n",
              " 8,\n",
              " 18,\n",
              " 14,\n",
              " 16,\n",
              " 13,\n",
              " 8,\n",
              " 18,\n",
              " 5,\n",
              " 8,\n",
              " 11,\n",
              " 5,\n",
              " 29,\n",
              " 20,\n",
              " 11,\n",
              " 23,\n",
              " 4,\n",
              " 13,\n",
              " 11,\n",
              " 3,\n",
              " 29,\n",
              " 35,\n",
              " 34,\n",
              " 25,\n",
              " 17,\n",
              " 46,\n",
              " 20,\n",
              " 26,\n",
              " 6,\n",
              " 8,\n",
              " 25,\n",
              " 11,\n",
              " 22,\n",
              " 27,\n",
              " 24,\n",
              " 23,\n",
              " 24,\n",
              " 15,\n",
              " 42,\n",
              " 11,\n",
              " 17,\n",
              " 37,\n",
              " 31,\n",
              " 29,\n",
              " 37,\n",
              " 26,\n",
              " 26,\n",
              " 31,\n",
              " 28,\n",
              " 46,\n",
              " 23,\n",
              " 23,\n",
              " 10,\n",
              " 10,\n",
              " 22,\n",
              " 15,\n",
              " 24,\n",
              " 43,\n",
              " 6,\n",
              " 32,\n",
              " 40,\n",
              " 15,\n",
              " 17,\n",
              " 33,\n",
              " 6,\n",
              " 19,\n",
              " 23,\n",
              " 22,\n",
              " 8,\n",
              " 7,\n",
              " 24,\n",
              " 14,\n",
              " 19,\n",
              " 17,\n",
              " 1,\n",
              " 177,\n",
              " 42,\n",
              " 20,\n",
              " 32,\n",
              " 18,\n",
              " 5,\n",
              " 26,\n",
              " 17,\n",
              " 34,\n",
              " 34,\n",
              " 28,\n",
              " 9,\n",
              " 27,\n",
              " 29,\n",
              " 30,\n",
              " 18,\n",
              " 12,\n",
              " 13,\n",
              " 33,\n",
              " 49,\n",
              " 22,\n",
              " 48,\n",
              " 12,\n",
              " 5,\n",
              " 29,\n",
              " 23,\n",
              " 13,\n",
              " 47,\n",
              " 17,\n",
              " 14,\n",
              " 33,\n",
              " 23,\n",
              " 43,\n",
              " 30,\n",
              " 16,\n",
              " 17,\n",
              " 40,\n",
              " 9,\n",
              " 6,\n",
              " 9,\n",
              " 9,\n",
              " 3,\n",
              " 8,\n",
              " 21,\n",
              " 16,\n",
              " 8,\n",
              " 22,\n",
              " 9,\n",
              " 37,\n",
              " 11,\n",
              " 37,\n",
              " 15,\n",
              " 31,\n",
              " 66,\n",
              " 51,\n",
              " 28,\n",
              " 31,\n",
              " 21,\n",
              " 15,\n",
              " 4,\n",
              " 28,\n",
              " 33,\n",
              " 20,\n",
              " 17,\n",
              " 5,\n",
              " 8,\n",
              " 11,\n",
              " 17,\n",
              " 7,\n",
              " 6,\n",
              " 6,\n",
              " 19,\n",
              " 10,\n",
              " 7,\n",
              " 5,\n",
              " 12,\n",
              " 26,\n",
              " 12,\n",
              " 24,\n",
              " 4,\n",
              " 23,\n",
              " 7,\n",
              " 9,\n",
              " 7,\n",
              " 4,\n",
              " 47,\n",
              " 19,\n",
              " 14,\n",
              " 19,\n",
              " 15,\n",
              " 26,\n",
              " 18,\n",
              " 16,\n",
              " 28,\n",
              " 18,\n",
              " 15,\n",
              " 11,\n",
              " 26,\n",
              " 12,\n",
              " 42,\n",
              " 45,\n",
              " 17,\n",
              " 29,\n",
              " 19,\n",
              " 27,\n",
              " 30,\n",
              " 40,\n",
              " 24,\n",
              " 16,\n",
              " 46,\n",
              " 4,\n",
              " 32,\n",
              " 37,\n",
              " 47,\n",
              " 50,\n",
              " 26,\n",
              " 21,\n",
              " 16,\n",
              " 19,\n",
              " 11,\n",
              " 68,\n",
              " 46,\n",
              " 18,\n",
              " 7,\n",
              " 2,\n",
              " 25,\n",
              " 14,\n",
              " 30,\n",
              " 31,\n",
              " 49,\n",
              " 22,\n",
              " 34,\n",
              " 21,\n",
              " 6,\n",
              " 18,\n",
              " 29,\n",
              " 28,\n",
              " 6,\n",
              " 12,\n",
              " 25,\n",
              " 13,\n",
              " 14,\n",
              " 25,\n",
              " 35,\n",
              " 12,\n",
              " 16,\n",
              " 24,\n",
              " 5,\n",
              " 9,\n",
              " 5,\n",
              " 8,\n",
              " 7,\n",
              " 8,\n",
              " 3,\n",
              " 5,\n",
              " 6,\n",
              " 25,\n",
              " 23,\n",
              " 10,\n",
              " 7,\n",
              " 6,\n",
              " 13,\n",
              " 4,\n",
              " 6,\n",
              " 22,\n",
              " 7,\n",
              " 60,\n",
              " 13,\n",
              " 14,\n",
              " 11,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 10,\n",
              " 34,\n",
              " 5,\n",
              " 21,\n",
              " 49,\n",
              " 2,\n",
              " 5,\n",
              " 6,\n",
              " 2,\n",
              " 42,\n",
              " 11,\n",
              " 4,\n",
              " 8,\n",
              " 10,\n",
              " 13,\n",
              " 33,\n",
              " 6,\n",
              " 17,\n",
              " 16,\n",
              " 24,\n",
              " 14,\n",
              " 28,\n",
              " 7,\n",
              " 8,\n",
              " 4,\n",
              " 5,\n",
              " 12,\n",
              " 14,\n",
              " 6,\n",
              " 5,\n",
              " 38,\n",
              " 10,\n",
              " 15,\n",
              " 52,\n",
              " 15,\n",
              " 23,\n",
              " 18,\n",
              " 31,\n",
              " 26,\n",
              " 13,\n",
              " 18,\n",
              " 10,\n",
              " 54,\n",
              " 32,\n",
              " 50,\n",
              " 30,\n",
              " 60,\n",
              " 26,\n",
              " 9,\n",
              " 32,\n",
              " 17,\n",
              " 6,\n",
              " 5,\n",
              " 11,\n",
              " 13,\n",
              " 14,\n",
              " 9,\n",
              " 60,\n",
              " 19,\n",
              " 16,\n",
              " 11,\n",
              " 23,\n",
              " 30,\n",
              " 6,\n",
              " 7,\n",
              " 16,\n",
              " 16,\n",
              " 14,\n",
              " 38,\n",
              " 22,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDILNjmxK6ZQ",
        "outputId": "3c9c2e99-7972-4058-df32-9b053d49af65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 6, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Total %s unique tokens.' % len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMsaPY3vK-fe",
        "outputId": "d4f7c63b-cc8d-4ec6-903e-ccd0619a4d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 17560 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.get_dummies(df[\"target\"])\n",
        "# labels = df[\"target\"]"
      ],
      "metadata": {
        "id": "qcsD-akXLBU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_feature_array = df.iloc[:, [10, 14, 19, 25, 38, 37, 42, 43, 56]]"
      ],
      "metadata": {
        "id": "iUcqFEVJA2OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_feature_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "3NfFyuD2BUxV",
        "outputId": "ad977a0e-74f2-4793-970c-1b08598f9ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 S10       S14   S5          T10        L2        L1  \\\n",
              "id                                                                     \n",
              "politifact720    2.0  0.000000  1.0   70046229.0  0.000000  0.000000   \n",
              "politifact10731  2.0  0.000000  1.0      66458.0  0.000000  0.000000   \n",
              "politifact11115  6.0  0.032958  1.0      25697.0 -0.106934  0.672131   \n",
              "politifact14148  6.0  0.029674  1.0      26238.0  0.041364  1.000000   \n",
              "politifact6932   3.0  0.026316  0.0          0.0  0.432900  2.000000   \n",
              "...              ...       ...  ...          ...       ...       ...   \n",
              "politifact7511   3.0  0.027027  1.0  233484128.0  0.516850  3.000000   \n",
              "politifact160    5.0  0.179487  1.0  124102139.0  0.061033  0.857143   \n",
              "politifact13443  3.0  0.028571  2.0     232329.0 -0.585900  0.500000   \n",
              "politifact14003  4.0  0.166667  2.0     141764.0 -0.016069  0.727273   \n",
              "politifact10903  2.0  0.000000  1.0      25453.0  0.000000  0.000000   \n",
              "\n",
              "                       L6      Sen1     Sen14  \n",
              "id                                             \n",
              "politifact720    0.000000  0.066667  0.015718  \n",
              "politifact10731  0.045455  0.000000  0.305667  \n",
              "politifact11115  0.000000  0.000000  0.208895  \n",
              "politifact14148  0.000000  0.050000  0.072144  \n",
              "politifact6932   0.055556  0.000000  0.341132  \n",
              "...                   ...       ...       ...  \n",
              "politifact7511   0.000000  0.000000  0.004649  \n",
              "politifact160    0.032258  0.032258  0.034538  \n",
              "politifact13443  0.000000  0.041667  0.007800  \n",
              "politifact14003  0.058824  0.000000  0.150233  \n",
              "politifact10903  0.000000  0.000000  0.000000  \n",
              "\n",
              "[312 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-212f76fa-5d0f-4744-b5b5-38acb125a620\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S10</th>\n",
              "      <th>S14</th>\n",
              "      <th>S5</th>\n",
              "      <th>T10</th>\n",
              "      <th>L2</th>\n",
              "      <th>L1</th>\n",
              "      <th>L6</th>\n",
              "      <th>Sen1</th>\n",
              "      <th>Sen14</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>politifact720</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70046229.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.015718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10731</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>66458.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.305667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact11115</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.032958</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25697.0</td>\n",
              "      <td>-0.106934</td>\n",
              "      <td>0.672131</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14148</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.029674</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26238.0</td>\n",
              "      <td>0.041364</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.072144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact6932</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.432900</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.341132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact7511</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>1.0</td>\n",
              "      <td>233484128.0</td>\n",
              "      <td>0.516850</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact160</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.179487</td>\n",
              "      <td>1.0</td>\n",
              "      <td>124102139.0</td>\n",
              "      <td>0.061033</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.034538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact13443</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>2.0</td>\n",
              "      <td>232329.0</td>\n",
              "      <td>-0.585900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14003</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>2.0</td>\n",
              "      <td>141764.0</td>\n",
              "      <td>-0.016069</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10903</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25453.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>312 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-212f76fa-5d0f-4744-b5b5-38acb125a620')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-212f76fa-5d0f-4744-b5b5-38acb125a620 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-212f76fa-5d0f-4744-b5b5-38acb125a620');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of labels tensor:', labels.shape)\n",
        "print('Shape of sample_feature_array tensor:', sample_feature_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfPelUK8LNfI",
        "outputId": "06bc2081-2359-427c-872e-16856a337dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (312, 6, 40)\n",
            "Shape of labels tensor: (312, 2)\n",
            "Shape of sample_feature_array tensor: (312, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(data.shape[0])"
      ],
      "metadata": {
        "id": "PoHLCeqOPGQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[indices]"
      ],
      "metadata": {
        "id": "2RwrMU1dVMxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEwADdziVSUF",
        "outputId": "7e722177-2f1a-4dab-e6e0-663d0aa9eca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 6, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test, f_train, f_test = train_test_split(data, df['target'], sample_feature_array, test_size= .15, random_state= 111, stratify= df['target'] )\n",
        "x_train, x_val, y_train, y_val, f_train, f_val= train_test_split(x_train, y_train,f_train, test_size= .10, random_state= 111, stratify= None )"
      ],
      "metadata": {
        "id": "D_IRCpwDXS1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "xWSKwOCPUd7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d883e2b-91ff-4a50-84a7-cbbc0bd99083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 459,  113, 1237, ...,    0,    0,    0],\n",
              "        [  41,   74,   51, ...,    0,    0,    0],\n",
              "        [  17,  838,  113, ...,    0,    0,    0],\n",
              "        [   2, 2521,   22, ...,    0,    0,    0],\n",
              "        [2327,   41,   10, ...,    0,    0,    0],\n",
              "        [   2,  113, 1237, ...,    0,    0,    0]],\n",
              "\n",
              "       [[  30,    2,  459, ...,    0,    0,    0],\n",
              "        [ 108,   18,    2, ...,    0,    0,    0],\n",
              "        [1979, 7061,    2, ...,    0,    0,    0],\n",
              "        [ 334, 1219, 6066, ...,    0,    0,    0],\n",
              "        [   2, 1955, 1276, ...,    0,    0,    0],\n",
              "        [ 225,  354, 1715, ...,    0,    0,    0]],\n",
              "\n",
              "       [[ 313,  280, 6323, ...,    7,    2, 5269],\n",
              "        [ 745,   28,    2, ...,    0,    0,    0],\n",
              "        [   2, 4093, 3703, ...,    0,    0,    0],\n",
              "        [  57,  538,   30, ...,    0,    0,    0],\n",
              "        [ 258,    6,  313, ...,    0,    0,    0],\n",
              "        [  57, 1497, 3762, ...,    7, 3703,   32]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[  37,  326, 3922, ...,    0,    0,    0],\n",
              "        [7612, 7613,    0, ...,    0,    0,    0],\n",
              "        [  58,    5,    2, ...,    0,    0,    0],\n",
              "        [  26,   20,  152, ...,    0,    0,    0],\n",
              "        [  11,  327,   24, ...,    0,    0,    0],\n",
              "        [  41,  197,  914, ...,    0,    0,    0]],\n",
              "\n",
              "       [[1354,    3, 6277, ...,    0,    0,    0],\n",
              "        [4152,  127, 2295, ...,    0,    0,    0],\n",
              "        [  17, 2634,  180, ...,    0,    0,    0],\n",
              "        [ 632, 2443, 1100, ...,    0,    0,    0],\n",
              "        [ 189,   41,  747, ...,    0,    0,    0],\n",
              "        [ 340,   84,  105, ...,    0,    0,    0]],\n",
              "\n",
              "       [[ 268, 1536,  143, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0]]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFICaSJVXXrM",
        "outputId": "75dfd768-fcad-4222-bdf4-b0a4840707e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(238, 6, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train, x_test, y_train, y_test = train_test_split(data, df['target'], test_size= .15, random_state= 111, stratify= None )\n",
        "# x_train, x_val, y_train, y_val= train_test_split(x_train, y_train, test_size= .10, random_state= 111, stratify= None )\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "# np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels.iloc[indices]\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_val = data[-nb_validation_samples:]\n",
        "y_val = labels[-nb_validation_samples:]\n",
        "print('Number of positive and negative reviews in traing and validation set')\n",
        "f_train = sample_feature_array[:-nb_validation_samples]\n",
        "f_val = sample_feature_array[-nb_validation_samples:]\n",
        "# print(y_train.columns.tolist())\n",
        "# print(y_train.sum(axis=0).tolist())\n",
        "# print(y_val.sum(axis=0).tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YgxADbELQ9C",
        "outputId": "5a3ce2f3-bbb5-49fa-c317-df966f8a4bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive and negative reviews in traing and validation set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "id": "SoGZdSmTUYHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9516f53c-c028-4300-fc75-1e0469542aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4658,   14,  300,  241,  263,  209, 1286,  766,   14, 1049,   16,\n",
              "           2,  416,  428,  766,    3,  554,   16,  263,  209,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [  17,  147,  146,    5,    2,  416,  173, 1256,   14,   14,  107,\n",
              "          18,   16,    2, 2324,   34,  100, 4658,   14,  300,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [1497,   46,  475,   45, 1066, 1629,   12,   17,  263, 1433,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [ 475,   45, 1066,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_train = sample_feature_array[:-nb_validation_samples]\n",
        "f_val = sample_feature_array[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "uTVmqysyNi0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHgrkpQQNx-m",
        "outputId": "69066ff1-c57e-4331-a8bb-9c5c1c72bcfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val"
      ],
      "metadata": {
        "id": "yXDfTj0Bc3pr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "fe7c78d7-0bf3-483a-90e0-164c7518beff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0  1\n",
              "id                   \n",
              "politifact15371  1  0\n",
              "politifact13132  0  1\n",
              "politifact15187  1  0\n",
              "politifact14289  1  0\n",
              "politifact8152   0  1\n",
              "...             .. ..\n",
              "politifact7511   0  1\n",
              "politifact160    0  1\n",
              "politifact13443  0  1\n",
              "politifact14003  1  0\n",
              "politifact10903  0  1\n",
              "\n",
              "[62 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-386c4390-2edb-4643-ae4d-efd11650f376\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>politifact15371</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact13132</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact15187</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14289</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact8152</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact7511</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact160</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact13443</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14003</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10903</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-386c4390-2edb-4643-ae4d-efd11650f376')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-386c4390-2edb-4643-ae4d-efd11650f376 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-386c4390-2edb-4643-ae4d-efd11650f376');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHrHxoEJBppV",
        "outputId": "3b7619e2-b5bf-44cb-ec6e-252cea7f484a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250, 6, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWXGDpyDKVta",
        "outputId": "31d6d374-4ddb-4150-9a37-b14305e56e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "Uj3qHChMcPYs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "99bae820-9831-4df7-b2f3-0eabc733e045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0  1\n",
              "id                   \n",
              "politifact720    0  1\n",
              "politifact10731  0  1\n",
              "politifact11115  0  1\n",
              "politifact14148  1  0\n",
              "politifact6932   0  1\n",
              "...             .. ..\n",
              "politifact7511   0  1\n",
              "politifact160    0  1\n",
              "politifact13443  0  1\n",
              "politifact14003  1  0\n",
              "politifact10903  0  1\n",
              "\n",
              "[312 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-657e4302-acd7-4fae-ad40-5aec6b0c4b8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>politifact720</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10731</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact11115</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14148</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact6932</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact7511</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact160</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact13443</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14003</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10903</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>312 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-657e4302-acd7-4fae-ad40-5aec6b0c4b8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-657e4302-acd7-4fae-ad40-5aec6b0c4b8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-657e4302-acd7-4fae-ad40-5aec6b0c4b8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REG_PARAM = 1e-13\n",
        "l2_reg = regularizers.l2(REG_PARAM)"
      ],
      "metadata": {
        "id": "A3A4j8FaLcHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n"
      ],
      "metadata": {
        "id": "VASyRsA6pJ3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip glove*.zip\n"
      ],
      "metadata": {
        "id": "LPe1rsbzp0VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GLOVE_DIR = \"/content/drive/MyDrive/glove.6B.100d.txt\"\n",
        "embeddings_index = {}\n",
        "f = open(GLOVE_DIR)\n",
        "for line in f:\n",
        "    try:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = values[1:]\n",
        "        # coefs = np.asarray(y, dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    except:\n",
        "        print(\"except\")\n",
        "        print(word)\n",
        "        pass\n",
        "f.close()\n",
        "print('Total %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTYXTLsvLhhY",
        "outputId": "f4c4bbf3-f5b4-42d1-fa2f-0b87f3f7ce31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KF6l9fw4Apm",
        "outputId": "1eebbd41-ef1f-462d-c2a3-3d490119d7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
        "absent_words = 0\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        absent_words += 1\n",
        "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7ZTdhVvq9OX",
        "outputId": "a81b3dfb-67db-4f62-e0fd-162f8c7d61bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total absent words are 978 which is 5.57 % of total words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1,embed_size,weights=[embedding_matrix], input_length=max_senten_len, trainable=False)"
      ],
      "metadata": {
        "id": "bFMWX8BO4xbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.engine.topology import Layer\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "\n",
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "class AttentionWithContext(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, context_vector_length = 1000, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.context_vector_length = context_vector_length\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "        print('{}_W'.format(self.name))\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'context_vector_length': self.context_vector_length\n",
        "        }\n",
        "        base_config = super(AttentionWithContext, self).get_config()\n",
        "        return {**base_config, **config}\n"
      ],
      "metadata": {
        "id": "OCFoIfaU5FPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_input = Input(shape=(max_senten_len,), dtype='float32')\n",
        "word_sequences = embedding_layer(word_input)\n",
        "embeding_dim = 128\n",
        "word_lstm = Bidirectional(LSTM(embeding_dim, return_sequences=True, kernel_regularizer=l2_reg))(word_sequences)\n",
        "word_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(word_lstm)\n",
        "word_att = AttentionWithContext()(word_dense)\n",
        "wordEncoder = Model(word_input, word_att)\n",
        "\n",
        "sent_input = Input(shape=(max_senten_num, max_senten_len), dtype='float32')\n",
        "sent_encoder = TimeDistributed(wordEncoder)(sent_input)\n",
        "sent_lstm = Bidirectional(LSTM(embeding_dim, return_sequences=True, kernel_regularizer=l2_reg))(sent_encoder)\n",
        "sent_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(sent_lstm)\n",
        "sent_att = Dropout(0.2)(AttentionWithContext()(sent_dense))\n",
        "# sentEncoder = Model(sent_input, sent_att)\n",
        "# preds = Dense(2, activation='sigmoid')(sent_att)\n",
        "dense_cat = Dense(128, activation='relu')(sent_att)\n",
        "# dense_cat shape == feature.shape 1 dim will be diff and rest same. \n",
        "feature_input = Input(shape=f_train.shape[1], dtype='float64', name='text')\n",
        "# fea_encoder = TimeDistributed(sent_encoder)(text_input)\n",
        "\n",
        "# embedded_text = tf.keras.layers.Embedding(64, len(f_train))(text_input)\n",
        "# encoded_feature = tf.keras.layers.LSTM(64)(feature_input)\n",
        "#shape of feature vector\n",
        "# feature_input = Input(shape=(sample_feature_array.shape), dtype='float64')\n",
        "# feature_encoder = tf.keras.layers.TimeDistributed(sample_feature_array)(feature_input)\n",
        "\n",
        "# feature_encoder = TimeDistributed(sample_feature_array)(feature_input)\n",
        "# feature_lstm = Bidirectional(LSTM(embeding_dim, return_sequences=True, kernel_regularizer=l2_reg))(feature_encoder)\n",
        "# feature_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(feature_lstm)\n",
        "# feature_att = Dropout(0.5)(AttentionWithContext()(feature_dense))\n",
        "# merged = tf.keras.layers.concatenate([encoded_feature, dense_cat],axis=-1)\n",
        "merged = tf.keras.layers.Concatenate(axis=1)([feature_input, dense_cat])\n",
        "\n",
        "preds = tf.keras.layers.Dense(2, activation='softmax')(merged)\n",
        "# merged = tf.keras.layers.concatenate([dense_cat, feature_input])\n",
        "\n",
        "# preds = Dense(2, activation='sigmoid')(concatenated)\n",
        "\n",
        "model = Model([sent_input, feature_input], preds)\n",
        "# model = Model(preds, sent_input, text_input)\n",
        "# model.add(GlobalAveragePooling2D())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTdtECWZ41N_",
        "outputId": "886efa20-a6fd-4e01-b8c5-c908d104cc0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_with_context_W\n",
            "attention_with_context_1_W\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(1e-3),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "d3dluKpHAeq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKTPlbry_t6u",
        "outputId": "a537c5ac-3c92-4bfe-a06b-63ebb8ac312a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 6, 40)]      0           []                               \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDistri  (None, 6, 200)      2082396     ['input_2[0][0]']                \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 6, 256)      336896      ['time_distributed_1[0][0]']     \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDistri  (None, 6, 200)      51400       ['bidirectional_1[0][0]']        \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " attention_with_context_1 (Atte  (None, 200)         40400       ['time_distributed_2[0][0]']     \n",
            " ntionWithContext)                                                                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 200)          0           ['attention_with_context_1[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " text (InputLayer)              [(None, 9)]          0           []                               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          25728       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 137)          0           ['text[0][0]',                   \n",
            "                                                                  'dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 2)            276         ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,537,096\n",
            "Trainable params: 780,996\n",
            "Non-trainable params: 1,756,100\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "metadata": {
        "id": "0Brmua8v9SSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.MinMaxScaler()\n",
        "f_train_transform = scaler.fit_transform(f_train)\n",
        "f_val_transform = scaler.fit_transform(f_val)\n",
        "f_test_transform = scaler.fit_transform(f_test)"
      ],
      "metadata": {
        "id": "6u6c8oDC3VCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_train_arr = [x_train, f_train_transform]\n",
        "merged_val_arr = [x_val, f_val_transform]\n",
        "# merged_test_arr = [x_test, f_test_transform]"
      ],
      "metadata": {
        "id": "bKSJz_AKYMfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_val_arr"
      ],
      "metadata": {
        "id": "epoBuEEoX9My",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31cd268-1570-4ef4-a7c7-713fc978d5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[  61,   41,    4, ...,    5,  210,  101],\n",
              "         [   6,  478,  101, ...,    0,    0,    0],\n",
              "         [   2, 2071, 1636, ...,   21,    8,  214],\n",
              "         [ 255,   84,   18, ...,   14,  710, 2657],\n",
              "         [   3,   15,    6, ...,    0,    0,    0],\n",
              "         [  20,  785,    2, ...,    0,    0,    0]],\n",
              " \n",
              "        [[ 267,  569,   10, ...,    0,    0,    0],\n",
              "         [   8,    6,  708, ...,    0,    0,    0],\n",
              "         [ 267,  569,   83, ...,    0,    0,    0],\n",
              "         [  11, 4530,  222, ...,    0,    0,    0],\n",
              "         [  11,  559,    2, ...,    0,    0,    0],\n",
              "         [ 637,   17, 3437, ...,    0,    0,    0]],\n",
              " \n",
              "        [[ 384, 5295,  264, ...,    0,    0,    0],\n",
              "         [1164,  287, 5661, ...,    0,    0,    0],\n",
              "         [ 758,  234,   23, ...,    0,    0,    0],\n",
              "         [ 104,    2, 2656, ...,    8,  225,  129],\n",
              "         [ 267,  376, 3415, ...,    0,    0,    0],\n",
              "         [ 153,   55,   10, ...,    0,    0,    0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 268, 1536,  143, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0]],\n",
              " \n",
              "        [[6330,    4,   40, ...,    0,    0,    0],\n",
              "         [ 980, 1790, 2466, ...,  330, 5890, 3105],\n",
              "         [   2,  488, 1404, ...,    0,    0,    0],\n",
              "         [ 367,    3, 1846, ...,    0,    0,    0],\n",
              "         [ 255, 2928,    3, ...,    0,    0,    0],\n",
              "         [1781,    5,   52, ...,    0,    0,    0]],\n",
              " \n",
              "        [[  71,  479,    0, ...,    0,    0,    0],\n",
              "         [  13, 2219,   62, ...,    0,    0,    0],\n",
              "         [1791,    8, 2104, ...,    0,    0,    0],\n",
              "         [ 637,    6, 1796, ...,    0,    0,    0],\n",
              "         [   2,  488, 1172, ...,    0,    0,    0],\n",
              "         [   2,  242,   10, ...,    0,    0,    0]]], dtype=int32),\n",
              " array([[5.71428571e-01, 2.73224044e-01, 1.66666667e-01, 1.44302679e-04,\n",
              "         2.80121012e-01, 1.08791209e-01, 8.46153846e-01, 6.15384615e-01,\n",
              "         1.00000000e+00],\n",
              "        [0.00000000e+00, 0.00000000e+00, 3.33333333e-01, 1.01495855e-04,\n",
              "         4.35445545e-01, 0.00000000e+00, 9.16666667e-01, 1.00000000e+00,\n",
              "         3.99051480e-01],\n",
              "        [5.71428571e-01, 3.26757090e-01, 1.66666667e-01, 1.14072932e-04,\n",
              "         3.07390074e-01, 1.34249781e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         6.86078296e-01],\n",
              "        [5.71428571e-01, 1.45797599e-01, 1.66666667e-01, 1.83304807e-04,\n",
              "         5.20618453e-01, 3.40080972e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         1.22951780e-02],\n",
              "        [5.71428571e-01, 4.13385827e-01, 1.66666667e-01, 1.65201693e-01,\n",
              "         4.86276854e-01, 2.88461538e-01, 0.00000000e+00, 3.33333333e-01,\n",
              "         1.52356276e-01],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.66666667e-01, 1.02263189e-04,\n",
              "         4.35445545e-01, 0.00000000e+00, 2.15686275e-01, 1.56862745e-01,\n",
              "         0.00000000e+00],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.66666667e-01, 1.00000000e+00,\n",
              "         4.35445545e-01, 0.00000000e+00, 1.64179104e-01, 5.97014925e-01,\n",
              "         2.53185328e-01],\n",
              "        [2.85714286e-01, 2.53623188e-01, 1.66666667e-01, 1.00744507e-04,\n",
              "         4.32673267e-01, 1.73076923e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         2.18113144e-02],\n",
              "        [4.28571429e-01, 2.88461538e-01, 1.66666667e-01, 1.20435407e-04,\n",
              "         3.25199853e-01, 1.12087912e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         1.90178365e-02],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.66666667e-01, 1.01499851e-04,\n",
              "         4.35445545e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         6.21776062e-01],\n",
              "        [1.42857143e-01, 2.00000000e-01, 1.66666667e-01, 1.32015390e-02,\n",
              "         4.35445545e-01, 2.30769231e-01, 0.00000000e+00, 3.33333333e-01,\n",
              "         0.00000000e+00],\n",
              "        [5.71428571e-01, 1.50976909e-01, 1.66666667e-01, 4.59984522e-04,\n",
              "         7.06765677e-01, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         8.73896734e-03],\n",
              "        [5.71428571e-01, 3.11320755e-01, 1.66666667e-01, 1.41766881e-03,\n",
              "         5.64319379e-01, 5.25641026e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         6.00801340e-03],\n",
              "        [2.85714286e-01, 1.24610592e-01, 1.66666667e-01, 3.38828253e-01,\n",
              "         4.81864686e-01, 2.30769231e-01, 0.00000000e+00, 3.47826087e-01,\n",
              "         5.15065132e-03],\n",
              "        [1.42857143e-01, 2.70270270e-01, 1.66666667e-01, 1.31949407e-04,\n",
              "         1.20792079e-01, 1.15384615e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         6.83648127e-01],\n",
              "        [5.71428571e-01, 1.69082126e-01, 1.66666667e-01, 2.06196926e-04,\n",
              "         9.85368537e-02, 3.29670330e-02, 7.33333333e-01, 0.00000000e+00,\n",
              "         8.69073359e-01],\n",
              "        [2.85714286e-01, 1.85185185e-01, 1.66666667e-01, 1.25766777e-04,\n",
              "         2.20180018e-01, 7.69230769e-02, 4.07407407e-01, 0.00000000e+00,\n",
              "         5.27344646e-01],\n",
              "        [5.71428571e-01, 4.04040404e-01, 1.66666667e-01, 3.08276274e-04,\n",
              "         3.72172956e-01, 1.73076923e-01, 6.47058824e-01, 0.00000000e+00,\n",
              "         4.76989977e-02],\n",
              "        [1.42857143e-01, 2.40384615e-02, 1.66666667e-01, 1.99423209e-03,\n",
              "         4.35445545e-01, 2.30769231e-01, 0.00000000e+00, 2.96296296e-01,\n",
              "         1.61581155e-02],\n",
              "        [5.71428571e-01, 7.53246753e-01, 1.66666667e-01, 1.70000361e-04,\n",
              "         4.11793179e-01, 2.00668896e-01, 5.78947368e-01, 4.21052632e-01,\n",
              "         1.04669308e-02],\n",
              "        [2.85714286e-01, 4.16666667e-01, 3.33333333e-01, 1.16498825e-04,\n",
              "         2.28547855e-01, 1.28205128e-01, 6.47058824e-01, 0.00000000e+00,\n",
              "         7.00361647e-01],\n",
              "        [5.71428571e-01, 2.43697479e-01, 1.66666667e-01, 1.21738275e-04,\n",
              "         3.47212620e-01, 1.39676113e-01, 6.87500000e-01, 5.00000000e-01,\n",
              "         8.90400895e-01],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.66666667e-01, 1.14200821e-04,\n",
              "         4.35445545e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [5.71428571e-01, 1.71460177e-01, 5.00000000e-01, 3.62960723e-01,\n",
              "         3.17932216e-01, 1.18681319e-01, 8.46153846e-01, 6.15384615e-01,\n",
              "         3.69278539e-02],\n",
              "        [5.71428571e-01, 4.43786982e-01, 1.66666667e-01, 1.22961213e-04,\n",
              "         4.81033345e-01, 3.46153846e-01, 0.00000000e+00, 3.47826087e-01,\n",
              "         1.71693587e-02],\n",
              "        [1.42857143e-01, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         1.00000000e+00, 4.61538462e-01, 4.58333333e-01, 0.00000000e+00,\n",
              "         7.61204633e-01],\n",
              "        [5.71428571e-01, 5.68181818e-02, 1.00000000e+00, 1.03705936e-04,\n",
              "         1.79985651e-01, 4.39560440e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         3.73247631e-01],\n",
              "        [1.42857143e-01, 9.43396226e-02, 1.66666667e-01, 1.88715308e-03,\n",
              "         4.10275028e-01, 2.30769231e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [1.42857143e-01, 2.17391304e-01, 1.66666667e-01, 2.26363133e-02,\n",
              "         4.08739274e-01, 1.73076923e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         1.06496559e-02],\n",
              "        [1.00000000e+00, 6.11707728e-01, 1.66666667e-01, 1.05104721e-04,\n",
              "         4.79351277e-01, 2.94041762e-01, 0.00000000e+00, 6.66666667e-01,\n",
              "         1.33372021e-01],\n",
              "        [5.71428571e-01, 7.75193798e-02, 1.66666667e-01, 1.01923484e-04,\n",
              "         5.03219655e-01, 3.62637363e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         3.57846218e-03],\n",
              "        [1.42857143e-01, 5.00000000e-01, 1.66666667e-01, 1.10124361e-04,\n",
              "         2.49953795e-01, 1.73076923e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         2.35364221e-01],\n",
              "        [1.42857143e-01, 8.26446281e-02, 1.66666667e-01, 6.58936988e-01,\n",
              "         4.95742574e-01, 2.30769231e-01, 0.00000000e+00, 2.75862069e-01,\n",
              "         3.83004244e-01],\n",
              "        [5.71428571e-01, 6.09243697e-01, 1.66666667e-01, 8.56147946e-01,\n",
              "         5.38142507e-01, 3.31730769e-01, 0.00000000e+00, 3.63636364e-01,\n",
              "         1.20383018e-01],\n",
              "        [5.71428571e-01, 1.77316294e-01, 1.66666667e-01, 3.28475532e-03,\n",
              "         3.73913775e-01, 1.85502959e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         8.71631737e-02],\n",
              "        [5.71428571e-01, 6.06060606e-01, 1.66666667e-01, 1.02219227e-04,\n",
              "         6.71639164e-01, 6.92307692e-01, 0.00000000e+00, 2.58064516e-01,\n",
              "         4.00671581e-01],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.66666667e-01, 1.04549203e-04,\n",
              "         4.35445545e-01, 0.00000000e+00, 5.23809524e-01, 3.80952381e-01,\n",
              "         0.00000000e+00],\n",
              "        [5.71428571e-01, 2.24103586e-01, 1.66666667e-01, 1.01292032e-04,\n",
              "         2.81843536e-01, 1.12929624e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         7.42834915e-01],\n",
              "        [5.71428571e-01, 5.45454545e-01, 1.66666667e-01, 1.01483865e-04,\n",
              "         3.81653733e-01, 1.73755656e-01, 1.00000000e+00, 0.00000000e+00,\n",
              "         2.69778870e-02],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.66666667e-01, 1.01192119e-04,\n",
              "         4.35445545e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.66666667e-01, 7.57841325e-02,\n",
              "         4.35445545e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.66666667e-01, 5.92542437e-01,\n",
              "         4.35445545e-01, 0.00000000e+00, 0.00000000e+00, 6.15384615e-01,\n",
              "         5.72258209e-03],\n",
              "        [4.28571429e-01, 4.09090909e-01, 1.66666667e-01, 1.01064230e-04,\n",
              "         3.64593149e-01, 1.33603239e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         5.70004212e-01],\n",
              "        [2.85714286e-01, 5.12820513e-01, 1.66666667e-01, 1.08505767e-04,\n",
              "         3.57964796e-01, 1.73076923e-01, 7.85714286e-01, 0.00000000e+00,\n",
              "         6.03538264e-01],\n",
              "        [5.71428571e-01, 2.50000000e-01, 1.66666667e-01, 1.29251750e-04,\n",
              "         4.14171201e-01, 2.14854111e-01, 6.11111111e-01, 4.44444444e-01,\n",
              "         4.02856718e-01],\n",
              "        [0.00000000e+00, 0.00000000e+00, 3.33333333e-01, 2.55294287e-04,\n",
              "         4.35445545e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         7.86918010e-02],\n",
              "        [5.71428571e-01, 2.76796231e-01, 1.66666667e-01, 2.53571487e-01,\n",
              "         4.85102517e-01, 3.21678322e-01, 0.00000000e+00, 3.20000000e-01,\n",
              "         2.26469342e-01],\n",
              "        [4.28571429e-01, 2.61437908e-01, 1.66666667e-01, 1.08222014e-04,\n",
              "         4.27201792e-01, 2.01923077e-01, 4.58333333e-01, 0.00000000e+00,\n",
              "         4.79254927e-01],\n",
              "        [7.14285714e-01, 3.02782324e-01, 1.66666667e-01, 9.03334690e-03,\n",
              "         4.63338800e-01, 2.77546778e-01, 5.78947368e-01, 8.42105263e-01,\n",
              "         1.06381589e-01],\n",
              "        [5.71428571e-01, 4.73684211e-01, 1.66666667e-01, 1.01343987e-04,\n",
              "         5.22083333e-01, 3.62637363e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         6.14834383e-03],\n",
              "        [2.85714286e-01, 3.84615385e-01, 1.66666667e-01, 7.67215112e-01,\n",
              "         2.50726073e-01, 7.69230769e-02, 4.07407407e-01, 2.96296296e-01,\n",
              "         1.61060291e-01],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.66666667e-01, 1.14328710e-04,\n",
              "         4.35445545e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         2.57764908e-01],\n",
              "        [1.42857143e-01, 1.42857143e-01, 1.66666667e-01, 1.78429042e-04,\n",
              "         0.00000000e+00, 1.15384615e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         6.06971870e-02],\n",
              "        [5.71428571e-01, 3.21100917e-01, 1.66666667e-01, 1.04293425e-04,\n",
              "         2.15016502e-01, 9.89010989e-02, 0.00000000e+00, 4.44444444e-01,\n",
              "         1.96843895e-02],\n",
              "        [1.42857143e-01, 1.40350877e-01, 1.66666667e-01, 8.57364973e-02,\n",
              "         4.96280334e-01, 4.23076923e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         6.36568448e-02],\n",
              "        [5.71428571e-01, 7.87671233e-01, 1.66666667e-01, 1.24839582e-04,\n",
              "         5.08143778e-01, 3.33008763e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         5.51028279e-01],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.66666667e-01, 6.92072331e-01,\n",
              "         4.35445545e-01, 0.00000000e+00, 5.50000000e-01, 4.00000000e-01,\n",
              "         2.02729433e-01],\n",
              "        [1.42857143e-01, 1.35135135e-01, 1.66666667e-01, 9.33126129e-01,\n",
              "         7.76600660e-01, 6.92307692e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         1.09485547e-02],\n",
              "        [4.28571429e-01, 8.97435897e-01, 1.66666667e-01, 4.95977819e-01,\n",
              "         4.75731573e-01, 1.97802198e-01, 3.54838710e-01, 2.58064516e-01,\n",
              "         8.13454113e-02],\n",
              "        [1.42857143e-01, 1.42857143e-01, 3.33333333e-01, 9.28509627e-04,\n",
              "         4.87128713e-02, 1.15384615e-01, 0.00000000e+00, 3.33333333e-01,\n",
              "         1.83706564e-02],\n",
              "        [2.85714286e-01, 8.33333333e-01, 3.33333333e-01, 5.66563962e-04,\n",
              "         4.24838651e-01, 1.67832168e-01, 6.47058824e-01, 0.00000000e+00,\n",
              "         3.53831403e-01],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.66666667e-01, 1.01723657e-04,\n",
              "         4.35445545e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00]])]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "berthist = model.fit(merged_train_arr, y_train, validation_data= (merged_val_arr, y_val), epochs=100, batch_size=64, verbose=1, callbacks=[earlyStopping, mcp_save])\n",
        "print(time.time()-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJQ4mHZY9Wlt",
        "outputId": "ac1f04b4-1d3a-47f4-b6a0-084b56b971eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 13s 1s/step - loss: 0.7360 - accuracy: 0.5040 - val_loss: 0.6527 - val_accuracy: 0.6935\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 3s 801ms/step - loss: 0.6899 - accuracy: 0.5400 - val_loss: 0.6525 - val_accuracy: 0.7742\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 3s 625ms/step - loss: 0.6728 - accuracy: 0.6000 - val_loss: 0.6220 - val_accuracy: 0.7097\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 2s 608ms/step - loss: 0.6400 - accuracy: 0.6320 - val_loss: 0.5596 - val_accuracy: 0.8226\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 0.5396 - accuracy: 0.7520 - val_loss: 0.4638 - val_accuracy: 0.7581\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 3s 683ms/step - loss: 0.5133 - accuracy: 0.7600 - val_loss: 0.4319 - val_accuracy: 0.8226\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 3s 670ms/step - loss: 0.4357 - accuracy: 0.8040 - val_loss: 0.5013 - val_accuracy: 0.7581\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 3s 691ms/step - loss: 0.4647 - accuracy: 0.8000 - val_loss: 0.4395 - val_accuracy: 0.8548\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 3s 819ms/step - loss: 0.4537 - accuracy: 0.7880 - val_loss: 0.4912 - val_accuracy: 0.7742\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 2s 599ms/step - loss: 0.4182 - accuracy: 0.8160 - val_loss: 0.4674 - val_accuracy: 0.7903\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 3s 635ms/step - loss: 0.3935 - accuracy: 0.8040 - val_loss: 0.5386 - val_accuracy: 0.8387\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 3s 787ms/step - loss: 0.3709 - accuracy: 0.8200 - val_loss: 0.4664 - val_accuracy: 0.8387\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 2s 580ms/step - loss: 0.3567 - accuracy: 0.8200 - val_loss: 0.5109 - val_accuracy: 0.8065\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.3192 - accuracy: 0.8560 - val_loss: 0.5607 - val_accuracy: 0.8065\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 2s 605ms/step - loss: 0.3117 - accuracy: 0.8560 - val_loss: 0.7257 - val_accuracy: 0.7581\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 3s 651ms/step - loss: 0.2910 - accuracy: 0.8560 - val_loss: 0.6444 - val_accuracy: 0.8065\n",
            "51.90693497657776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"/content/drive/MyDrive/fake_bert/HAN_model_finetune\""
      ],
      "metadata": {
        "id": "FNpV1wmG9zlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, file_name)"
      ],
      "metadata": {
        "id": "OvIGjJmi91u_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7f9c9d-888e-4c8b-a905-4a79d6868576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hanModel_pred = model.predict([x_val, f_val])\n",
        "# hanLayerModel_y = np.argmax(hanModel_pred, axis = 1)\n",
        "# hanLayerModel_y\n",
        "\n",
        "hanModel_pred = model.predict(merged_val_arr)\n",
        "hanLayerModel_y = np.argmax(hanModel_pred, axis = 1)\n",
        "hanLayerModel_y"
      ],
      "metadata": {
        "id": "ieyew1Lx95CW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f39077-2b50-45d7-d5f8-a1a8deeedeee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 113ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(hanLayerModel_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC537jmrbkxN",
        "outputId": "6e8638b2-2cf8-4870-b683-978b3cf7c888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_val[1].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUiTQoWzOy4i",
        "outputId": "157557a4-a947-44b7-db7f-66c1b64abe3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy:', accuracy_score(hanLayerModel_y, y_val[1].values))\n",
        "print('F1 score:', f1_score(y_val[1].values, hanLayerModel_y))\n",
        "print('Recall:', recall_score(np.array(y_val[1]), hanLayerModel_y))\n",
        "print('Precision:', precision_score(np.array(y_val[1]), hanLayerModel_y))\n",
        "print('ROC_AUC Score:', roc_auc_score(np.array(y_val[1]), hanLayerModel_y))\n",
        "\n",
        "print(classification_report(np.array(y_val[1]), hanLayerModel_y))"
      ],
      "metadata": {
        "id": "OkY6U1nP99ZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31cf3468-eec0-4e83-ce0a-cc136a2d9185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8064516129032258\n",
            "F1 score: 0.7999999999999999\n",
            "Recall: 0.75\n",
            "Precision: 0.8571428571428571\n",
            "ROC_AUC Score: 0.8083333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.87      0.81        30\n",
            "           1       0.86      0.75      0.80        32\n",
            "\n",
            "    accuracy                           0.81        62\n",
            "   macro avg       0.81      0.81      0.81        62\n",
            "weighted avg       0.81      0.81      0.81        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hanLayerModel_y"
      ],
      "metadata": {
        "id": "elvBAVSnOr7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b5bb2b-7e12-417f-e0bb-8a9eecfe3e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}
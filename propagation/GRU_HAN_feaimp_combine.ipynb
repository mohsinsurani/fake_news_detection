{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgupxXAn-5HF",
        "outputId": "99865483-7f19-4956-f6d1-879eebee3eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import sys\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from keras import Sequential, regularizers \n",
        "\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras import losses\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten, InputLayer\n",
        "\n",
        "import time\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import torch\n",
        "from sklearn.metrics import precision_score, \\\n",
        "    recall_score, confusion_matrix, classification_report, \\\n",
        "    accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn import metrics\n",
        "import plotly.express as px\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer,  text_to_word_sequence\n",
        "# from keras.engine.topology import Layer\n",
        "from keras import initializers as initializers, regularizers, constraints\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Embedding, Input, Dense, LSTM, GRU, Bidirectional, TimeDistributed, Dropout\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.models import Model\n",
        "from nltk import tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_df = \"/content/drive/MyDrive/fake_bert/politifact_global_feature.pkl\""
      ],
      "metadata": {
        "id": "BxH344MZ_D_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pickle.load(open(path_df, \"rb\"))"
      ],
      "metadata": {
        "id": "AOIr3tZp_J-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "b5z39z9wJkPK",
        "outputId": "d7306ad7-526c-4340-a280-73ce0b36a791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                              text  \\\n",
              "id                                                                   \n",
              "politifact720    Organizing for ’18\\n\\nThrough Election Day\\n\\n...   \n",
              "politifact10731  COLUMBUS, Ohio — America's role as a world lea...   \n",
              "politifact11115  In the course of the email review, State Depar...   \n",
              "politifact14148  We all get lazy from time to time and just wan...   \n",
              "politifact6932   Mitt Romney came to coal country on Aug. 14, s...   \n",
              "\n",
              "                                                             title  \\\n",
              "id                                                                   \n",
              "politifact720                                Organizing for Action   \n",
              "politifact10731  Call 'Islamic terrorism' what it is: a threat ...   \n",
              "politifact11115   Inquiry Sought in Hillary Clinton’s Use of Email   \n",
              "politifact14148  NASA Will Pay You 18000 USD To Stay In Bed And...   \n",
              "politifact6932   Barack Obama says Mitt Romney condemned coal-f...   \n",
              "\n",
              "                                                           top_img  \\\n",
              "id                                                                   \n",
              "politifact720    https://secure.assets.bostatic.com/apps/quincy...   \n",
              "politifact10731  http://triblive.com/csp/mediapool/sites/dt.com...   \n",
              "politifact11115  https://static01.nyt.com/images/2015/07/24/us/...   \n",
              "politifact14148  http://reflectionofmind.org/wp-content/uploads...   \n",
              "politifact6932   http://static.politifact.com.s3.amazonaws.com/...   \n",
              "\n",
              "                 publish_date  \\\n",
              "id                              \n",
              "politifact720            None   \n",
              "politifact10731  1429079762.0   \n",
              "politifact11115  1437721200.0   \n",
              "politifact14148  1482942009.0   \n",
              "politifact6932   1345705200.0   \n",
              "\n",
              "                                                            images  \\\n",
              "id                                                                   \n",
              "politifact720    [https://secure.assets.bostatic.com/apps/quinc...   \n",
              "politifact10731  [http://triblive.com/csp/mediapool/sites/TribL...   \n",
              "politifact11115  [https://static01.nyt.com/images/2015/07/24/us...   \n",
              "politifact14148  [http://reflectionofmind.org/wp-content/upload...   \n",
              "politifact6932   [http://metric.politifact.com/b/ss/spttbglobal...   \n",
              "\n",
              "                     source  target  \\\n",
              "id                                    \n",
              "politifact720    politifact       1   \n",
              "politifact10731  politifact       1   \n",
              "politifact11115  politifact       1   \n",
              "politifact14148  politifact       0   \n",
              "politifact6932   politifact       1   \n",
              "\n",
              "                                                         tweet_mod  \\\n",
              "id                                                                   \n",
              "politifact720    [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "politifact10731  [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "politifact11115  [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "politifact14148  [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "politifact6932   [{'time': None, 'type': 1, 'user': 1716929114,...   \n",
              "\n",
              "                                                         comp_text  \\\n",
              "id                                                                   \n",
              "politifact720    Organizing for 18 Through Election Day Sometim...   \n",
              "politifact10731  COLUMBUS Ohio America's role as a world leader...   \n",
              "politifact11115  In the course of the email review State Depart...   \n",
              "politifact14148  We all get lazy from time to time and just wan...   \n",
              "politifact6932   Mitt Romney came to coal country on Aug. 14 st...   \n",
              "\n",
              "                                                          lem_text  ...  \\\n",
              "id                                                                  ...   \n",
              "politifact720    organize for 18 through election day sometimes...  ...   \n",
              "politifact10731  columbus ohio americas role a a world leader a...  ...   \n",
              "politifact11115  in the course of the email review state depart...  ...   \n",
              "politifact14148  we all get lazy from time to time and just wan...  ...   \n",
              "politifact6932   mitt romney come to coal country on aug 14 sta...  ...   \n",
              "\n",
              "                    Sen15     Sen16     Sen17     Sen18     Sen19        G1  \\\n",
              "id                                                                            \n",
              "politifact720    0.949437  0.034845  0.071476  1.681818  0.011628  0.012289   \n",
              "politifact10731  0.694333  0.000000 -0.738400  1.250000  0.041667  0.046498   \n",
              "politifact11115  0.778346  0.012754 -0.472698  1.156863  0.000543  0.000609   \n",
              "politifact14148  0.829039  0.098993  0.134468  1.240000  0.000836  0.000885   \n",
              "politifact6932   0.642184  0.016658 -0.765808  1.000000  0.025000  0.025214   \n",
              "\n",
              "                     G2      G3            G4      G5  \n",
              "id                                                     \n",
              "politifact720      79.0    86.0  1.866903e-04    85.0  \n",
              "politifact10731    20.0    24.0  3.071834e-03    23.0  \n",
              "politifact11115  1673.0  1842.0  5.721557e-07  1841.0  \n",
              "politifact14148  1089.0  1196.0  1.024639e-06  1195.0  \n",
              "politifact6932     38.0    40.0  6.738988e-04    39.0  \n",
              "\n",
              "[5 rows x 67 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc18b4f7-5aec-417c-b607-153db8e5451f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>top_img</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>images</th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>tweet_mod</th>\n",
              "      <th>comp_text</th>\n",
              "      <th>lem_text</th>\n",
              "      <th>...</th>\n",
              "      <th>Sen15</th>\n",
              "      <th>Sen16</th>\n",
              "      <th>Sen17</th>\n",
              "      <th>Sen18</th>\n",
              "      <th>Sen19</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "      <th>G4</th>\n",
              "      <th>G5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>politifact720</th>\n",
              "      <td>Organizing for ’18\\n\\nThrough Election Day\\n\\n...</td>\n",
              "      <td>Organizing for Action</td>\n",
              "      <td>https://secure.assets.bostatic.com/apps/quincy...</td>\n",
              "      <td>None</td>\n",
              "      <td>[https://secure.assets.bostatic.com/apps/quinc...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>Organizing for 18 Through Election Day Sometim...</td>\n",
              "      <td>organize for 18 through election day sometimes...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.949437</td>\n",
              "      <td>0.034845</td>\n",
              "      <td>0.071476</td>\n",
              "      <td>1.681818</td>\n",
              "      <td>0.011628</td>\n",
              "      <td>0.012289</td>\n",
              "      <td>79.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>1.866903e-04</td>\n",
              "      <td>85.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10731</th>\n",
              "      <td>COLUMBUS, Ohio — America's role as a world lea...</td>\n",
              "      <td>Call 'Islamic terrorism' what it is: a threat ...</td>\n",
              "      <td>http://triblive.com/csp/mediapool/sites/dt.com...</td>\n",
              "      <td>1429079762.0</td>\n",
              "      <td>[http://triblive.com/csp/mediapool/sites/TribL...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>COLUMBUS Ohio America's role as a world leader...</td>\n",
              "      <td>columbus ohio americas role a a world leader a...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.694333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.738400</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.046498</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3.071834e-03</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact11115</th>\n",
              "      <td>In the course of the email review, State Depar...</td>\n",
              "      <td>Inquiry Sought in Hillary Clinton’s Use of Email</td>\n",
              "      <td>https://static01.nyt.com/images/2015/07/24/us/...</td>\n",
              "      <td>1437721200.0</td>\n",
              "      <td>[https://static01.nyt.com/images/2015/07/24/us...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>In the course of the email review State Depart...</td>\n",
              "      <td>in the course of the email review state depart...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.778346</td>\n",
              "      <td>0.012754</td>\n",
              "      <td>-0.472698</td>\n",
              "      <td>1.156863</td>\n",
              "      <td>0.000543</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>1673.0</td>\n",
              "      <td>1842.0</td>\n",
              "      <td>5.721557e-07</td>\n",
              "      <td>1841.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14148</th>\n",
              "      <td>We all get lazy from time to time and just wan...</td>\n",
              "      <td>NASA Will Pay You 18000 USD To Stay In Bed And...</td>\n",
              "      <td>http://reflectionofmind.org/wp-content/uploads...</td>\n",
              "      <td>1482942009.0</td>\n",
              "      <td>[http://reflectionofmind.org/wp-content/upload...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>We all get lazy from time to time and just wan...</td>\n",
              "      <td>we all get lazy from time to time and just wan...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.829039</td>\n",
              "      <td>0.098993</td>\n",
              "      <td>0.134468</td>\n",
              "      <td>1.240000</td>\n",
              "      <td>0.000836</td>\n",
              "      <td>0.000885</td>\n",
              "      <td>1089.0</td>\n",
              "      <td>1196.0</td>\n",
              "      <td>1.024639e-06</td>\n",
              "      <td>1195.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact6932</th>\n",
              "      <td>Mitt Romney came to coal country on Aug. 14, s...</td>\n",
              "      <td>Barack Obama says Mitt Romney condemned coal-f...</td>\n",
              "      <td>http://static.politifact.com.s3.amazonaws.com/...</td>\n",
              "      <td>1345705200.0</td>\n",
              "      <td>[http://metric.politifact.com/b/ss/spttbglobal...</td>\n",
              "      <td>politifact</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'time': None, 'type': 1, 'user': 1716929114,...</td>\n",
              "      <td>Mitt Romney came to coal country on Aug. 14 st...</td>\n",
              "      <td>mitt romney come to coal country on aug 14 sta...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.642184</td>\n",
              "      <td>0.016658</td>\n",
              "      <td>-0.765808</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.025214</td>\n",
              "      <td>38.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>6.738988e-04</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 67 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc18b4f7-5aec-417c-b607-153db8e5451f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc18b4f7-5aec-417c-b607-153db8e5451f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc18b4f7-5aec-417c-b607-153db8e5451f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_lens = []\n",
        "sent_nums = []\n",
        "texts = []\n",
        "paras = []\n",
        "\n",
        "for idx in range(df[\"comp_text\"].shape[0]):\n",
        "    text = df[\"comp_text\"][idx]\n",
        "    texts.append(text)\n",
        "    sentences = tokenize.sent_tokenize(text)\n",
        "    sent_nums.append(len(sentences))\n",
        "    for sent in sentences:\n",
        "        sent_lens.append(len(text_to_word_sequence(sent)))\n",
        "    print(len(sentences))\n",
        "    paras.append(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW6KwrZlETFg",
        "outputId": "82b38fc1-6901-491c-ae67-5e2b6e497d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "44\n",
            "15\n",
            "30\n",
            "85\n",
            "11\n",
            "7\n",
            "18\n",
            "11\n",
            "6\n",
            "10\n",
            "30\n",
            "312\n",
            "36\n",
            "9\n",
            "12\n",
            "24\n",
            "1\n",
            "2\n",
            "4\n",
            "27\n",
            "1\n",
            "15\n",
            "33\n",
            "9\n",
            "1\n",
            "1\n",
            "80\n",
            "4\n",
            "4\n",
            "10\n",
            "11\n",
            "21\n",
            "919\n",
            "61\n",
            "267\n",
            "3\n",
            "464\n",
            "32\n",
            "8\n",
            "4\n",
            "3\n",
            "11\n",
            "668\n",
            "3\n",
            "7\n",
            "53\n",
            "69\n",
            "1\n",
            "21\n",
            "155\n",
            "66\n",
            "3\n",
            "26\n",
            "56\n",
            "12\n",
            "462\n",
            "16\n",
            "7\n",
            "3\n",
            "2\n",
            "73\n",
            "209\n",
            "16\n",
            "17\n",
            "15\n",
            "34\n",
            "22\n",
            "18\n",
            "1\n",
            "13\n",
            "40\n",
            "3\n",
            "49\n",
            "43\n",
            "8\n",
            "5\n",
            "21\n",
            "1\n",
            "2\n",
            "18\n",
            "1\n",
            "8\n",
            "5\n",
            "1\n",
            "3\n",
            "47\n",
            "3\n",
            "17\n",
            "237\n",
            "23\n",
            "5\n",
            "16\n",
            "15\n",
            "41\n",
            "6\n",
            "15\n",
            "13\n",
            "44\n",
            "40\n",
            "6\n",
            "48\n",
            "296\n",
            "796\n",
            "12\n",
            "1\n",
            "28\n",
            "140\n",
            "21\n",
            "29\n",
            "23\n",
            "4\n",
            "18\n",
            "19\n",
            "13\n",
            "16\n",
            "4\n",
            "22\n",
            "60\n",
            "6\n",
            "15\n",
            "3\n",
            "3\n",
            "11\n",
            "3\n",
            "7\n",
            "2\n",
            "32\n",
            "63\n",
            "83\n",
            "1\n",
            "23\n",
            "52\n",
            "51\n",
            "14\n",
            "1\n",
            "42\n",
            "1\n",
            "44\n",
            "22\n",
            "9\n",
            "10\n",
            "3\n",
            "1\n",
            "38\n",
            "4\n",
            "4\n",
            "2\n",
            "67\n",
            "43\n",
            "39\n",
            "9\n",
            "52\n",
            "11\n",
            "64\n",
            "698\n",
            "18\n",
            "20\n",
            "49\n",
            "11\n",
            "1302\n",
            "511\n",
            "11\n",
            "40\n",
            "12\n",
            "12\n",
            "3\n",
            "3\n",
            "7\n",
            "2\n",
            "37\n",
            "105\n",
            "253\n",
            "4\n",
            "22\n",
            "18\n",
            "1259\n",
            "5\n",
            "33\n",
            "1\n",
            "191\n",
            "63\n",
            "12\n",
            "5\n",
            "918\n",
            "693\n",
            "22\n",
            "12\n",
            "8\n",
            "36\n",
            "43\n",
            "3\n",
            "14\n",
            "23\n",
            "58\n",
            "39\n",
            "14\n",
            "29\n",
            "26\n",
            "28\n",
            "5\n",
            "4\n",
            "35\n",
            "25\n",
            "3\n",
            "19\n",
            "92\n",
            "8\n",
            "3\n",
            "40\n",
            "17\n",
            "28\n",
            "13\n",
            "47\n",
            "20\n",
            "52\n",
            "10\n",
            "3\n",
            "10\n",
            "7\n",
            "12\n",
            "4\n",
            "65\n",
            "5\n",
            "49\n",
            "33\n",
            "1\n",
            "2\n",
            "27\n",
            "30\n",
            "4\n",
            "14\n",
            "280\n",
            "8\n",
            "1041\n",
            "967\n",
            "91\n",
            "1\n",
            "15\n",
            "75\n",
            "110\n",
            "1\n",
            "30\n",
            "2\n",
            "64\n",
            "47\n",
            "4\n",
            "4\n",
            "13\n",
            "11\n",
            "12\n",
            "18\n",
            "52\n",
            "14\n",
            "1\n",
            "1\n",
            "22\n",
            "23\n",
            "10\n",
            "15\n",
            "3\n",
            "24\n",
            "18\n",
            "19\n",
            "5\n",
            "44\n",
            "67\n",
            "22\n",
            "4\n",
            "16\n",
            "12\n",
            "4\n",
            "30\n",
            "1\n",
            "11\n",
            "11\n",
            "49\n",
            "1\n",
            "1\n",
            "618\n",
            "82\n",
            "48\n",
            "12\n",
            "50\n",
            "244\n",
            "44\n",
            "48\n",
            "18\n",
            "6\n",
            "1267\n",
            "11\n",
            "213\n",
            "21\n",
            "29\n",
            "42\n",
            "173\n",
            "551\n",
            "5\n",
            "1\n",
            "196\n",
            "700\n",
            "76\n",
            "28\n",
            "14\n",
            "176\n",
            "19\n",
            "13\n",
            "16\n",
            "1\n",
            "1\n",
            "10\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sentences[0]\n",
        "# print(\"---\")\n",
        "paras[0]\n",
        "# len(paras[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bax7g5rVJ_Gq",
        "outputId": "d8f37b41-e268-4a99-db57-eff1aa069a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Organizing for 18 Through Election Day Sometimes fighting for progress on the issues means fighting to win on election day.',\n",
              " \"This year many of the issues we've fought for for years are on the ballot so we're Organizing for 18.\",\n",
              " 'Host or find an event near you this election season.',\n",
              " 'Find an event']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features=10000\n",
        "max_senten_len=40\n",
        "max_senten_num=6\n",
        "embed_size=100\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "metadata": {
        "id": "Stonxlk1BXVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_features, oov_token=True)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "data = np.zeros((len(texts), max_senten_num, max_senten_len), dtype='int32')\n",
        "for i, sentences in enumerate(paras):\n",
        "    for j, sent in enumerate(sentences):\n",
        "        if j< max_senten_num:\n",
        "            wordTokens = text_to_word_sequence(sent)\n",
        "            k=0\n",
        "            for _, word in enumerate(wordTokens):\n",
        "                try:\n",
        "                    if k<max_senten_len and tokenizer.word_index[word]<max_features:\n",
        "                        data[i,j,k] = tokenizer.word_index[word]\n",
        "                        k=k+1\n",
        "                except:\n",
        "                    print(word)\n",
        "                    pass"
      ],
      "metadata": {
        "id": "0QqUbo-D_Mk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(sent_lens, bins=200)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "wdsGl92SKcrx",
        "outputId": "7f28237d-016f-4423-c117-054345396b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_lens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X49qAppeJSaJ",
        "outputId": "103d08a9-163c-465c-ddbe-c7b9c21b7bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20,\n",
              " 20,\n",
              " 10,\n",
              " 3,\n",
              " 26,\n",
              " 4,\n",
              " 34,\n",
              " 28,\n",
              " 5,\n",
              " 38,\n",
              " 30,\n",
              " 27,\n",
              " 30,\n",
              " 27,\n",
              " 21,\n",
              " 25,\n",
              " 23,\n",
              " 15,\n",
              " 51,\n",
              " 22,\n",
              " 37,\n",
              " 32,\n",
              " 10,\n",
              " 5,\n",
              " 15,\n",
              " 18,\n",
              " 26,\n",
              " 34,\n",
              " 12,\n",
              " 16,\n",
              " 23,\n",
              " 17,\n",
              " 32,\n",
              " 20,\n",
              " 22,\n",
              " 26,\n",
              " 5,\n",
              " 31,\n",
              " 2,\n",
              " 8,\n",
              " 23,\n",
              " 10,\n",
              " 15,\n",
              " 27,\n",
              " 14,\n",
              " 6,\n",
              " 9,\n",
              " 5,\n",
              " 21,\n",
              " 24,\n",
              " 15,\n",
              " 29,\n",
              " 12,\n",
              " 14,\n",
              " 41,\n",
              " 18,\n",
              " 14,\n",
              " 5,\n",
              " 16,\n",
              " 6,\n",
              " 31,\n",
              " 12,\n",
              " 34,\n",
              " 30,\n",
              " 14,\n",
              " 20,\n",
              " 33,\n",
              " 13,\n",
              " 50,\n",
              " 16,\n",
              " 24,\n",
              " 9,\n",
              " 23,\n",
              " 26,\n",
              " 15,\n",
              " 18,\n",
              " 24,\n",
              " 15,\n",
              " 12,\n",
              " 13,\n",
              " 35,\n",
              " 22,\n",
              " 31,\n",
              " 18,\n",
              " 17,\n",
              " 14,\n",
              " 5,\n",
              " 32,\n",
              " 5,\n",
              " 18,\n",
              " 32,\n",
              " 37,\n",
              " 1,\n",
              " 25,\n",
              " 32,\n",
              " 37,\n",
              " 13,\n",
              " 34,\n",
              " 26,\n",
              " 19,\n",
              " 37,\n",
              " 6,\n",
              " 14,\n",
              " 8,\n",
              " 11,\n",
              " 18,\n",
              " 36,\n",
              " 11,\n",
              " 24,\n",
              " 27,\n",
              " 9,\n",
              " 9,\n",
              " 15,\n",
              " 46,\n",
              " 36,\n",
              " 51,\n",
              " 17,\n",
              " 22,\n",
              " 7,\n",
              " 44,\n",
              " 26,\n",
              " 17,\n",
              " 10,\n",
              " 9,\n",
              " 22,\n",
              " 47,\n",
              " 9,\n",
              " 12,\n",
              " 21,\n",
              " 39,\n",
              " 11,\n",
              " 11,\n",
              " 25,\n",
              " 16,\n",
              " 12,\n",
              " 35,\n",
              " 18,\n",
              " 18,\n",
              " 9,\n",
              " 13,\n",
              " 40,\n",
              " 57,\n",
              " 23,\n",
              " 15,\n",
              " 58,\n",
              " 14,\n",
              " 10,\n",
              " 28,\n",
              " 38,\n",
              " 15,\n",
              " 27,\n",
              " 3,\n",
              " 14,\n",
              " 8,\n",
              " 26,\n",
              " 25,\n",
              " 20,\n",
              " 16,\n",
              " 9,\n",
              " 10,\n",
              " 13,\n",
              " 18,\n",
              " 21,\n",
              " 24,\n",
              " 24,\n",
              " 19,\n",
              " 10,\n",
              " 20,\n",
              " 18,\n",
              " 38,\n",
              " 57,\n",
              " 13,\n",
              " 28,\n",
              " 21,\n",
              " 24,\n",
              " 15,\n",
              " 37,\n",
              " 9,\n",
              " 2,\n",
              " 27,\n",
              " 31,\n",
              " 18,\n",
              " 21,\n",
              " 18,\n",
              " 21,\n",
              " 16,\n",
              " 26,\n",
              " 33,\n",
              " 21,\n",
              " 36,\n",
              " 17,\n",
              " 19,\n",
              " 41,\n",
              " 26,\n",
              " 34,\n",
              " 23,\n",
              " 19,\n",
              " 32,\n",
              " 20,\n",
              " 24,\n",
              " 28,\n",
              " 28,\n",
              " 15,\n",
              " 12,\n",
              " 27,\n",
              " 13,\n",
              " 17,\n",
              " 18,\n",
              " 11,\n",
              " 8,\n",
              " 4,\n",
              " 28,\n",
              " 13,\n",
              " 12,\n",
              " 7,\n",
              " 27,\n",
              " 20,\n",
              " 23,\n",
              " 20,\n",
              " 28,\n",
              " 22,\n",
              " 53,\n",
              " 12,\n",
              " 31,\n",
              " 19,\n",
              " 44,\n",
              " 4,\n",
              " 20,\n",
              " 40,\n",
              " 26,\n",
              " 2,\n",
              " 42,\n",
              " 22,\n",
              " 21,\n",
              " 30,\n",
              " 43,\n",
              " 30,\n",
              " 17,\n",
              " 25,\n",
              " 33,\n",
              " 1,\n",
              " 41,\n",
              " 16,\n",
              " 29,\n",
              " 17,\n",
              " 8,\n",
              " 18,\n",
              " 16,\n",
              " 31,\n",
              " 34,\n",
              " 28,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 21,\n",
              " 24,\n",
              " 10,\n",
              " 18,\n",
              " 23,\n",
              " 27,\n",
              " 4,\n",
              " 7,\n",
              " 70,\n",
              " 13,\n",
              " 10,\n",
              " 13,\n",
              " 21,\n",
              " 16,\n",
              " 28,\n",
              " 18,\n",
              " 9,\n",
              " 14,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 8,\n",
              " 6,\n",
              " 6,\n",
              " 1,\n",
              " 14,\n",
              " 1,\n",
              " 8,\n",
              " 32,\n",
              " 5,\n",
              " 7,\n",
              " 1,\n",
              " 11,\n",
              " 1,\n",
              " 8,\n",
              " 1,\n",
              " 4,\n",
              " 17,\n",
              " 1,\n",
              " 10,\n",
              " 1,\n",
              " 6,\n",
              " 1,\n",
              " 5,\n",
              " 1,\n",
              " 12,\n",
              " 1,\n",
              " 15,\n",
              " 1,\n",
              " 14,\n",
              " 1,\n",
              " 13,\n",
              " 16,\n",
              " 1,\n",
              " 9,\n",
              " 1,\n",
              " 6,\n",
              " 7,\n",
              " 14,\n",
              " 6,\n",
              " 2,\n",
              " 1,\n",
              " 7,\n",
              " 1,\n",
              " 4,\n",
              " 13,\n",
              " 1,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 16,\n",
              " 1,\n",
              " 52,\n",
              " 40,\n",
              " 14,\n",
              " 20,\n",
              " 4,\n",
              " 8,\n",
              " 11,\n",
              " 12,\n",
              " 26,\n",
              " 1,\n",
              " 5,\n",
              " 40,\n",
              " 1,\n",
              " 14,\n",
              " 17,\n",
              " 5,\n",
              " 14,\n",
              " 13,\n",
              " 13,\n",
              " 5,\n",
              " 1,\n",
              " 22,\n",
              " 14,\n",
              " 18,\n",
              " 35,\n",
              " 12,\n",
              " 5,\n",
              " 1,\n",
              " 33,\n",
              " 7,\n",
              " 1,\n",
              " 52,\n",
              " 14,\n",
              " 87,\n",
              " 26,\n",
              " 34,\n",
              " 42,\n",
              " 1,\n",
              " 7,\n",
              " 41,\n",
              " 25,\n",
              " 6,\n",
              " 31,\n",
              " 19,\n",
              " 18,\n",
              " 11,\n",
              " 32,\n",
              " 10,\n",
              " 9,\n",
              " 34,\n",
              " 27,\n",
              " 11,\n",
              " 15,\n",
              " 22,\n",
              " 7,\n",
              " 18,\n",
              " 17,\n",
              " 3,\n",
              " 17,\n",
              " 11,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 11,\n",
              " 33,\n",
              " 10,\n",
              " 22,\n",
              " 9,\n",
              " 22,\n",
              " 28,\n",
              " 36,\n",
              " 23,\n",
              " 1,\n",
              " 26,\n",
              " 1,\n",
              " 24,\n",
              " 16,\n",
              " 17,\n",
              " 12,\n",
              " 1,\n",
              " 16,\n",
              " 11,\n",
              " 6,\n",
              " 6,\n",
              " 8,\n",
              " 19,\n",
              " 1,\n",
              " 28,\n",
              " 1,\n",
              " 10,\n",
              " 14,\n",
              " 10,\n",
              " 12,\n",
              " 6,\n",
              " 18,\n",
              " 20,\n",
              " 8,\n",
              " 22,\n",
              " 18,\n",
              " 19,\n",
              " 15,\n",
              " 12,\n",
              " 8,\n",
              " 8,\n",
              " 14,\n",
              " 1,\n",
              " 41,\n",
              " 26,\n",
              " 1,\n",
              " 19,\n",
              " 7,\n",
              " 1,\n",
              " 15,\n",
              " 31,\n",
              " 1,\n",
              " 39,\n",
              " 16,\n",
              " 22,\n",
              " 34,\n",
              " 22,\n",
              " 9,\n",
              " 30,\n",
              " 1,\n",
              " 6,\n",
              " 16,\n",
              " 8,\n",
              " 1,\n",
              " 40,\n",
              " 1,\n",
              " 39,\n",
              " 30,\n",
              " 27,\n",
              " 7,\n",
              " 1,\n",
              " 20,\n",
              " 26,\n",
              " 25,\n",
              " 12,\n",
              " 1,\n",
              " 5,\n",
              " 17,\n",
              " 8,\n",
              " 26,\n",
              " 30,\n",
              " 17,\n",
              " 1,\n",
              " 23,\n",
              " 30,\n",
              " 1,\n",
              " 21,\n",
              " 18,\n",
              " 33,\n",
              " 8,\n",
              " 8,\n",
              " 18,\n",
              " 1,\n",
              " 70,\n",
              " 9,\n",
              " 13,\n",
              " 14,\n",
              " 25,\n",
              " 13,\n",
              " 19,\n",
              " 3,\n",
              " 11,\n",
              " 24,\n",
              " 9,\n",
              " 1,\n",
              " 37,\n",
              " 27,\n",
              " 8,\n",
              " 4,\n",
              " 22,\n",
              " 24,\n",
              " 8,\n",
              " 15,\n",
              " 12,\n",
              " 23,\n",
              " 1,\n",
              " 8,\n",
              " 62,\n",
              " 1,\n",
              " 60,\n",
              " 21,\n",
              " 4,\n",
              " 27,\n",
              " 1,\n",
              " 35,\n",
              " 5,\n",
              " 7,\n",
              " 1,\n",
              " 21,\n",
              " 20,\n",
              " 1,\n",
              " 17,\n",
              " 14,\n",
              " 23,\n",
              " 38,\n",
              " 11,\n",
              " 14,\n",
              " 1,\n",
              " 16,\n",
              " 7,\n",
              " 1,\n",
              " 15,\n",
              " 1,\n",
              " 6,\n",
              " 34,\n",
              " 1,\n",
              " 22,\n",
              " 1,\n",
              " 37,\n",
              " 14,\n",
              " 12,\n",
              " 11,\n",
              " 1,\n",
              " 21,\n",
              " 32,\n",
              " 5,\n",
              " 9,\n",
              " 1,\n",
              " 8,\n",
              " 7,\n",
              " 3,\n",
              " 17,\n",
              " 1,\n",
              " 9,\n",
              " 26,\n",
              " 17,\n",
              " 7,\n",
              " 25,\n",
              " 8,\n",
              " 19,\n",
              " 9,\n",
              " 1,\n",
              " 8,\n",
              " 18,\n",
              " 32,\n",
              " 27,\n",
              " 27,\n",
              " 23,\n",
              " 1,\n",
              " 80,\n",
              " 16,\n",
              " 23,\n",
              " 1,\n",
              " 9,\n",
              " 6,\n",
              " 52,\n",
              " 1,\n",
              " 21,\n",
              " 5,\n",
              " 3,\n",
              " 1,\n",
              " 6,\n",
              " 31,\n",
              " 15,\n",
              " 39,\n",
              " 37,\n",
              " 9,\n",
              " 20,\n",
              " 23,\n",
              " 31,\n",
              " 18,\n",
              " 34,\n",
              " 6,\n",
              " 12,\n",
              " 8,\n",
              " 32,\n",
              " 22,\n",
              " 27,\n",
              " 11,\n",
              " 4,\n",
              " 18,\n",
              " 32,\n",
              " 27,\n",
              " 48,\n",
              " 34,\n",
              " 27,\n",
              " 15,\n",
              " 29,\n",
              " 7,\n",
              " 17,\n",
              " 14,\n",
              " 35,\n",
              " 31,\n",
              " 20,\n",
              " 22,\n",
              " 37,\n",
              " 6,\n",
              " 9,\n",
              " 27,\n",
              " 14,\n",
              " 27,\n",
              " 24,\n",
              " 39,\n",
              " 56,\n",
              " 4,\n",
              " 18,\n",
              " 2,\n",
              " 25,\n",
              " 54,\n",
              " 32,\n",
              " 23,\n",
              " 19,\n",
              " 10,\n",
              " 11,\n",
              " 7,\n",
              " 20,\n",
              " 42,\n",
              " 22,\n",
              " 24,\n",
              " 59,\n",
              " 31,\n",
              " 30,\n",
              " 38,\n",
              " 25,\n",
              " 29,\n",
              " 13,\n",
              " 8,\n",
              " 26,\n",
              " 35,\n",
              " 60,\n",
              " 17,\n",
              " 23,\n",
              " 40,\n",
              " 20,\n",
              " 23,\n",
              " 45,\n",
              " 2,\n",
              " 20,\n",
              " 9,\n",
              " 19,\n",
              " 7,\n",
              " 20,\n",
              " 18,\n",
              " 5,\n",
              " 5,\n",
              " 36,\n",
              " 13,\n",
              " 11,\n",
              " 23,\n",
              " 21,\n",
              " 26,\n",
              " 22,\n",
              " 30,\n",
              " 10,\n",
              " 25,\n",
              " 36,\n",
              " 6,\n",
              " 17,\n",
              " 13,\n",
              " 4,\n",
              " 32,\n",
              " 16,\n",
              " 8,\n",
              " 18,\n",
              " 14,\n",
              " 16,\n",
              " 13,\n",
              " 8,\n",
              " 18,\n",
              " 5,\n",
              " 8,\n",
              " 11,\n",
              " 5,\n",
              " 29,\n",
              " 20,\n",
              " 11,\n",
              " 23,\n",
              " 4,\n",
              " 13,\n",
              " 11,\n",
              " 3,\n",
              " 29,\n",
              " 35,\n",
              " 34,\n",
              " 25,\n",
              " 17,\n",
              " 46,\n",
              " 20,\n",
              " 26,\n",
              " 6,\n",
              " 8,\n",
              " 25,\n",
              " 11,\n",
              " 22,\n",
              " 27,\n",
              " 24,\n",
              " 23,\n",
              " 24,\n",
              " 15,\n",
              " 42,\n",
              " 11,\n",
              " 17,\n",
              " 37,\n",
              " 31,\n",
              " 29,\n",
              " 37,\n",
              " 26,\n",
              " 26,\n",
              " 31,\n",
              " 28,\n",
              " 46,\n",
              " 23,\n",
              " 23,\n",
              " 10,\n",
              " 10,\n",
              " 22,\n",
              " 15,\n",
              " 24,\n",
              " 43,\n",
              " 6,\n",
              " 32,\n",
              " 40,\n",
              " 15,\n",
              " 17,\n",
              " 33,\n",
              " 6,\n",
              " 19,\n",
              " 23,\n",
              " 22,\n",
              " 8,\n",
              " 7,\n",
              " 24,\n",
              " 14,\n",
              " 19,\n",
              " 17,\n",
              " 1,\n",
              " 177,\n",
              " 42,\n",
              " 20,\n",
              " 32,\n",
              " 18,\n",
              " 5,\n",
              " 26,\n",
              " 17,\n",
              " 34,\n",
              " 34,\n",
              " 28,\n",
              " 9,\n",
              " 27,\n",
              " 29,\n",
              " 30,\n",
              " 18,\n",
              " 12,\n",
              " 13,\n",
              " 33,\n",
              " 49,\n",
              " 22,\n",
              " 48,\n",
              " 12,\n",
              " 5,\n",
              " 29,\n",
              " 23,\n",
              " 13,\n",
              " 47,\n",
              " 17,\n",
              " 14,\n",
              " 33,\n",
              " 23,\n",
              " 43,\n",
              " 30,\n",
              " 16,\n",
              " 17,\n",
              " 40,\n",
              " 9,\n",
              " 6,\n",
              " 9,\n",
              " 9,\n",
              " 3,\n",
              " 8,\n",
              " 21,\n",
              " 16,\n",
              " 8,\n",
              " 22,\n",
              " 9,\n",
              " 37,\n",
              " 11,\n",
              " 37,\n",
              " 15,\n",
              " 31,\n",
              " 66,\n",
              " 51,\n",
              " 28,\n",
              " 31,\n",
              " 21,\n",
              " 15,\n",
              " 4,\n",
              " 28,\n",
              " 33,\n",
              " 20,\n",
              " 17,\n",
              " 5,\n",
              " 8,\n",
              " 11,\n",
              " 17,\n",
              " 7,\n",
              " 6,\n",
              " 6,\n",
              " 19,\n",
              " 10,\n",
              " 7,\n",
              " 5,\n",
              " 12,\n",
              " 26,\n",
              " 12,\n",
              " 24,\n",
              " 4,\n",
              " 23,\n",
              " 7,\n",
              " 9,\n",
              " 7,\n",
              " 4,\n",
              " 47,\n",
              " 19,\n",
              " 14,\n",
              " 19,\n",
              " 15,\n",
              " 26,\n",
              " 18,\n",
              " 16,\n",
              " 28,\n",
              " 18,\n",
              " 15,\n",
              " 11,\n",
              " 26,\n",
              " 12,\n",
              " 42,\n",
              " 45,\n",
              " 17,\n",
              " 29,\n",
              " 19,\n",
              " 27,\n",
              " 30,\n",
              " 40,\n",
              " 24,\n",
              " 16,\n",
              " 46,\n",
              " 4,\n",
              " 32,\n",
              " 37,\n",
              " 47,\n",
              " 50,\n",
              " 26,\n",
              " 21,\n",
              " 16,\n",
              " 19,\n",
              " 11,\n",
              " 68,\n",
              " 46,\n",
              " 18,\n",
              " 7,\n",
              " 2,\n",
              " 25,\n",
              " 14,\n",
              " 30,\n",
              " 31,\n",
              " 49,\n",
              " 22,\n",
              " 34,\n",
              " 21,\n",
              " 6,\n",
              " 18,\n",
              " 29,\n",
              " 28,\n",
              " 6,\n",
              " 12,\n",
              " 25,\n",
              " 13,\n",
              " 14,\n",
              " 25,\n",
              " 35,\n",
              " 12,\n",
              " 16,\n",
              " 24,\n",
              " 5,\n",
              " 9,\n",
              " 5,\n",
              " 8,\n",
              " 7,\n",
              " 8,\n",
              " 3,\n",
              " 5,\n",
              " 6,\n",
              " 25,\n",
              " 23,\n",
              " 10,\n",
              " 7,\n",
              " 6,\n",
              " 13,\n",
              " 4,\n",
              " 6,\n",
              " 22,\n",
              " 7,\n",
              " 60,\n",
              " 13,\n",
              " 14,\n",
              " 11,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 10,\n",
              " 34,\n",
              " 5,\n",
              " 21,\n",
              " 49,\n",
              " 2,\n",
              " 5,\n",
              " 6,\n",
              " 2,\n",
              " 42,\n",
              " 11,\n",
              " 4,\n",
              " 8,\n",
              " 10,\n",
              " 13,\n",
              " 33,\n",
              " 6,\n",
              " 17,\n",
              " 16,\n",
              " 24,\n",
              " 14,\n",
              " 28,\n",
              " 7,\n",
              " 8,\n",
              " 4,\n",
              " 5,\n",
              " 12,\n",
              " 14,\n",
              " 6,\n",
              " 5,\n",
              " 38,\n",
              " 10,\n",
              " 15,\n",
              " 52,\n",
              " 15,\n",
              " 23,\n",
              " 18,\n",
              " 31,\n",
              " 26,\n",
              " 13,\n",
              " 18,\n",
              " 10,\n",
              " 54,\n",
              " 32,\n",
              " 50,\n",
              " 30,\n",
              " 60,\n",
              " 26,\n",
              " 9,\n",
              " 32,\n",
              " 17,\n",
              " 6,\n",
              " 5,\n",
              " 11,\n",
              " 13,\n",
              " 14,\n",
              " 9,\n",
              " 60,\n",
              " 19,\n",
              " 16,\n",
              " 11,\n",
              " 23,\n",
              " 30,\n",
              " 6,\n",
              " 7,\n",
              " 16,\n",
              " 16,\n",
              " 14,\n",
              " 38,\n",
              " 22,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDILNjmxK6ZQ",
        "outputId": "a7c44c5c-362c-4d1c-9ee2-2aaebfb8e3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 6, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Total %s unique tokens.' % len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMsaPY3vK-fe",
        "outputId": "faa9a082-5d1d-40a1-f937-93dfbdd0be10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 17560 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.get_dummies(df[\"target\"])\n",
        "# labels = df[\"target\"]"
      ],
      "metadata": {
        "id": "qcsD-akXLBU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "KYZmASmucTrQ",
        "outputId": "c54a79ab-d77c-4ae0-eb2b-71f5489ca948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0  1\n",
              "id                   \n",
              "politifact720    0  1\n",
              "politifact10731  0  1\n",
              "politifact11115  0  1\n",
              "politifact14148  1  0\n",
              "politifact6932   0  1\n",
              "...             .. ..\n",
              "politifact7511   0  1\n",
              "politifact160    0  1\n",
              "politifact13443  0  1\n",
              "politifact14003  1  0\n",
              "politifact10903  0  1\n",
              "\n",
              "[312 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d0acbb5-7cba-42e4-91d3-0f18d9e40f2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>politifact720</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10731</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact11115</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14148</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact6932</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact7511</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact160</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact13443</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14003</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10903</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>312 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d0acbb5-7cba-42e4-91d3-0f18d9e40f2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d0acbb5-7cba-42e4-91d3-0f18d9e40f2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d0acbb5-7cba-42e4-91d3-0f18d9e40f2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_feature_array = sample_feature_array = df[['L5', 'L6', 'S6', 'Sen1', 'Sen14', 'Sen18', 'T11', 'T4', 'T5', 'T9']]"
      ],
      "metadata": {
        "id": "nFJpXzmENN9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of labels tensor:', labels.shape)\n",
        "print('Shape of sample_feature_array tensor:', sample_feature_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfPelUK8LNfI",
        "outputId": "3e4ddc1f-c043-4c9d-90aa-db0e3717205a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (312, 6, 40)\n",
            "Shape of labels tensor: (312, 2)\n",
            "Shape of sample_feature_array tensor: (312, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(data.shape[0])"
      ],
      "metadata": {
        "id": "PoHLCeqOPGQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[indices]"
      ],
      "metadata": {
        "id": "2RwrMU1dVMxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEwADdziVSUF",
        "outputId": "d4e11140-bf1e-43c2-e575-078501b3032f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312, 6, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test, f_train, f_test = train_test_split(data, df['target'], df.iloc[:, 10:70], test_size= .15, random_state= 111, stratify= df['target'] )\n",
        "x_train, x_val, y_train, y_val, f_train, f_val= train_test_split(x_train, y_train,f_train, test_size= .10, random_state= 111, stratify= None )"
      ],
      "metadata": {
        "id": "D_IRCpwDXS1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWSKwOCPUd7Q",
        "outputId": "a17a0634-c275-4873-d388-21f36d780e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 459,  113, 1237, ...,    0,    0,    0],\n",
              "        [  41,   74,   51, ...,    0,    0,    0],\n",
              "        [  17,  838,  113, ...,    0,    0,    0],\n",
              "        [   2, 2521,   22, ...,    0,    0,    0],\n",
              "        [2327,   41,   10, ...,    0,    0,    0],\n",
              "        [   2,  113, 1237, ...,    0,    0,    0]],\n",
              "\n",
              "       [[  30,    2,  459, ...,    0,    0,    0],\n",
              "        [ 108,   18,    2, ...,    0,    0,    0],\n",
              "        [1979, 7061,    2, ...,    0,    0,    0],\n",
              "        [ 334, 1219, 6066, ...,    0,    0,    0],\n",
              "        [   2, 1955, 1276, ...,    0,    0,    0],\n",
              "        [ 225,  354, 1715, ...,    0,    0,    0]],\n",
              "\n",
              "       [[ 313,  280, 6323, ...,    7,    2, 5269],\n",
              "        [ 745,   28,    2, ...,    0,    0,    0],\n",
              "        [   2, 4093, 3703, ...,    0,    0,    0],\n",
              "        [  57,  538,   30, ...,    0,    0,    0],\n",
              "        [ 258,    6,  313, ...,    0,    0,    0],\n",
              "        [  57, 1497, 3762, ...,    7, 3703,   32]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[  37,  326, 3922, ...,    0,    0,    0],\n",
              "        [7612, 7613,    0, ...,    0,    0,    0],\n",
              "        [  58,    5,    2, ...,    0,    0,    0],\n",
              "        [  26,   20,  152, ...,    0,    0,    0],\n",
              "        [  11,  327,   24, ...,    0,    0,    0],\n",
              "        [  41,  197,  914, ...,    0,    0,    0]],\n",
              "\n",
              "       [[1354,    3, 6277, ...,    0,    0,    0],\n",
              "        [4152,  127, 2295, ...,    0,    0,    0],\n",
              "        [  17, 2634,  180, ...,    0,    0,    0],\n",
              "        [ 632, 2443, 1100, ...,    0,    0,    0],\n",
              "        [ 189,   41,  747, ...,    0,    0,    0],\n",
              "        [ 340,   84,  105, ...,    0,    0,    0]],\n",
              "\n",
              "       [[ 268, 1536,  143, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0],\n",
              "        [   0,    0,    0, ...,    0,    0,    0]]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFICaSJVXXrM",
        "outputId": "8526c723-05c1-4889-a59c-9aab56281335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(238, 6, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train, x_test, y_train, y_test = train_test_split(data, df['target'], test_size= .15, random_state= 111, stratify= None )\n",
        "# x_train, x_val, y_train, y_val= train_test_split(x_train, y_train, test_size= .10, random_state= 111, stratify= None )\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "# np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels.iloc[indices]\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_val = data[-nb_validation_samples:]\n",
        "y_val = labels[-nb_validation_samples:]\n",
        "print('Number of positive and negative reviews in traing and validation set')\n",
        "f_train = sample_feature_array[:-nb_validation_samples]\n",
        "f_val = sample_feature_array[-nb_validation_samples:]\n",
        "# print(y_train.columns.tolist())\n",
        "# print(y_train.sum(axis=0).tolist())\n",
        "# print(y_val.sum(axis=0).tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YgxADbELQ9C",
        "outputId": "cd4e9de8-0567-4506-d2e2-cf8d83bc3481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive and negative reviews in traing and validation set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoGZdSmTUYHE",
        "outputId": "e755c434-1f3e-4388-90df-52bfe0e46dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4658,   14,  300,  241,  263,  209, 1286,  766,   14, 1049,   16,\n",
              "           2,  416,  428,  766,    3,  554,   16,  263,  209,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [  17,  147,  146,    5,    2,  416,  173, 1256,   14,   14,  107,\n",
              "          18,   16,    2, 2324,   34,  100, 4658,   14,  300,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [1497,   46,  475,   45, 1066, 1629,   12,   17,  263, 1433,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [ 475,   45, 1066,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_train = sample_feature_array[:-nb_validation_samples]\n",
        "f_val = sample_feature_array[-nb_validation_samples:]"
      ],
      "metadata": {
        "id": "uTVmqysyNi0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHgrkpQQNx-m",
        "outputId": "1e677afc-a77f-427e-8336-8e8581f173e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "yXDfTj0Bc3pr",
        "outputId": "44fef6b1-8a9e-49a6-ad1c-f879666e64f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0  1\n",
              "id                   \n",
              "politifact15371  1  0\n",
              "politifact13132  0  1\n",
              "politifact15187  1  0\n",
              "politifact14289  1  0\n",
              "politifact8152   0  1\n",
              "...             .. ..\n",
              "politifact7511   0  1\n",
              "politifact160    0  1\n",
              "politifact13443  0  1\n",
              "politifact14003  1  0\n",
              "politifact10903  0  1\n",
              "\n",
              "[62 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ff6db32-e070-4820-97ef-de556665f77b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>politifact15371</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact13132</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact15187</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14289</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact8152</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact7511</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact160</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact13443</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14003</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10903</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ff6db32-e070-4820-97ef-de556665f77b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ff6db32-e070-4820-97ef-de556665f77b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ff6db32-e070-4820-97ef-de556665f77b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHrHxoEJBppV",
        "outputId": "1e593c16-7fe8-4c25-c447-204201dd7468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250, 6, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWXGDpyDKVta",
        "outputId": "8061df0c-dd25-499c-e4ce-d5fc96544659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Uj3qHChMcPYs",
        "outputId": "7128f8e0-ccca-4fd9-b5a4-99dc22b30646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0  1\n",
              "id                   \n",
              "politifact720    0  1\n",
              "politifact10731  0  1\n",
              "politifact11115  0  1\n",
              "politifact14148  1  0\n",
              "politifact6932   0  1\n",
              "...             .. ..\n",
              "politifact7511   0  1\n",
              "politifact160    0  1\n",
              "politifact13443  0  1\n",
              "politifact14003  1  0\n",
              "politifact10903  0  1\n",
              "\n",
              "[312 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c3ef7d5-b696-411e-99b9-2e7a8f538ebd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>politifact720</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10731</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact11115</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14148</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact6932</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact7511</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact160</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact13443</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact14003</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politifact10903</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>312 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c3ef7d5-b696-411e-99b9-2e7a8f538ebd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c3ef7d5-b696-411e-99b9-2e7a8f538ebd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c3ef7d5-b696-411e-99b9-2e7a8f538ebd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REG_PARAM = 1e-13\n",
        "l2_reg = regularizers.l2(REG_PARAM)"
      ],
      "metadata": {
        "id": "A3A4j8FaLcHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n"
      ],
      "metadata": {
        "id": "VASyRsA6pJ3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip glove*.zip\n"
      ],
      "metadata": {
        "id": "LPe1rsbzp0VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GLOVE_DIR = \"/content/drive/MyDrive/glove.6B.100d.txt\"\n",
        "embeddings_index = {}\n",
        "f = open(GLOVE_DIR)\n",
        "for line in f:\n",
        "    try:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = values[1:]\n",
        "        # coefs = np.asarray(y, dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    except:\n",
        "        print(\"except\")\n",
        "        print(word)\n",
        "        pass\n",
        "f.close()\n",
        "print('Total %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTYXTLsvLhhY",
        "outputId": "abf1bbd0-ade0-44d7-f66a-ca37aa658149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KF6l9fw4Apm",
        "outputId": "09402758-b9de-423b-8b14-a91622865fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
        "absent_words = 0\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        absent_words += 1\n",
        "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7ZTdhVvq9OX",
        "outputId": "7e998b4a-8401-4a47-c510-b8bdb7f47d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total absent words are 978 which is 5.57 % of total words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1,embed_size,weights=[embedding_matrix], input_length=max_senten_len, trainable=False)"
      ],
      "metadata": {
        "id": "bFMWX8BO4xbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.engine.topology import Layer\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "\n",
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "class AttentionWithContext(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, context_vector_length = 1000, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.context_vector_length = context_vector_length\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "        print('{}_W'.format(self.name))\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'context_vector_length': self.context_vector_length\n",
        "        }\n",
        "        base_config = super(AttentionWithContext, self).get_config()\n",
        "        return {**base_config, **config}\n"
      ],
      "metadata": {
        "id": "OCFoIfaU5FPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_DZLznUPDvEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_input = Input(shape=(max_senten_len,), dtype='float32')\n",
        "word_sequences = embedding_layer(word_input)\n",
        "embeding_dim = 128\n",
        "word_lstm = Bidirectional(GRU(embeding_dim, return_sequences=True, kernel_regularizer=l2_reg))(word_sequences)\n",
        "word_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(word_lstm)\n",
        "word_att = AttentionWithContext()(word_dense)\n",
        "wordEncoder = Model(word_input, word_att)\n",
        "\n",
        "sent_input = Input(shape=(max_senten_num, max_senten_len), dtype='float32')\n",
        "sent_encoder = TimeDistributed(wordEncoder)(sent_input)\n",
        "sent_lstm = Bidirectional(GRU(embeding_dim, return_sequences=True, kernel_regularizer=l2_reg))(sent_encoder)\n",
        "sent_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(sent_lstm)\n",
        "sent_att = Dropout(0.2)(AttentionWithContext()(sent_dense))\n",
        "# sentEncoder = Model(sent_input, sent_att)\n",
        "# preds = Dense(2, activation='sigmoid')(sent_att)\n",
        "dense_cat = Dense(128, activation='relu')(sent_att)\n",
        "# dense_cat shape == feature.shape 1 dim will be diff and rest same. \n",
        "feature_input = Input(shape=f_train.shape[1], dtype='float64', name='text')\n",
        "# fea_encoder = TimeDistributed(sent_encoder)(text_input)\n",
        "\n",
        "# embedded_text = tf.keras.layers.Embedding(64, len(f_train))(text_input)\n",
        "# encoded_feature = tf.keras.layers.LSTM(64)(feature_input)\n",
        "#shape of feature vector\n",
        "# feature_input = Input(shape=(sample_feature_array.shape), dtype='float64')\n",
        "# feature_encoder = tf.keras.layers.TimeDistributed(sample_feature_array)(feature_input)\n",
        "\n",
        "# feature_encoder = TimeDistributed(sample_feature_array)(feature_input)\n",
        "# feature_lstm = Bidirectional(LSTM(embeding_dim, return_sequences=True, kernel_regularizer=l2_reg))(feature_encoder)\n",
        "# feature_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(feature_lstm)\n",
        "# feature_att = Dropout(0.5)(AttentionWithContext()(feature_dense))\n",
        "# merged = tf.keras.layers.concatenate([encoded_feature, dense_cat],axis=-1)\n",
        "merged = tf.keras.layers.Concatenate(axis=1)([feature_input, dense_cat])\n",
        "\n",
        "preds = tf.keras.layers.Dense(2, activation='softmax')(merged)\n",
        "# merged = tf.keras.layers.concatenate([dense_cat, feature_input])\n",
        "\n",
        "# preds = Dense(2, activation='sigmoid')(concatenated)\n",
        "\n",
        "model = Model([sent_input, feature_input], preds)\n",
        "# model = Model(preds, sent_input, text_input)\n",
        "# model.add(GlobalAveragePooling2D())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTdtECWZ41N_",
        "outputId": "423b22f7-4df2-4171-e655-3c8a113cb829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_with_context_2_W\n",
            "attention_with_context_3_W\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(1e-3),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "d3dluKpHAeq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKTPlbry_t6u",
        "outputId": "2c67df94-74b9-4ff8-b00e-3ae57f2e42aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 6, 40)]      0           []                               \n",
            "                                                                                                  \n",
            " time_distributed_4 (TimeDistri  (None, 6, 200)      2448988     ['input_4[0][0]']                \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirectional  (None, 6, 512)      703488      ['time_distributed_4[0][0]']     \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " time_distributed_5 (TimeDistri  (None, 6, 200)      102600      ['bidirectional_3[0][0]']        \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " attention_with_context_3 (Atte  (None, 200)         40400       ['time_distributed_5[0][0]']     \n",
            " ntionWithContext)                                                                                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 200)          0           ['attention_with_context_3[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " text (InputLayer)              [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          25728       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 138)          0           ['text[0][0]',                   \n",
            "                                                                  'dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 2)            278         ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,321,482\n",
            "Trainable params: 1,565,382\n",
            "Non-trainable params: 1,756,100\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "metadata": {
        "id": "0Brmua8v9SSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.MinMaxScaler()\n",
        "f_train_transform = scaler.fit_transform(f_train)\n",
        "f_val_transform = scaler.fit_transform(f_val)\n",
        "f_test_transform = scaler.fit_transform(f_test)"
      ],
      "metadata": {
        "id": "6u6c8oDC3VCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_train_arr = [x_train, f_train_transform]\n",
        "merged_val_arr = [x_val, f_val_transform]\n",
        "# merged_test_arr = [x_test, f_test_transform]"
      ],
      "metadata": {
        "id": "bKSJz_AKYMfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_val_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epoBuEEoX9My",
        "outputId": "0b7306b1-0bbe-4f0c-c125-680be8cf72cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[  61,   41,    4, ...,    5,  210,  101],\n",
              "         [   6,  478,  101, ...,    0,    0,    0],\n",
              "         [   2, 2071, 1636, ...,   21,    8,  214],\n",
              "         [ 255,   84,   18, ...,   14,  710, 2657],\n",
              "         [   3,   15,    6, ...,    0,    0,    0],\n",
              "         [  20,  785,    2, ...,    0,    0,    0]],\n",
              " \n",
              "        [[ 267,  569,   10, ...,    0,    0,    0],\n",
              "         [   8,    6,  708, ...,    0,    0,    0],\n",
              "         [ 267,  569,   83, ...,    0,    0,    0],\n",
              "         [  11, 4530,  222, ...,    0,    0,    0],\n",
              "         [  11,  559,    2, ...,    0,    0,    0],\n",
              "         [ 637,   17, 3437, ...,    0,    0,    0]],\n",
              " \n",
              "        [[ 384, 5295,  264, ...,    0,    0,    0],\n",
              "         [1164,  287, 5661, ...,    0,    0,    0],\n",
              "         [ 758,  234,   23, ...,    0,    0,    0],\n",
              "         [ 104,    2, 2656, ...,    8,  225,  129],\n",
              "         [ 267,  376, 3415, ...,    0,    0,    0],\n",
              "         [ 153,   55,   10, ...,    0,    0,    0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 268, 1536,  143, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0],\n",
              "         [   0,    0,    0, ...,    0,    0,    0]],\n",
              " \n",
              "        [[6330,    4,   40, ...,    0,    0,    0],\n",
              "         [ 980, 1790, 2466, ...,  330, 5890, 3105],\n",
              "         [   2,  488, 1404, ...,    0,    0,    0],\n",
              "         [ 367,    3, 1846, ...,    0,    0,    0],\n",
              "         [ 255, 2928,    3, ...,    0,    0,    0],\n",
              "         [1781,    5,   52, ...,    0,    0,    0]],\n",
              " \n",
              "        [[  71,  479,    0, ...,    0,    0,    0],\n",
              "         [  13, 2219,   62, ...,    0,    0,    0],\n",
              "         [1791,    8, 2104, ...,    0,    0,    0],\n",
              "         [ 637,    6, 1796, ...,    0,    0,    0],\n",
              "         [   2,  488, 1172, ...,    0,    0,    0],\n",
              "         [   2,  242,   10, ...,    0,    0,    0]]], dtype=int32),\n",
              " array([[3.93375735e-01, 8.46153846e-01, 5.49786194e-02, 6.15384615e-01,\n",
              "         1.00000000e+00, 5.31943212e-01, 9.39788828e-02, 9.08439466e-02,\n",
              "         1.86238863e-01, 1.37205194e-03],\n",
              "        [4.86799472e-01, 9.16666667e-01, 4.88698839e-03, 1.00000000e+00,\n",
              "         3.99051480e-01, 4.78260870e-01, 4.71176600e-02, 4.71855747e-02,\n",
              "         2.25606019e-02, 0.00000000e+00],\n",
              "        [5.07380295e-01, 0.00000000e+00, 6.90287111e-02, 0.00000000e+00,\n",
              "         6.86078296e-01, 6.70893720e-01, 4.81418288e-03, 4.60471714e-03,\n",
              "         2.62865118e-02, 3.02124371e-03],\n",
              "        [4.86799472e-01, 0.00000000e+00, 5.62003665e-02, 0.00000000e+00,\n",
              "         1.22951780e-02, 5.08847321e-01, 1.99597334e-01, 1.99654381e-01,\n",
              "         5.71390096e-02, 3.61135677e-04],\n",
              "        [8.07257290e-01, 0.00000000e+00, 2.93219304e-02, 3.33333333e-01,\n",
              "         1.52356276e-01, 5.84541063e-01, 8.91637161e-01, 8.91644884e-01,\n",
              "         3.36190850e-01, 2.07834805e-04],\n",
              "        [4.86799472e-01, 2.15686275e-01, 6.10873549e-04, 1.56862745e-01,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         1.61017706e-02, 0.00000000e+00],\n",
              "        [4.86799472e-01, 1.64179104e-01, 6.10873549e-04, 5.97014925e-01,\n",
              "         2.53185328e-01, 0.00000000e+00, 7.92431586e-01, 7.92446380e-01,\n",
              "         2.01825891e-02, 0.00000000e+00],\n",
              "        [4.27057082e-01, 0.00000000e+00, 1.09957239e-02, 0.00000000e+00,\n",
              "         2.18113144e-02, 4.78260870e-01, 3.35261020e-03, 5.37463368e-04,\n",
              "         7.73459515e-01, 2.61042113e-05],\n",
              "        [0.00000000e+00, 0.00000000e+00, 3.17654246e-02, 0.00000000e+00,\n",
              "         1.90178365e-02, 5.27566114e-01, 7.47371211e-02, 7.48030673e-02,\n",
              "         2.21754255e-01, 1.52103646e-03],\n",
              "        [4.86799472e-01, 0.00000000e+00, 6.10873549e-04, 0.00000000e+00,\n",
              "         6.21776062e-01, 0.00000000e+00, 1.69392543e-05, 0.00000000e+00,\n",
              "         1.99283639e-02, 0.00000000e+00],\n",
              "        [4.86799472e-01, 0.00000000e+00, 2.44349420e-03, 3.33333333e-01,\n",
              "         0.00000000e+00, 0.00000000e+00, 1.29140073e-02, 1.24746725e-02,\n",
              "         1.22681925e-01, 0.00000000e+00],\n",
              "        [4.86799472e-01, 0.00000000e+00, 8.67440440e-02, 0.00000000e+00,\n",
              "         8.73896734e-03, 6.80244829e-01, 7.18345062e-01, 7.18115261e-01,\n",
              "         9.54546541e-02, 9.56688269e-04],\n",
              "        [6.01636065e-01, 0.00000000e+00, 3.23762981e-02, 0.00000000e+00,\n",
              "         6.00801340e-03, 5.25807272e-01, 7.60098383e-02, 7.60756938e-02,\n",
              "         3.64467115e-01, 1.81107289e-03],\n",
              "        [4.86799472e-01, 0.00000000e+00, 1.22174710e-02, 3.47826087e-01,\n",
              "         5.15065132e-03, 5.57971014e-01, 8.96600251e-01, 8.96607621e-01,\n",
              "         7.81931382e-02, 8.07955796e-01],\n",
              "        [4.86799472e-01, 0.00000000e+00, 3.05436775e-03, 0.00000000e+00,\n",
              "         6.83648127e-01, 0.00000000e+00, 7.13147901e-04, 7.84370013e-04,\n",
              "         1.74773557e-02, 0.00000000e+00],\n",
              "        [4.86799472e-01, 7.33333333e-01, 1.03848503e-02, 0.00000000e+00,\n",
              "         8.69073359e-01, 5.86255259e-01, 1.07385220e-01, 1.07448840e-01,\n",
              "         1.78253422e-02, 3.44585949e-04],\n",
              "        [8.44833793e-02, 4.07407407e-01, 2.81001833e-02, 0.00000000e+00,\n",
              "         5.27344646e-01, 5.01781896e-01, 1.82345209e-02, 1.83044942e-02,\n",
              "         5.43834346e-02, 9.45920282e-03],\n",
              "        [4.86799472e-01, 6.47058824e-01, 6.10873549e-03, 0.00000000e+00,\n",
              "         4.76989977e-02, 5.00000000e-01, 1.46915841e-01, 1.46976643e-01,\n",
              "         1.47784150e-01, 1.16268455e-03],\n",
              "        [4.86799472e-01, 0.00000000e+00, 1.77153329e-02, 2.96296296e-01,\n",
              "         1.61581155e-02, 5.29503106e-01, 2.33016993e-01, 2.32991497e-01,\n",
              "         1.87585502e-02, 0.00000000e+00],\n",
              "        [5.13911556e-01, 5.78947368e-01, 6.71960904e-02, 4.21052632e-01,\n",
              "         1.04669308e-02, 9.31350114e-01, 9.48347734e-02, 9.48992872e-02,\n",
              "         3.45928180e-01, 5.07857091e-03],\n",
              "        [3.06312252e-02, 6.47058824e-01, 2.01588271e-02, 0.00000000e+00,\n",
              "         7.00361647e-01, 1.00000000e+00, 2.07487063e-03, 2.14599569e-03,\n",
              "         1.17078902e-01, 3.55462703e-04],\n",
              "        [4.74018961e-01, 6.87500000e-01, 4.58155162e-02, 5.00000000e-01,\n",
              "         8.90400895e-01, 5.30913442e-01, 1.29059109e-01, 1.29121184e-01,\n",
              "         1.00000000e+00, 3.67590026e-02],\n",
              "        [4.86799472e-01, 0.00000000e+00, 1.22174710e-03, 0.00000000e+00,\n",
              "         0.00000000e+00, 0.00000000e+00, 1.37289021e-03, 1.44406530e-03,\n",
              "         1.60703071e-02, 0.00000000e+00],\n",
              "        [4.42697708e-01, 8.46153846e-01, 6.41417227e-02, 6.15384615e-01,\n",
              "         3.69278539e-02, 5.68190264e-01, 1.00000000e+00, 1.00000000e+00,\n",
              "         5.93590755e-02, 3.95509060e-04],\n",
              "        [6.53101124e-01, 0.00000000e+00, 8.55222969e-03, 3.47826087e-01,\n",
              "         1.71693587e-02, 4.78260870e-01, 1.62093162e-01, 1.62152882e-01,\n",
              "         5.34653291e-02, 4.10578068e-04],\n",
              "        [1.00000000e+00, 4.58333333e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "         7.61204633e-01, 4.78260870e-01, 4.41761129e-02, 4.42442373e-02,\n",
              "         0.00000000e+00, 0.00000000e+00],\n",
              "        [2.14375943e-01, 0.00000000e+00, 4.27611484e-03, 0.00000000e+00,\n",
              "         3.73247631e-01, 5.13043478e-01, 9.08560766e-03, 9.15623304e-03,\n",
              "         1.16381670e-01, 1.42771834e-03],\n",
              "        [4.63918557e-01, 0.00000000e+00, 1.22174710e-03, 0.00000000e+00,\n",
              "         0.00000000e+00, 0.00000000e+00, 1.79030313e-02, 1.79730283e-02,\n",
              "         4.62721393e-02, 0.00000000e+00],\n",
              "        [4.86799472e-01, 0.00000000e+00, 4.27611484e-03, 0.00000000e+00,\n",
              "         1.06496559e-02, 6.37681159e-01, 5.83945029e-01, 5.83693552e-01,\n",
              "         1.77938787e-02, 0.00000000e+00],\n",
              "        [9.20376815e-01, 0.00000000e+00, 1.00000000e+00, 6.66666667e-01,\n",
              "         1.33372021e-01, 7.58436080e-01, 4.70284900e-02, 4.50980363e-02,\n",
              "         9.50896773e-02, 3.47410225e-03],\n",
              "        [4.86799472e-01, 0.00000000e+00, 4.88698839e-03, 0.00000000e+00,\n",
              "         3.57846218e-03, 4.94202899e-01, 6.89536792e-02, 6.90200376e-02,\n",
              "         2.28412565e-02, 5.84576880e-02],\n",
              "        [4.35797432e-01, 0.00000000e+00, 4.27611484e-03, 0.00000000e+00,\n",
              "         2.35364221e-01, 4.78260870e-01, 1.72698960e-01, 1.72757924e-01,\n",
              "         2.85455925e-02, 0.00000000e+00],\n",
              "        [4.86799472e-01, 0.00000000e+00, 2.44349420e-03, 2.75862069e-01,\n",
              "         3.83004244e-01, 4.78260870e-01, 8.93912478e-01, 8.93920039e-01,\n",
              "         6.64336478e-01, 0.00000000e+00],\n",
              "        [4.54188168e-01, 0.00000000e+00, 2.62675626e-02, 3.63636364e-01,\n",
              "         1.20383018e-01, 6.71600370e-01, 8.43468326e-01, 8.43479482e-01,\n",
              "         1.82565183e-01, 2.22331392e-03],\n",
              "        [4.86799472e-01, 0.00000000e+00, 8.91875382e-02, 0.00000000e+00,\n",
              "         8.71631737e-02, 6.10245584e-01, 1.10269320e-01, 1.10332734e-01,\n",
              "         4.27161324e-02, 1.33286590e-03],\n",
              "        [4.86799472e-01, 0.00000000e+00, 4.27611484e-03, 2.58064516e-01,\n",
              "         4.00671581e-01, 0.00000000e+00, 5.45783277e-04, 6.17017317e-04,\n",
              "         1.64673767e-02, 6.75252241e-04],\n",
              "        [4.86799472e-01, 5.23809524e-01, 1.22174710e-03, 3.80952381e-01,\n",
              "         0.00000000e+00, 4.78260870e-01, 7.68279616e-02, 7.68937588e-02,\n",
              "         1.64617133e-02, 0.00000000e+00],\n",
              "        [4.80244210e-01, 0.00000000e+00, 5.80329872e-02, 0.00000000e+00,\n",
              "         7.42834915e-01, 4.97781721e-01, 2.28558612e-01, 2.28613595e-01,\n",
              "         9.22006970e-02, 1.44101462e-03],\n",
              "        [6.77727109e-01, 1.00000000e+00, 1.64935858e-02, 0.00000000e+00,\n",
              "         2.69778870e-02, 5.42028986e-01, 1.48313830e-01, 1.48374532e-01,\n",
              "         7.82466262e-02, 1.00000000e+00],\n",
              "        [4.86799472e-01, 0.00000000e+00, 1.83262065e-03, 0.00000000e+00,\n",
              "         0.00000000e+00, 4.78260870e-01, 5.06366988e-04, 5.77603838e-04,\n",
              "         1.63471861e-02, 0.00000000e+00],\n",
              "        [4.86799472e-01, 0.00000000e+00, 6.10873549e-04, 0.00000000e+00,\n",
              "         0.00000000e+00, 4.78260870e-01, 5.27642591e-02, 5.27479837e-02,\n",
              "         1.89290825e-02, 0.00000000e+00],\n",
              "        [4.86799472e-01, 0.00000000e+00, 3.05436775e-03, 6.15384615e-01,\n",
              "         5.72258209e-03, 4.78260870e-01, 8.19713569e-01, 8.19726418e-01,\n",
              "         1.60224826e-02, 0.00000000e+00],\n",
              "        [4.86799472e-01, 0.00000000e+00, 3.90959071e-02, 0.00000000e+00,\n",
              "         5.70004212e-01, 4.94983278e-01, 3.45482235e-03, 2.79701444e-03,\n",
              "         4.58297622e-02, 6.45872054e-04],\n",
              "        [4.44100264e-01, 7.85714286e-01, 6.71960904e-03, 0.00000000e+00,\n",
              "         6.03538264e-01, 4.78260870e-01, 9.41695992e-02, 9.42341604e-02,\n",
              "         1.44206748e-01, 6.62223442e-03],\n",
              "        [4.86799472e-01, 6.11111111e-01, 1.21563836e-01, 4.44444444e-01,\n",
              "         4.02856718e-01, 5.36231884e-01, 1.39262797e-01, 1.22431544e-01,\n",
              "         4.58952063e-02, 1.58888348e-01],\n",
              "        [4.86799472e-01, 0.00000000e+00, 6.10873549e-04, 0.00000000e+00,\n",
              "         7.86918010e-02, 4.78260870e-01, 7.39840945e-03, 7.46915509e-03,\n",
              "         1.63213860e-02, 0.00000000e+00],\n",
              "        [6.26185047e-01, 0.00000000e+00, 7.33048259e-02, 3.20000000e-01,\n",
              "         2.26469342e-01, 6.12771739e-01, 9.41807781e-01, 9.41738174e-01,\n",
              "         9.84292153e-02, 9.21482198e-04],\n",
              "        [3.53504140e-01, 4.58333333e-01, 3.48197923e-02, 0.00000000e+00,\n",
              "         4.79254927e-01, 4.84392419e-01, 2.08785433e-03, 2.14164488e-03,\n",
              "         1.59468443e-01, 7.30940196e-01],\n",
              "        [7.19953798e-01, 5.78947368e-01, 4.33720220e-02, 8.42105263e-01,\n",
              "         1.06381589e-01, 7.06832298e-01, 2.10482141e-01, 2.10538412e-01,\n",
              "         2.25574555e-02, 9.11431647e-04],\n",
              "        [7.62720509e-01, 0.00000000e+00, 1.64935858e-02, 0.00000000e+00,\n",
              "         6.14834383e-03, 6.86200378e-01, 2.42130050e-01, 2.41952264e-01,\n",
              "         5.23678815e-02, 5.59030664e-05],\n",
              "        [4.86799472e-01, 4.07407407e-01, 2.44349420e-03, 2.96296296e-01,\n",
              "         1.61060291e-01, 4.78260870e-01, 6.13035832e-01, 6.13063412e-01,\n",
              "         3.60156613e-02, 0.00000000e+00],\n",
              "        [4.86799472e-01, 0.00000000e+00, 1.83262065e-03, 0.00000000e+00,\n",
              "         2.57764908e-01, 4.78260870e-01, 4.15585343e-02, 4.16268452e-02,\n",
              "         2.20880198e-02, 0.00000000e+00],\n",
              "        [4.86799472e-01, 0.00000000e+00, 1.83262065e-03, 0.00000000e+00,\n",
              "         6.06971870e-02, 4.78260870e-01, 6.31966364e-02, 6.32634051e-02,\n",
              "         1.58897065e-02, 0.00000000e+00],\n",
              "        [4.86799472e-01, 0.00000000e+00, 9.77397679e-03, 4.44444444e-01,\n",
              "         1.96843895e-02, 9.42857143e-01, 3.87779199e-02, 3.88464290e-02,\n",
              "         1.09915288e-01, 1.44117000e-05],\n",
              "        [8.61754470e-01, 0.00000000e+00, 1.52718387e-02, 0.00000000e+00,\n",
              "         6.36568448e-02, 5.07844016e-01, 8.41275056e-01, 8.41286368e-01,\n",
              "         1.07084829e-01, 0.00000000e+00],\n",
              "        [6.43512883e-01, 0.00000000e+00, 6.29199756e-02, 0.00000000e+00,\n",
              "         5.51028279e-01, 8.36956522e-01, 4.70476856e-02, 4.71156053e-02,\n",
              "         5.10797651e-02, 1.47025738e-01],\n",
              "        [4.86799472e-01, 5.50000000e-01, 1.22174710e-03, 4.00000000e-01,\n",
              "         2.02729433e-01, 4.78260870e-01, 7.90800234e-01, 7.90713847e-01,\n",
              "         2.28846761e-02, 0.00000000e+00],\n",
              "        [7.96921877e-01, 0.00000000e+00, 1.22174710e-03, 0.00000000e+00,\n",
              "         1.09485547e-02, 4.78260870e-01, 6.55355282e-01, 6.55305626e-01,\n",
              "         1.67675387e-02, 0.00000000e+00],\n",
              "        [4.86799472e-01, 3.54838710e-01, 1.71044594e-02, 2.58064516e-01,\n",
              "         8.13454113e-02, 5.57971014e-01, 8.68234694e-01, 8.68244085e-01,\n",
              "         1.90385755e-02, 5.44187346e-04],\n",
              "        [4.86799472e-01, 0.00000000e+00, 3.66524130e-03, 3.33333333e-01,\n",
              "         1.83706564e-02, 7.85714286e-01, 9.51418723e-02, 9.51358739e-02,\n",
              "         1.80632064e-02, 0.00000000e+00],\n",
              "        [4.51305909e-01, 6.47058824e-01, 2.44349420e-03, 0.00000000e+00,\n",
              "         3.53831403e-01, 4.78260870e-01, 2.87177605e-03, 2.87254627e-03,\n",
              "         9.46416368e-02, 2.51554476e-03],\n",
              "        [4.86799472e-01, 0.00000000e+00, 1.83262065e-03, 0.00000000e+00,\n",
              "         0.00000000e+00, 5.82230624e-01, 7.46323045e-03, 7.53397146e-03,\n",
              "         1.83174317e-02, 0.00000000e+00]])]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "berthist = model.fit(merged_train_arr, y_train, validation_data= (merged_val_arr, y_val), epochs=100, batch_size=64, verbose=1, callbacks=[earlyStopping, mcp_save])\n",
        "print(time.time()-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJQ4mHZY9Wlt",
        "outputId": "b862e541-ec06-4c1d-8ee6-8796984dbac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 22s 3s/step - loss: 0.7295 - accuracy: 0.5160 - val_loss: 0.7007 - val_accuracy: 0.4516\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.7044 - accuracy: 0.4840 - val_loss: 0.6898 - val_accuracy: 0.6290\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.6771 - accuracy: 0.5880 - val_loss: 0.6126 - val_accuracy: 0.7419\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.5944 - accuracy: 0.6760 - val_loss: 0.5157 - val_accuracy: 0.7742\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.5235 - accuracy: 0.7280 - val_loss: 0.5586 - val_accuracy: 0.7742\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.4739 - accuracy: 0.7720 - val_loss: 0.6363 - val_accuracy: 0.6774\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 10s 2s/step - loss: 0.4356 - accuracy: 0.8080 - val_loss: 0.5321 - val_accuracy: 0.8387\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.3991 - accuracy: 0.7960 - val_loss: 0.5788 - val_accuracy: 0.8065\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.3539 - accuracy: 0.8360 - val_loss: 0.4736 - val_accuracy: 0.8387\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.3302 - accuracy: 0.8240 - val_loss: 0.4729 - val_accuracy: 0.8387\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.2749 - accuracy: 0.8600 - val_loss: 0.6152 - val_accuracy: 0.7742\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.2388 - accuracy: 0.8800 - val_loss: 0.5845 - val_accuracy: 0.7419\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1843 - accuracy: 0.9160 - val_loss: 0.9563 - val_accuracy: 0.7419\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1944 - accuracy: 0.9000 - val_loss: 0.8398 - val_accuracy: 0.7581\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1482 - accuracy: 0.9240 - val_loss: 0.8945 - val_accuracy: 0.7742\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 9s 2s/step - loss: 0.1783 - accuracy: 0.9240 - val_loss: 1.4026 - val_accuracy: 0.7419\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1594 - accuracy: 0.9440 - val_loss: 0.7494 - val_accuracy: 0.7903\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1232 - accuracy: 0.9480 - val_loss: 1.1613 - val_accuracy: 0.7742\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1449 - accuracy: 0.9440 - val_loss: 1.3027 - val_accuracy: 0.7903\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 7s 2s/step - loss: 0.1196 - accuracy: 0.9440 - val_loss: 0.9296 - val_accuracy: 0.8065\n",
            "162.24313807487488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"/content/drive/MyDrive/fake_bert/HAN_model_finetune\""
      ],
      "metadata": {
        "id": "FNpV1wmG9zlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, file_name)"
      ],
      "metadata": {
        "id": "OvIGjJmi91u_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f62972-0f06-4c27-858e-2a26f5cee319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_10_layer_call_fn, gru_cell_10_layer_call_and_return_conditional_losses, gru_cell_11_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_7_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hanModel_pred = model.predict([x_val, f_val])\n",
        "# hanLayerModel_y = np.argmax(hanModel_pred, axis = 1)\n",
        "# hanLayerModel_y\n",
        "\n",
        "hanModel_pred = model.predict(merged_val_arr)\n",
        "hanLayerModel_y = np.argmax(hanModel_pred, axis = 1)\n",
        "hanLayerModel_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieyew1Lx95CW",
        "outputId": "000699c4-5ab7-4245-8f6f-251646bebc9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 4s 539ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(hanLayerModel_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC537jmrbkxN",
        "outputId": "e729d990-47d4-4dc2-c6c2-13de5315639f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_val[1].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUiTQoWzOy4i",
        "outputId": "2aff042b-87d2-478d-fdee-e261cc348442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy:', accuracy_score(hanLayerModel_y, y_val[1].values))\n",
        "print('F1 score:', f1_score(y_val[1].values, hanLayerModel_y))\n",
        "print('Recall:', recall_score(np.array(y_val[1]), hanLayerModel_y))\n",
        "print('Precision:', precision_score(np.array(y_val[1]), hanLayerModel_y))\n",
        "print('ROC_AUC Score:', roc_auc_score(np.array(y_val[1]), hanLayerModel_y))\n",
        "\n",
        "print(classification_report(np.array(y_val[1]), hanLayerModel_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkY6U1nP99ZS",
        "outputId": "f0ca5820-e040-494f-8c8b-7da3b8f228fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8064516129032258\n",
            "F1 score: 0.8285714285714286\n",
            "Recall: 0.90625\n",
            "Precision: 0.7631578947368421\n",
            "ROC_AUC Score: 0.8031249999999999\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.70      0.78        30\n",
            "           1       0.76      0.91      0.83        32\n",
            "\n",
            "    accuracy                           0.81        62\n",
            "   macro avg       0.82      0.80      0.80        62\n",
            "weighted avg       0.82      0.81      0.80        62\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hanLayerModel_y"
      ],
      "metadata": {
        "id": "elvBAVSnOr7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cda1c30-86d7-4494-c1f0-be138cd52f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    }
  ]
}